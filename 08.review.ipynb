{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_core.tools import FunctionTool\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_chat_completion_client = AzureOpenAIChatCompletionClient(\n",
    "            model=\"gpt-4o\",\n",
    "            azure_endpoint=azure_endpoint,\n",
    "            api_version=api_version,\n",
    "            api_key=api_key,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_search(query: str, num_results: int = 2, max_chars: int = 500) -> list:  # type: ignore[type-arg]\n",
    "    import os\n",
    "    import time\n",
    "\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "    serp_api_key = os.getenv(\"SERPAPI_KEY\")\n",
    "\n",
    "    if not serp_api_key:\n",
    "        raise ValueError(\"SerpAPI key not found in environment variables\")\n",
    "\n",
    "    url = \"https://serpapi.com/search\"\n",
    "    params = {\n",
    "        \"engine\": \"google\",\n",
    "        \"q\": query,\n",
    "        \"num\": num_results,\n",
    "        \"api_key\": serp_api_key,\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(response.json())\n",
    "        raise Exception(f\"Error in API request: {response.status_code}\")\n",
    "\n",
    "    results = response.json().get(\"organic_results\", [])\n",
    "\n",
    "    def get_page_content(url: str) -> str:\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            text = soup.get_text(separator=\" \", strip=True)\n",
    "            words = text.split()\n",
    "            content = \"\"\n",
    "            for word in words:\n",
    "                if len(content) + len(word) + 1 > max_chars:\n",
    "                    break\n",
    "                content += \" \" + word\n",
    "            return content.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {url}: {str(e)}\")\n",
    "            return \"\"\n",
    "\n",
    "    enriched_results = []\n",
    "    for item in results:\n",
    "        body = get_page_content(item[\"link\"])\n",
    "        enriched_results.append(\n",
    "            {\"title\": item[\"title\"], \"link\": item[\"link\"], \"snippet\": item.get(\"snippet\", \"\"), \"body\": body}\n",
    "        )\n",
    "        time.sleep(1)  # Be respectful to the servers\n",
    "\n",
    "    print(enriched_results)    \n",
    "\n",
    "    return enriched_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arxiv_search(query: str, max_results: int = 2) -> list:  # type: ignore[type-arg]\n",
    "    \"\"\"\n",
    "    Search Arxiv for papers and return the results including abstracts.\n",
    "    \"\"\"\n",
    "    import arxiv\n",
    "\n",
    "    client = arxiv.Client()\n",
    "    search = arxiv.Search(query=query, max_results=max_results, sort_by=arxiv.SortCriterion.Relevance)\n",
    "\n",
    "    results = []\n",
    "    for paper in client.results(search):\n",
    "        results.append(\n",
    "            {\n",
    "                \"title\": paper.title,\n",
    "                \"authors\": [author.name for author in paper.authors],\n",
    "                \"published\": paper.published.strftime(\"%Y-%m-%d\"),\n",
    "                \"abstract\": paper.summary,\n",
    "                \"pdf_url\": paper.pdf_url,\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "    print(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_search_tool = FunctionTool(\n",
    "    google_search, description=\"Search Google for information, returns results with a snippet and body content\"\n",
    ")\n",
    "arxiv_search_tool = FunctionTool(\n",
    "    arxiv_search, description=\"Search Arxiv for papers related to a given topic, including abstracts\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_search_agent = AssistantAgent(\n",
    "    name=\"Google_Search_Agent\",\n",
    "    tools=[google_search_tool],\n",
    "    model_client=azure_openai_chat_completion_client,\n",
    "    description=\"An agent that can search Google for information, returns results with a snippet and body content\",\n",
    "    system_message=\"You are a helpful AI assistant. Solve tasks using your tools.\",\n",
    ")\n",
    "\n",
    "arxiv_search_agent = AssistantAgent(\n",
    "    name=\"Arxiv_Search_Agent\",\n",
    "    tools=[arxiv_search_tool],\n",
    "    model_client=azure_openai_chat_completion_client,\n",
    "    description=\"An agent that can search Arxiv for papers related to a given topic, including abstracts\",\n",
    "    system_message=\"You are a helpful AI assistant. Solve tasks using your tools. Specifically, you can take into consideration the user's request and craft a search query that is most likely to return relevant academi papers.\",\n",
    ")\n",
    "\n",
    "\n",
    "report_agent = AssistantAgent(\n",
    "    name=\"Report_Agent\",\n",
    "    model_client=azure_openai_chat_completion_client,\n",
    "    description=\"Generate a report based on a given topic\",\n",
    "    system_message=\"You are a helpful assistant. Your task is to synthesize data extracted into a high quality literature review including CORRECT references. You MUST write a final report that is formatted as a literature review with CORRECT references.  Your response should end with the word 'TERMINATE'\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "termination = TextMentionTermination(\"TERMINATE\")\n",
    "team = RoundRobinGroupChat(\n",
    "    participants=[google_search_agent, arxiv_search_agent, report_agent], termination_condition=termination\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "최신 RAG 기술에 대한 동향 및 논문 리뷰\n",
      "---------- Google_Search_Agent ----------\n",
      "[FunctionCall(id='call_oodSiHoLpMdeejXJ8c3YnRSU', arguments='{\"query\":\"최신 RAG(지식 증강 생성) 기술 동향 2023\",\"num_results\":3}', name='google_search')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andy/works/ai/autogen04-sample/.venv/lib/python3.11/site-packages/autogen_agentchat/agents/_assistant_agent.py:870: UserWarning: Resolved model mismatch: gpt-4o-2024-08-06 != gpt-4o-2024-11-20. Model mapping in autogen_ext.models.openai may be incorrect. Set the model to gpt-4o-2024-11-20 to enhance token/cost estimation and suppress this warning.\n",
      "  model_result = await model_client.create(\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': '2024 Year Of The RAG :: RAG가 주목 받는 이유와 미래 동향', 'link': 'https://www.skelterlabs.com/blog/2024-year-of-the-rag', 'snippet': 'RAG가 급부상하면서 고객 지원부터 직원 생산성, AI 워크플로우 강화에 이르기까지 다양한 영역에서 기업과 소비자 모두에게 상당한 수익과 생산성 향상을 가져올 것으로 ...', 'body': '2024 Year Of The RAG :: RAG가 주목 받는 이유와 미래 동향 Company Gen ai Offerings AI Agent 를 활용한 비즈니스 자동화 기업의 복잡한 업무를 독립적으로 수행하는 AI Agent 모델을 구축합니다. RAG 기반 맞춤형 챗봇 등 애플리케이션 개발 RAG 기술로 할루시네이션을 제어하고, 기업 데이터 기반으로 동작해 정확도와 효율을 극대화합니다. Private Data 기반, 기업에 꼭 맞는 LLM 모델 구축 모델 학습에 기업 데이터를 활용해 보안성과 성능을 모두 갖춘 기업향 LLM 모델을 구축합니다. 대고객용 노코드 AI 챗봇 빌더 구축 및 운영 지원 코딩 없이 구축 가능한 AI 챗봇으로, 신속한 고객 응대를 통해 비즈니스 민첩성을 강화합니다. AI 컨택센터 구축을 위한 실시간 STT 및 TTS 모델 제공 한국어 특화 음성 인식과 자연스러운 음성 합성 기술로 고객 커뮤니케이션을 지원합니다. USECASE Newsroom Blog'}, {'title': '검색증강생성(RAG) 기술의 등장과 발전 동향', 'link': 'https://www.nia.or.kr/common/board/Download.do?bcIdx=27539&cbIdx=82618&fileNo=1', 'snippet': 'RAG는 LLM의 강력한 텍스트 생성 능력과 외부 지식 베이스를 결합한 혁신적인 접근 방식이다. 이 기술은 최신 정보를 실시간으로 검색하고 활용할 수 있어 ...', 'body': \"%PDF-1.4 %���� 10 0 obj << /Type /Page /Parent 1 0 R /MediaBox [ 0 0 532 745 ] /TrimBox [ 0 0 532 745 ] /BleedBox [ 0 0 532 745 ] /Resources 9 0 R /Contents 16 0 R >> endobj 16 0 obj << /Length 17 0 R /Filter /FlateDecode >> stream x��VMk�0\\x10��W�\\\\��ѷ��P��\\x06z(5�\\x10rH�ݖ����\\x04��;����5&�dac0;��\\x19�{�vG8�J�-�RDk\\x13-�@����/�� �'_�\\uee00 ��4\\x05 �w[r�i �� �6�;:�\\x10 �@LR�<3\\\\`���I� �\\x19\\x11#�T�H�*H)\\x13_\\x01�z\\x19k��!��%\\x03���O�'\\x17 ��д_\\x13A��T0M \\x080 /�ujteMX|q� ��o��[4d\\x00���5��\\x03�f�W� ��}\\x15:S�6��W�Ob\\x17���f�\\x15�\\x02��Y �Q�\\x04 �KU��i�zH#��\"}, {'title': '[한국지능정보사회진흥원] 검색증강생성(RAG) 기술의 등장 ...', 'link': 'https://keia.kr/main/board/20/18545/board_view.do?cp=13', 'snippet': 'RAG 기술의 등장은 LLM의 한계를 극복하고 AI의 활용 범위를 확장하는 중요한 전환점이 되었다. RAG는 실시간 데이터를 활용하여 정확성과 최신성을 높이는 동시에, LLM의 ...', 'body': '홈 > 회원사서비스 > 최신기술동향 메뉴 바로가기 본문 바로가기 검색 검색 로그인 회원가입 EN CH 협회소개 KEIA 소개 회장인사말 조직도 연락처 및 약도 회원사서비스 회원사 가입안내 회원사 현황 회원사 서비스 안내 회원사 동정 최신기술동향 주요사업 환경산업 육성 지원 해외진출 지원 녹색산업 정보제공 제도개선 및 교류 지원 알림마당 공지사항 협회뉴스 환경산업정보 환경기업소개 신청·입력·조회 지원사업 신청 전시회 및 행사 신청 환경전문공사업 수주실적 환경DB검색 환경기술, 제품 검색 환경분야 소·부·장 정보 환경산업체 검색 환경컨설팅 검색 해외기업 검색 전체메뉴 전체메뉴 닫기 상단영역 최신기술동향 메인 회원사서비스 협회소개 회원사서비스 주요사업 알림마당 신청·입력·조회 환경DB검색 최신기술동향 회원사 가입안내 회원사 현황 회원사 서비스 안내 회원사 동정 최신기술동향 게시판 상세보기 [한국지능정보사회진흥원] 검색증강생성(RAG) 기술의 등장과 발전 동향 한국환경산업협회'}]\n",
      "---------- Google_Search_Agent ----------\n",
      "[FunctionExecutionResult(content='[{\\'title\\': \\'2024 Year Of The RAG :: RAG가 주목 받는 이유와 미래 동향\\', \\'link\\': \\'https://www.skelterlabs.com/blog/2024-year-of-the-rag\\', \\'snippet\\': \\'RAG가 급부상하면서 고객 지원부터 직원 생산성, AI 워크플로우 강화에 이르기까지 다양한 영역에서 기업과 소비자 모두에게 상당한 수익과 생산성 향상을 가져올 것으로 ...\\', \\'body\\': \\'2024 Year Of The RAG :: RAG가 주목 받는 이유와 미래 동향 Company Gen ai Offerings AI Agent 를 활용한 비즈니스 자동화 기업의 복잡한 업무를 독립적으로 수행하는 AI Agent 모델을 구축합니다. RAG 기반 맞춤형 챗봇 등 애플리케이션 개발 RAG 기술로 할루시네이션을 제어하고, 기업 데이터 기반으로 동작해 정확도와 효율을 극대화합니다. Private Data 기반, 기업에 꼭 맞는 LLM 모델 구축 모델 학습에 기업 데이터를 활용해 보안성과 성능을 모두 갖춘 기업향 LLM 모델을 구축합니다. 대고객용 노코드 AI 챗봇 빌더 구축 및 운영 지원 코딩 없이 구축 가능한 AI 챗봇으로, 신속한 고객 응대를 통해 비즈니스 민첩성을 강화합니다. AI 컨택센터 구축을 위한 실시간 STT 및 TTS 모델 제공 한국어 특화 음성 인식과 자연스러운 음성 합성 기술로 고객 커뮤니케이션을 지원합니다. USECASE Newsroom Blog\\'}, {\\'title\\': \\'검색증강생성(RAG) 기술의 등장과 발전 동향\\', \\'link\\': \\'https://www.nia.or.kr/common/board/Download.do?bcIdx=27539&cbIdx=82618&fileNo=1\\', \\'snippet\\': \\'RAG는 LLM의 강력한 텍스트 생성 능력과 외부 지식 베이스를 결합한 혁신적인 접근 방식이다. 이 기술은 최신 정보를 실시간으로 검색하고 활용할 수 있어 ...\\', \\'body\\': \"%PDF-1.4 %���� 10 0 obj << /Type /Page /Parent 1 0 R /MediaBox [ 0 0 532 745 ] /TrimBox [ 0 0 532 745 ] /BleedBox [ 0 0 532 745 ] /Resources 9 0 R /Contents 16 0 R >> endobj 16 0 obj << /Length 17 0 R /Filter /FlateDecode >> stream x��VMk�0\\\\x10��W�\\\\\\\\��ѷ��P��\\\\x06z(5�\\\\x10rH�ݖ����\\\\x04��;����5&�dac0;��\\\\x19�{�vG8�J�-�RDk\\\\x13-�@����/�� �\\'_�\\\\uee00 ��4\\\\x05 �w[r�i �� �6�;:�\\\\x10 �@LR�<3\\\\\\\\`���I� �\\\\x19\\\\x11#�T�H�*H)\\\\x13_\\\\x01�z\\\\x19k��!��%\\\\x03���O�\\'\\\\x17 ��д_\\\\x13A��T0M \\\\x080 /�ujteMX|q� ��o��[4d\\\\x00���5��\\\\x03�f�W� ��}\\\\x15:S�6��W�Ob\\\\x17���f�\\\\x15�\\\\x02��Y �Q�\\\\x04 �KU��i�zH#��\"}, {\\'title\\': \\'[한국지능정보사회진흥원] 검색증강생성(RAG) 기술의 등장 ...\\', \\'link\\': \\'https://keia.kr/main/board/20/18545/board_view.do?cp=13\\', \\'snippet\\': \\'RAG 기술의 등장은 LLM의 한계를 극복하고 AI의 활용 범위를 확장하는 중요한 전환점이 되었다. RAG는 실시간 데이터를 활용하여 정확성과 최신성을 높이는 동시에, LLM의 ...\\', \\'body\\': \\'홈 > 회원사서비스 > 최신기술동향 메뉴 바로가기 본문 바로가기 검색 검색 로그인 회원가입 EN CH 협회소개 KEIA 소개 회장인사말 조직도 연락처 및 약도 회원사서비스 회원사 가입안내 회원사 현황 회원사 서비스 안내 회원사 동정 최신기술동향 주요사업 환경산업 육성 지원 해외진출 지원 녹색산업 정보제공 제도개선 및 교류 지원 알림마당 공지사항 협회뉴스 환경산업정보 환경기업소개 신청·입력·조회 지원사업 신청 전시회 및 행사 신청 환경전문공사업 수주실적 환경DB검색 환경기술, 제품 검색 환경분야 소·부·장 정보 환경산업체 검색 환경컨설팅 검색 해외기업 검색 전체메뉴 전체메뉴 닫기 상단영역 최신기술동향 메인 회원사서비스 협회소개 회원사서비스 주요사업 알림마당 신청·입력·조회 환경DB검색 최신기술동향 회원사 가입안내 회원사 현황 회원사 서비스 안내 회원사 동정 최신기술동향 게시판 상세보기 [한국지능정보사회진흥원] 검색증강생성(RAG) 기술의 등장과 발전 동향 한국환경산업협회\\'}]', name='google_search', call_id='call_oodSiHoLpMdeejXJ8c3YnRSU', is_error=False)]\n",
      "---------- Google_Search_Agent ----------\n",
      "[{'title': '2024 Year Of The RAG :: RAG가 주목 받는 이유와 미래 동향', 'link': 'https://www.skelterlabs.com/blog/2024-year-of-the-rag', 'snippet': 'RAG가 급부상하면서 고객 지원부터 직원 생산성, AI 워크플로우 강화에 이르기까지 다양한 영역에서 기업과 소비자 모두에게 상당한 수익과 생산성 향상을 가져올 것으로 ...', 'body': '2024 Year Of The RAG :: RAG가 주목 받는 이유와 미래 동향 Company Gen ai Offerings AI Agent 를 활용한 비즈니스 자동화 기업의 복잡한 업무를 독립적으로 수행하는 AI Agent 모델을 구축합니다. RAG 기반 맞춤형 챗봇 등 애플리케이션 개발 RAG 기술로 할루시네이션을 제어하고, 기업 데이터 기반으로 동작해 정확도와 효율을 극대화합니다. Private Data 기반, 기업에 꼭 맞는 LLM 모델 구축 모델 학습에 기업 데이터를 활용해 보안성과 성능을 모두 갖춘 기업향 LLM 모델을 구축합니다. 대고객용 노코드 AI 챗봇 빌더 구축 및 운영 지원 코딩 없이 구축 가능한 AI 챗봇으로, 신속한 고객 응대를 통해 비즈니스 민첩성을 강화합니다. AI 컨택센터 구축을 위한 실시간 STT 및 TTS 모델 제공 한국어 특화 음성 인식과 자연스러운 음성 합성 기술로 고객 커뮤니케이션을 지원합니다. USECASE Newsroom Blog'}, {'title': '검색증강생성(RAG) 기술의 등장과 발전 동향', 'link': 'https://www.nia.or.kr/common/board/Download.do?bcIdx=27539&cbIdx=82618&fileNo=1', 'snippet': 'RAG는 LLM의 강력한 텍스트 생성 능력과 외부 지식 베이스를 결합한 혁신적인 접근 방식이다. 이 기술은 최신 정보를 실시간으로 검색하고 활용할 수 있어 ...', 'body': \"%PDF-1.4 %���� 10 0 obj << /Type /Page /Parent 1 0 R /MediaBox [ 0 0 532 745 ] /TrimBox [ 0 0 532 745 ] /BleedBox [ 0 0 532 745 ] /Resources 9 0 R /Contents 16 0 R >> endobj 16 0 obj << /Length 17 0 R /Filter /FlateDecode >> stream x��VMk�0\\x10��W�\\\\��ѷ��P��\\x06z(5�\\x10rH�ݖ����\\x04��;����5&�dac0;��\\x19�{�vG8�J�-�RDk\\x13-�@����/�� �'_�\\uee00 ��4\\x05 �w[r�i �� �6�;:�\\x10 �@LR�<3\\\\`���I� �\\x19\\x11#�T�H�*H)\\x13_\\x01�z\\x19k��!��%\\x03���O�'\\x17 ��д_\\x13A��T0M \\x080 /�ujteMX|q� ��o��[4d\\x00���5��\\x03�f�W� ��}\\x15:S�6��W�Ob\\x17���f�\\x15�\\x02��Y �Q�\\x04 �KU��i�zH#��\"}, {'title': '[한국지능정보사회진흥원] 검색증강생성(RAG) 기술의 등장 ...', 'link': 'https://keia.kr/main/board/20/18545/board_view.do?cp=13', 'snippet': 'RAG 기술의 등장은 LLM의 한계를 극복하고 AI의 활용 범위를 확장하는 중요한 전환점이 되었다. RAG는 실시간 데이터를 활용하여 정확성과 최신성을 높이는 동시에, LLM의 ...', 'body': '홈 > 회원사서비스 > 최신기술동향 메뉴 바로가기 본문 바로가기 검색 검색 로그인 회원가입 EN CH 협회소개 KEIA 소개 회장인사말 조직도 연락처 및 약도 회원사서비스 회원사 가입안내 회원사 현황 회원사 서비스 안내 회원사 동정 최신기술동향 주요사업 환경산업 육성 지원 해외진출 지원 녹색산업 정보제공 제도개선 및 교류 지원 알림마당 공지사항 협회뉴스 환경산업정보 환경기업소개 신청·입력·조회 지원사업 신청 전시회 및 행사 신청 환경전문공사업 수주실적 환경DB검색 환경기술, 제품 검색 환경분야 소·부·장 정보 환경산업체 검색 환경컨설팅 검색 해외기업 검색 전체메뉴 전체메뉴 닫기 상단영역 최신기술동향 메인 회원사서비스 협회소개 회원사서비스 주요사업 알림마당 신청·입력·조회 환경DB검색 최신기술동향 회원사 가입안내 회원사 현황 회원사 서비스 안내 회원사 동정 최신기술동향 게시판 상세보기 [한국지능정보사회진흥원] 검색증강생성(RAG) 기술의 등장과 발전 동향 한국환경산업협회'}]\n",
      "---------- Arxiv_Search_Agent ----------\n",
      "[FunctionCall(id='call_sMKOchAl6IS3gdgJP9TlKLQV', arguments='{\"query\":\"Recent advancements in retrieval-augmented generation (RAG)\",\"max_results\":2}', name='arxiv_search')]\n",
      "[{'title': 'Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks', 'authors': ['Yunfan Gao', 'Yun Xiong', 'Meng Wang', 'Haofen Wang'], 'published': '2024-07-26', 'abstract': 'Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\\nof Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\\nincreasing demands of application scenarios have driven the evolution of RAG,\\nleading to the integration of advanced retrievers, LLMs and other complementary\\ntechnologies, which in turn has amplified the intricacy of RAG systems.\\nHowever, the rapid advancements are outpacing the foundational RAG paradigm,\\nwith many methods struggling to be unified under the process of\\n\"retrieve-then-generate\". In this context, this paper examines the limitations\\nof the existing RAG paradigm and introduces the modular RAG framework. By\\ndecomposing complex RAG systems into independent modules and specialized\\noperators, it facilitates a highly reconfigurable framework. Modular RAG\\ntranscends the traditional linear architecture, embracing a more advanced\\ndesign that integrates routing, scheduling, and fusion mechanisms. Drawing on\\nextensive research, this paper further identifies prevalent RAG\\npatterns-linear, conditional, branching, and looping-and offers a comprehensive\\nanalysis of their respective implementation nuances. Modular RAG presents\\ninnovative opportunities for the conceptualization and deployment of RAG\\nsystems. Finally, the paper explores the potential emergence of new operators\\nand paradigms, establishing a solid theoretical foundation and a practical\\nroadmap for the continued evolution and practical deployment of RAG\\ntechnologies.', 'pdf_url': 'http://arxiv.org/pdf/2407.21059v1'}, {'title': 'Toward General Instruction-Following Alignment for Retrieval-Augmented Generation', 'authors': ['Guanting Dong', 'Xiaoshuai Song', 'Yutao Zhu', 'Runqi Qiao', 'Zhicheng Dou', 'Ji-Rong Wen'], 'published': '2024-10-12', 'abstract': 'Following natural instructions is crucial for the effective application of\\nRetrieval-Augmented Generation (RAG) systems. Despite recent advancements in\\nLarge Language Models (LLMs), research on assessing and improving\\ninstruction-following (IF) alignment within the RAG domain remains limited. To\\naddress this issue, we propose VIF-RAG, the first automated, scalable, and\\nverifiable synthetic pipeline for instruction-following alignment in RAG\\nsystems. We start by manually crafting a minimal set of atomic instructions\\n(<100) and developing combination rules to synthesize and verify complex\\ninstructions for a seed set. We then use supervised models for instruction\\nrewriting while simultaneously generating code to automate the verification of\\ninstruction quality via a Python executor. Finally, we integrate these\\ninstructions with extensive RAG and general data samples, scaling up to a\\nhigh-quality VIF-RAG-QA dataset (>100k) through automated processes. To further\\nbridge the gap in instruction-following auto-evaluation for RAG systems, we\\nintroduce FollowRAG Benchmark, which includes approximately 3K test samples,\\ncovering 22 categories of general instruction constraints and four\\nknowledge-intensive QA datasets. Due to its robust pipeline design, FollowRAG\\ncan seamlessly integrate with different RAG benchmarks. Using FollowRAG and\\neight widely-used IF and foundational abilities benchmarks for LLMs, we\\ndemonstrate that VIF-RAG markedly enhances LLM performance across a broad range\\nof general instruction constraints while effectively leveraging its\\ncapabilities in RAG scenarios. Further analysis offers practical insights for\\nachieving IF alignment in RAG systems. Our code and datasets are released at\\nhttps://FollowRAG.github.io.', 'pdf_url': 'http://arxiv.org/pdf/2410.09584v1'}]\n",
      "---------- Arxiv_Search_Agent ----------\n",
      "[FunctionExecutionResult(content='[{\\'title\\': \\'Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks\\', \\'authors\\': [\\'Yunfan Gao\\', \\'Yun Xiong\\', \\'Meng Wang\\', \\'Haofen Wang\\'], \\'published\\': \\'2024-07-26\\', \\'abstract\\': \\'Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\\\\nof Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\\\\nincreasing demands of application scenarios have driven the evolution of RAG,\\\\nleading to the integration of advanced retrievers, LLMs and other complementary\\\\ntechnologies, which in turn has amplified the intricacy of RAG systems.\\\\nHowever, the rapid advancements are outpacing the foundational RAG paradigm,\\\\nwith many methods struggling to be unified under the process of\\\\n\"retrieve-then-generate\". In this context, this paper examines the limitations\\\\nof the existing RAG paradigm and introduces the modular RAG framework. By\\\\ndecomposing complex RAG systems into independent modules and specialized\\\\noperators, it facilitates a highly reconfigurable framework. Modular RAG\\\\ntranscends the traditional linear architecture, embracing a more advanced\\\\ndesign that integrates routing, scheduling, and fusion mechanisms. Drawing on\\\\nextensive research, this paper further identifies prevalent RAG\\\\npatterns-linear, conditional, branching, and looping-and offers a comprehensive\\\\nanalysis of their respective implementation nuances. Modular RAG presents\\\\ninnovative opportunities for the conceptualization and deployment of RAG\\\\nsystems. Finally, the paper explores the potential emergence of new operators\\\\nand paradigms, establishing a solid theoretical foundation and a practical\\\\nroadmap for the continued evolution and practical deployment of RAG\\\\ntechnologies.\\', \\'pdf_url\\': \\'http://arxiv.org/pdf/2407.21059v1\\'}, {\\'title\\': \\'Toward General Instruction-Following Alignment for Retrieval-Augmented Generation\\', \\'authors\\': [\\'Guanting Dong\\', \\'Xiaoshuai Song\\', \\'Yutao Zhu\\', \\'Runqi Qiao\\', \\'Zhicheng Dou\\', \\'Ji-Rong Wen\\'], \\'published\\': \\'2024-10-12\\', \\'abstract\\': \\'Following natural instructions is crucial for the effective application of\\\\nRetrieval-Augmented Generation (RAG) systems. Despite recent advancements in\\\\nLarge Language Models (LLMs), research on assessing and improving\\\\ninstruction-following (IF) alignment within the RAG domain remains limited. To\\\\naddress this issue, we propose VIF-RAG, the first automated, scalable, and\\\\nverifiable synthetic pipeline for instruction-following alignment in RAG\\\\nsystems. We start by manually crafting a minimal set of atomic instructions\\\\n(<100) and developing combination rules to synthesize and verify complex\\\\ninstructions for a seed set. We then use supervised models for instruction\\\\nrewriting while simultaneously generating code to automate the verification of\\\\ninstruction quality via a Python executor. Finally, we integrate these\\\\ninstructions with extensive RAG and general data samples, scaling up to a\\\\nhigh-quality VIF-RAG-QA dataset (>100k) through automated processes. To further\\\\nbridge the gap in instruction-following auto-evaluation for RAG systems, we\\\\nintroduce FollowRAG Benchmark, which includes approximately 3K test samples,\\\\ncovering 22 categories of general instruction constraints and four\\\\nknowledge-intensive QA datasets. Due to its robust pipeline design, FollowRAG\\\\ncan seamlessly integrate with different RAG benchmarks. Using FollowRAG and\\\\neight widely-used IF and foundational abilities benchmarks for LLMs, we\\\\ndemonstrate that VIF-RAG markedly enhances LLM performance across a broad range\\\\nof general instruction constraints while effectively leveraging its\\\\ncapabilities in RAG scenarios. Further analysis offers practical insights for\\\\nachieving IF alignment in RAG systems. Our code and datasets are released at\\\\nhttps://FollowRAG.github.io.\\', \\'pdf_url\\': \\'http://arxiv.org/pdf/2410.09584v1\\'}]', name='arxiv_search', call_id='call_sMKOchAl6IS3gdgJP9TlKLQV', is_error=False)]\n",
      "---------- Arxiv_Search_Agent ----------\n",
      "[{'title': 'Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks', 'authors': ['Yunfan Gao', 'Yun Xiong', 'Meng Wang', 'Haofen Wang'], 'published': '2024-07-26', 'abstract': 'Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\\nof Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\\nincreasing demands of application scenarios have driven the evolution of RAG,\\nleading to the integration of advanced retrievers, LLMs and other complementary\\ntechnologies, which in turn has amplified the intricacy of RAG systems.\\nHowever, the rapid advancements are outpacing the foundational RAG paradigm,\\nwith many methods struggling to be unified under the process of\\n\"retrieve-then-generate\". In this context, this paper examines the limitations\\nof the existing RAG paradigm and introduces the modular RAG framework. By\\ndecomposing complex RAG systems into independent modules and specialized\\noperators, it facilitates a highly reconfigurable framework. Modular RAG\\ntranscends the traditional linear architecture, embracing a more advanced\\ndesign that integrates routing, scheduling, and fusion mechanisms. Drawing on\\nextensive research, this paper further identifies prevalent RAG\\npatterns-linear, conditional, branching, and looping-and offers a comprehensive\\nanalysis of their respective implementation nuances. Modular RAG presents\\ninnovative opportunities for the conceptualization and deployment of RAG\\nsystems. Finally, the paper explores the potential emergence of new operators\\nand paradigms, establishing a solid theoretical foundation and a practical\\nroadmap for the continued evolution and practical deployment of RAG\\ntechnologies.', 'pdf_url': 'http://arxiv.org/pdf/2407.21059v1'}, {'title': 'Toward General Instruction-Following Alignment for Retrieval-Augmented Generation', 'authors': ['Guanting Dong', 'Xiaoshuai Song', 'Yutao Zhu', 'Runqi Qiao', 'Zhicheng Dou', 'Ji-Rong Wen'], 'published': '2024-10-12', 'abstract': 'Following natural instructions is crucial for the effective application of\\nRetrieval-Augmented Generation (RAG) systems. Despite recent advancements in\\nLarge Language Models (LLMs), research on assessing and improving\\ninstruction-following (IF) alignment within the RAG domain remains limited. To\\naddress this issue, we propose VIF-RAG, the first automated, scalable, and\\nverifiable synthetic pipeline for instruction-following alignment in RAG\\nsystems. We start by manually crafting a minimal set of atomic instructions\\n(<100) and developing combination rules to synthesize and verify complex\\ninstructions for a seed set. We then use supervised models for instruction\\nrewriting while simultaneously generating code to automate the verification of\\ninstruction quality via a Python executor. Finally, we integrate these\\ninstructions with extensive RAG and general data samples, scaling up to a\\nhigh-quality VIF-RAG-QA dataset (>100k) through automated processes. To further\\nbridge the gap in instruction-following auto-evaluation for RAG systems, we\\nintroduce FollowRAG Benchmark, which includes approximately 3K test samples,\\ncovering 22 categories of general instruction constraints and four\\nknowledge-intensive QA datasets. Due to its robust pipeline design, FollowRAG\\ncan seamlessly integrate with different RAG benchmarks. Using FollowRAG and\\neight widely-used IF and foundational abilities benchmarks for LLMs, we\\ndemonstrate that VIF-RAG markedly enhances LLM performance across a broad range\\nof general instruction constraints while effectively leveraging its\\ncapabilities in RAG scenarios. Further analysis offers practical insights for\\nachieving IF alignment in RAG systems. Our code and datasets are released at\\nhttps://FollowRAG.github.io.', 'pdf_url': 'http://arxiv.org/pdf/2410.09584v1'}]\n",
      "---------- Report_Agent ----------\n",
      "# Literature Review: Current Trends and Advances in Retrieval-Augmented Generation (RAG)\n",
      "\n",
      "## 1. Introduction to RAG\n",
      "Retrieval-Augmented Generation (RAG) integrates the strengths of retrieval systems and generative models (typically Large Language Models, LLMs) to address knowledge-intensive tasks. This hybrid architecture allows RAG systems to fetch relevant external knowledge bases or documents and refine contextually accurate outputs through their generative components. RAG is particularly relevant for scenarios requiring real-time information retrieval or highly domain-specific responses—tasks often challenging for standalone LLMs due to their static knowledge and \"hallucination\" tendencies (Dong et al., 2024; Gao et al., 2024).\n",
      "\n",
      "The concept has gained substantial traction across industries, finding applications in customer support automation, knowledge management systems, and even customized corporate natural language interfaces. The synergy of retrieval and generation opens up transformative possibilities for ensuring more accurate, relevant, and dynamic responses in interactions (Skelter Labs, 2024; NIA, 2024).\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Technological Evolution of RAG\n",
      "\n",
      "### 2.1 Modularity in RAG Systems\n",
      "Recent advancements in RAG architectures emphasize modularity, allowing task-specific customization and reconfigurability. For instance, Gao et al. (2024) propose \"Modular RAG,\" which moves beyond linear retrieve-then-generate paradigms by decomposing RAG systems into independent modules. This approach introduces novel routing, scheduling, and fusion mechanisms, facilitating more complex workflows, including conditional retrieval and looping processes.\n",
      "\n",
      "Modular RAG aligns with emerging needs for scalability, efficiency, and adaptability in enterprise AI deployments. Tasks such as decision-making automation benefit from these modular frameworks, which offer dynamic operators and flexible patterns like branching and fusion (Gao et al., 2024).\n",
      "\n",
      "### 2.2 Instruction-Following Alignment in RAG\n",
      "Another critical limitation in many RAG systems is the often-suboptimal alignment of generative outputs with user intentions or given instructions. Addressing this, Dong et al. (2024) introduce VIF-RAG—a pipeline engineered to ensure robust instruction-following (IF) capabilities. They manually design atomic instruction sets and merge them with automated verification and combination mechanisms. This creates a scalable framework capable of synthesizing complex instructions for training RAG models.\n",
      "\n",
      "The proposed FollowRAG benchmark (Dong et al., 2024) pushes these endeavors further by offering a dataset specifically crafted to evaluate compliance with diverse user instructions across multiple categories. This benchmark demonstrates how improving instruction-following alignment significantly enhances RAG's performance across knowledge-intensive domains.\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Practical Applications\n",
      "\n",
      "### 3.1 Reducing Hallucination for Domain-Specific Tasks\n",
      "Corporate environments often rely on LLMs for creating tailored chatbot solutions. Here, RAG next-gen systems, which leverage retrievals from private or enterprise environments, effectively mitigate hallucinations while maintaining contextual accuracy. Skelter Labs (2024) highlights how integrating RAG into customer service workflows offers real-time querying capabilities embedded with domain-specific insights—thus aligning database fidelity with natural user inquiries.\n",
      "\n",
      "### 3.2 Realtime Knowledge Base Integration\n",
      "RAG enriches applications requiring live information retrieval. In scenarios such as financial reporting or technical troubleshooting, RAG’s retrieval components can access updated databases or APIs, ensuring generative outputs remain highly relevant and recent (NIA, 2024). This transformation significantly improves LLM deficiencies in rapidly changing disciplines.\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Challenges and Research Opportunities\n",
      "\n",
      "### 4.1 Scalability Issues in Large Datasets\n",
      "Although RAG systems promise high accuracy, training them with large and ever-expanding datasets raises storage and computational complexity challenges. As detailed by Gao et al. (2024), modular systems might offer partial relief via more streamlined architectures.\n",
      "\n",
      "### 4.2 Instruction-Generalization Problems\n",
      "Ensuring instruction-following robustness across varying user contexts is another open research area. While works such as Dong et al. (2024) provide scalable results for instruction-following refinement, further improvements in the blend of supervised learning and synthetic pipelines remain critical to generalizing performance.\n",
      "\n",
      "---\n",
      "\n",
      "## 5. Future Directions\n",
      "\n",
      "### 5.1 Towards Unified Architectures\n",
      "The fragmentation between retrieval engines and generative modules suggests the need for unified RAG architectures capable of embedding adaptability within a single pipeline (Gao et al., 2024).\n",
      "\n",
      "### 5.2 Expanding Instruction Benchmarks\n",
      "Efforts like FollowRAG (Dong et al., 2024) should expand to non-textual domains, addressing diverse multimodal input-output constraints.\n",
      "\n",
      "### 5.3 Socio-Technical Integration\n",
      "Finally, increasing RAG’s adoption in diverse fields will require bridging technical capabilities with ethical and operational considerations, especially for sensitive applications such as healthcare or defense (Skelter Labs, 2024).\n",
      "\n",
      "---\n",
      "\n",
      "## 6. Conclusion\n",
      "RAG embodies a promising methodology for augmenting LLMs with external knowledge, ensuring heightened performance in dynamic and domain-intensive contexts. With advances in modular construction and instruction-following refinement, RAG continues to expand its relevance across enterprise AI, customer interaction systems, and knowledge retrieval domains. As researchers tackle scalability and context alignment challenges, RAG is poised to redefine intelligent system designs for the future.\n",
      "\n",
      "---\n",
      "\n",
      "### References\n",
      "1. Gao, Y., Xiong, Y., Wang, M., & Wang, H. (2024). Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks. Retrieved from [http://arxiv.org/pdf/2407.21059v1](http://arxiv.org/pdf/2407.21059v1)\n",
      "2. Dong, G., Song, X., Zhu, Y., Qiao, R., Dou, Z., & Wen, J.-R. (2024). Toward General Instruction-Following Alignment for Retrieval-Augmented Generation. Retrieved from [http://arxiv.org/pdf/2410.09584v1](http://arxiv.org/pdf/2410.09584v1)\n",
      "3. Skelter Labs. (2024). 2024 Year Of The RAG: RAG Technology Trends and Use Cases. Retrieved from [https://www.skelterlabs.com/blog/2024-year-of-the-rag](https://www.skelterlabs.com/blog/2024-year-of-the-rag)\n",
      "4. NIA. (2024). 검색증강생성(RAG) 기술의 등장과 발전 동향. Retrieved from [https://www.nia.or.kr/common/board/Download.do?bcIdx=27539&cbIdx=82618&fileNo=1](https://www.nia.or.kr/common/board/Download.do?bcIdx=27539&cbIdx=82618&fileNo=1)\n",
      "\n",
      "TERMINATE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, metadata={}, content='최신 RAG 기술에 대한 동향 및 논문 리뷰', type='TextMessage'), ToolCallRequestEvent(source='Google_Search_Agent', models_usage=RequestUsage(prompt_tokens=122, completion_tokens=36), metadata={}, content=[FunctionCall(id='call_oodSiHoLpMdeejXJ8c3YnRSU', arguments='{\"query\":\"최신 RAG(지식 증강 생성) 기술 동향 2023\",\"num_results\":3}', name='google_search')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='Google_Search_Agent', models_usage=None, metadata={}, content=[FunctionExecutionResult(content='[{\\'title\\': \\'2024 Year Of The RAG :: RAG가 주목 받는 이유와 미래 동향\\', \\'link\\': \\'https://www.skelterlabs.com/blog/2024-year-of-the-rag\\', \\'snippet\\': \\'RAG가 급부상하면서 고객 지원부터 직원 생산성, AI 워크플로우 강화에 이르기까지 다양한 영역에서 기업과 소비자 모두에게 상당한 수익과 생산성 향상을 가져올 것으로 ...\\', \\'body\\': \\'2024 Year Of The RAG :: RAG가 주목 받는 이유와 미래 동향 Company Gen ai Offerings AI Agent 를 활용한 비즈니스 자동화 기업의 복잡한 업무를 독립적으로 수행하는 AI Agent 모델을 구축합니다. RAG 기반 맞춤형 챗봇 등 애플리케이션 개발 RAG 기술로 할루시네이션을 제어하고, 기업 데이터 기반으로 동작해 정확도와 효율을 극대화합니다. Private Data 기반, 기업에 꼭 맞는 LLM 모델 구축 모델 학습에 기업 데이터를 활용해 보안성과 성능을 모두 갖춘 기업향 LLM 모델을 구축합니다. 대고객용 노코드 AI 챗봇 빌더 구축 및 운영 지원 코딩 없이 구축 가능한 AI 챗봇으로, 신속한 고객 응대를 통해 비즈니스 민첩성을 강화합니다. AI 컨택센터 구축을 위한 실시간 STT 및 TTS 모델 제공 한국어 특화 음성 인식과 자연스러운 음성 합성 기술로 고객 커뮤니케이션을 지원합니다. USECASE Newsroom Blog\\'}, {\\'title\\': \\'검색증강생성(RAG) 기술의 등장과 발전 동향\\', \\'link\\': \\'https://www.nia.or.kr/common/board/Download.do?bcIdx=27539&cbIdx=82618&fileNo=1\\', \\'snippet\\': \\'RAG는 LLM의 강력한 텍스트 생성 능력과 외부 지식 베이스를 결합한 혁신적인 접근 방식이다. 이 기술은 최신 정보를 실시간으로 검색하고 활용할 수 있어 ...\\', \\'body\\': \"%PDF-1.4 %���� 10 0 obj << /Type /Page /Parent 1 0 R /MediaBox [ 0 0 532 745 ] /TrimBox [ 0 0 532 745 ] /BleedBox [ 0 0 532 745 ] /Resources 9 0 R /Contents 16 0 R >> endobj 16 0 obj << /Length 17 0 R /Filter /FlateDecode >> stream x��VMk�0\\\\x10��W�\\\\\\\\��ѷ��P��\\\\x06z(5�\\\\x10rH�ݖ����\\\\x04��;����5&�dac0;��\\\\x19�{�vG8�J�-�RDk\\\\x13-�@����/�� �\\'_�\\\\uee00 ��4\\\\x05 �w[r�i �� �6�;:�\\\\x10 �@LR�<3\\\\\\\\`���I� �\\\\x19\\\\x11#�T�H�*H)\\\\x13_\\\\x01�z\\\\x19k��!��%\\\\x03���O�\\'\\\\x17 ��д_\\\\x13A��T0M \\\\x080 /�ujteMX|q� ��o��[4d\\\\x00���5��\\\\x03�f�W� ��}\\\\x15:S�6��W�Ob\\\\x17���f�\\\\x15�\\\\x02��Y �Q�\\\\x04 �KU��i�zH#��\"}, {\\'title\\': \\'[한국지능정보사회진흥원] 검색증강생성(RAG) 기술의 등장 ...\\', \\'link\\': \\'https://keia.kr/main/board/20/18545/board_view.do?cp=13\\', \\'snippet\\': \\'RAG 기술의 등장은 LLM의 한계를 극복하고 AI의 활용 범위를 확장하는 중요한 전환점이 되었다. RAG는 실시간 데이터를 활용하여 정확성과 최신성을 높이는 동시에, LLM의 ...\\', \\'body\\': \\'홈 > 회원사서비스 > 최신기술동향 메뉴 바로가기 본문 바로가기 검색 검색 로그인 회원가입 EN CH 협회소개 KEIA 소개 회장인사말 조직도 연락처 및 약도 회원사서비스 회원사 가입안내 회원사 현황 회원사 서비스 안내 회원사 동정 최신기술동향 주요사업 환경산업 육성 지원 해외진출 지원 녹색산업 정보제공 제도개선 및 교류 지원 알림마당 공지사항 협회뉴스 환경산업정보 환경기업소개 신청·입력·조회 지원사업 신청 전시회 및 행사 신청 환경전문공사업 수주실적 환경DB검색 환경기술, 제품 검색 환경분야 소·부·장 정보 환경산업체 검색 환경컨설팅 검색 해외기업 검색 전체메뉴 전체메뉴 닫기 상단영역 최신기술동향 메인 회원사서비스 협회소개 회원사서비스 주요사업 알림마당 신청·입력·조회 환경DB검색 최신기술동향 회원사 가입안내 회원사 현황 회원사 서비스 안내 회원사 동정 최신기술동향 게시판 상세보기 [한국지능정보사회진흥원] 검색증강생성(RAG) 기술의 등장과 발전 동향 한국환경산업협회\\'}]', name='google_search', call_id='call_oodSiHoLpMdeejXJ8c3YnRSU', is_error=False)], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='Google_Search_Agent', models_usage=None, metadata={}, content='[{\\'title\\': \\'2024 Year Of The RAG :: RAG가 주목 받는 이유와 미래 동향\\', \\'link\\': \\'https://www.skelterlabs.com/blog/2024-year-of-the-rag\\', \\'snippet\\': \\'RAG가 급부상하면서 고객 지원부터 직원 생산성, AI 워크플로우 강화에 이르기까지 다양한 영역에서 기업과 소비자 모두에게 상당한 수익과 생산성 향상을 가져올 것으로 ...\\', \\'body\\': \\'2024 Year Of The RAG :: RAG가 주목 받는 이유와 미래 동향 Company Gen ai Offerings AI Agent 를 활용한 비즈니스 자동화 기업의 복잡한 업무를 독립적으로 수행하는 AI Agent 모델을 구축합니다. RAG 기반 맞춤형 챗봇 등 애플리케이션 개발 RAG 기술로 할루시네이션을 제어하고, 기업 데이터 기반으로 동작해 정확도와 효율을 극대화합니다. Private Data 기반, 기업에 꼭 맞는 LLM 모델 구축 모델 학습에 기업 데이터를 활용해 보안성과 성능을 모두 갖춘 기업향 LLM 모델을 구축합니다. 대고객용 노코드 AI 챗봇 빌더 구축 및 운영 지원 코딩 없이 구축 가능한 AI 챗봇으로, 신속한 고객 응대를 통해 비즈니스 민첩성을 강화합니다. AI 컨택센터 구축을 위한 실시간 STT 및 TTS 모델 제공 한국어 특화 음성 인식과 자연스러운 음성 합성 기술로 고객 커뮤니케이션을 지원합니다. USECASE Newsroom Blog\\'}, {\\'title\\': \\'검색증강생성(RAG) 기술의 등장과 발전 동향\\', \\'link\\': \\'https://www.nia.or.kr/common/board/Download.do?bcIdx=27539&cbIdx=82618&fileNo=1\\', \\'snippet\\': \\'RAG는 LLM의 강력한 텍스트 생성 능력과 외부 지식 베이스를 결합한 혁신적인 접근 방식이다. 이 기술은 최신 정보를 실시간으로 검색하고 활용할 수 있어 ...\\', \\'body\\': \"%PDF-1.4 %���� 10 0 obj << /Type /Page /Parent 1 0 R /MediaBox [ 0 0 532 745 ] /TrimBox [ 0 0 532 745 ] /BleedBox [ 0 0 532 745 ] /Resources 9 0 R /Contents 16 0 R >> endobj 16 0 obj << /Length 17 0 R /Filter /FlateDecode >> stream x��VMk�0\\\\x10��W�\\\\\\\\��ѷ��P��\\\\x06z(5�\\\\x10rH�ݖ����\\\\x04��;����5&�dac0;��\\\\x19�{�vG8�J�-�RDk\\\\x13-�@����/�� �\\'_�\\\\uee00 ��4\\\\x05 �w[r�i �� �6�;:�\\\\x10 �@LR�<3\\\\\\\\`���I� �\\\\x19\\\\x11#�T�H�*H)\\\\x13_\\\\x01�z\\\\x19k��!��%\\\\x03���O�\\'\\\\x17 ��д_\\\\x13A��T0M \\\\x080 /�ujteMX|q� ��o��[4d\\\\x00���5��\\\\x03�f�W� ��}\\\\x15:S�6��W�Ob\\\\x17���f�\\\\x15�\\\\x02��Y �Q�\\\\x04 �KU��i�zH#��\"}, {\\'title\\': \\'[한국지능정보사회진흥원] 검색증강생성(RAG) 기술의 등장 ...\\', \\'link\\': \\'https://keia.kr/main/board/20/18545/board_view.do?cp=13\\', \\'snippet\\': \\'RAG 기술의 등장은 LLM의 한계를 극복하고 AI의 활용 범위를 확장하는 중요한 전환점이 되었다. RAG는 실시간 데이터를 활용하여 정확성과 최신성을 높이는 동시에, LLM의 ...\\', \\'body\\': \\'홈 > 회원사서비스 > 최신기술동향 메뉴 바로가기 본문 바로가기 검색 검색 로그인 회원가입 EN CH 협회소개 KEIA 소개 회장인사말 조직도 연락처 및 약도 회원사서비스 회원사 가입안내 회원사 현황 회원사 서비스 안내 회원사 동정 최신기술동향 주요사업 환경산업 육성 지원 해외진출 지원 녹색산업 정보제공 제도개선 및 교류 지원 알림마당 공지사항 협회뉴스 환경산업정보 환경기업소개 신청·입력·조회 지원사업 신청 전시회 및 행사 신청 환경전문공사업 수주실적 환경DB검색 환경기술, 제품 검색 환경분야 소·부·장 정보 환경산업체 검색 환경컨설팅 검색 해외기업 검색 전체메뉴 전체메뉴 닫기 상단영역 최신기술동향 메인 회원사서비스 협회소개 회원사서비스 주요사업 알림마당 신청·입력·조회 환경DB검색 최신기술동향 회원사 가입안내 회원사 현황 회원사 서비스 안내 회원사 동정 최신기술동향 게시판 상세보기 [한국지능정보사회진흥원] 검색증강생성(RAG) 기술의 등장과 발전 동향 한국환경산업협회\\'}]', type='ToolCallSummaryMessage'), ToolCallRequestEvent(source='Arxiv_Search_Agent', models_usage=RequestUsage(prompt_tokens=1308, completion_tokens=32), metadata={}, content=[FunctionCall(id='call_sMKOchAl6IS3gdgJP9TlKLQV', arguments='{\"query\":\"Recent advancements in retrieval-augmented generation (RAG)\",\"max_results\":2}', name='arxiv_search')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='Arxiv_Search_Agent', models_usage=None, metadata={}, content=[FunctionExecutionResult(content='[{\\'title\\': \\'Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks\\', \\'authors\\': [\\'Yunfan Gao\\', \\'Yun Xiong\\', \\'Meng Wang\\', \\'Haofen Wang\\'], \\'published\\': \\'2024-07-26\\', \\'abstract\\': \\'Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\\\\nof Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\\\\nincreasing demands of application scenarios have driven the evolution of RAG,\\\\nleading to the integration of advanced retrievers, LLMs and other complementary\\\\ntechnologies, which in turn has amplified the intricacy of RAG systems.\\\\nHowever, the rapid advancements are outpacing the foundational RAG paradigm,\\\\nwith many methods struggling to be unified under the process of\\\\n\"retrieve-then-generate\". In this context, this paper examines the limitations\\\\nof the existing RAG paradigm and introduces the modular RAG framework. By\\\\ndecomposing complex RAG systems into independent modules and specialized\\\\noperators, it facilitates a highly reconfigurable framework. Modular RAG\\\\ntranscends the traditional linear architecture, embracing a more advanced\\\\ndesign that integrates routing, scheduling, and fusion mechanisms. Drawing on\\\\nextensive research, this paper further identifies prevalent RAG\\\\npatterns-linear, conditional, branching, and looping-and offers a comprehensive\\\\nanalysis of their respective implementation nuances. Modular RAG presents\\\\ninnovative opportunities for the conceptualization and deployment of RAG\\\\nsystems. Finally, the paper explores the potential emergence of new operators\\\\nand paradigms, establishing a solid theoretical foundation and a practical\\\\nroadmap for the continued evolution and practical deployment of RAG\\\\ntechnologies.\\', \\'pdf_url\\': \\'http://arxiv.org/pdf/2407.21059v1\\'}, {\\'title\\': \\'Toward General Instruction-Following Alignment for Retrieval-Augmented Generation\\', \\'authors\\': [\\'Guanting Dong\\', \\'Xiaoshuai Song\\', \\'Yutao Zhu\\', \\'Runqi Qiao\\', \\'Zhicheng Dou\\', \\'Ji-Rong Wen\\'], \\'published\\': \\'2024-10-12\\', \\'abstract\\': \\'Following natural instructions is crucial for the effective application of\\\\nRetrieval-Augmented Generation (RAG) systems. Despite recent advancements in\\\\nLarge Language Models (LLMs), research on assessing and improving\\\\ninstruction-following (IF) alignment within the RAG domain remains limited. To\\\\naddress this issue, we propose VIF-RAG, the first automated, scalable, and\\\\nverifiable synthetic pipeline for instruction-following alignment in RAG\\\\nsystems. We start by manually crafting a minimal set of atomic instructions\\\\n(<100) and developing combination rules to synthesize and verify complex\\\\ninstructions for a seed set. We then use supervised models for instruction\\\\nrewriting while simultaneously generating code to automate the verification of\\\\ninstruction quality via a Python executor. Finally, we integrate these\\\\ninstructions with extensive RAG and general data samples, scaling up to a\\\\nhigh-quality VIF-RAG-QA dataset (>100k) through automated processes. To further\\\\nbridge the gap in instruction-following auto-evaluation for RAG systems, we\\\\nintroduce FollowRAG Benchmark, which includes approximately 3K test samples,\\\\ncovering 22 categories of general instruction constraints and four\\\\nknowledge-intensive QA datasets. Due to its robust pipeline design, FollowRAG\\\\ncan seamlessly integrate with different RAG benchmarks. Using FollowRAG and\\\\neight widely-used IF and foundational abilities benchmarks for LLMs, we\\\\ndemonstrate that VIF-RAG markedly enhances LLM performance across a broad range\\\\nof general instruction constraints while effectively leveraging its\\\\ncapabilities in RAG scenarios. Further analysis offers practical insights for\\\\nachieving IF alignment in RAG systems. Our code and datasets are released at\\\\nhttps://FollowRAG.github.io.\\', \\'pdf_url\\': \\'http://arxiv.org/pdf/2410.09584v1\\'}]', name='arxiv_search', call_id='call_sMKOchAl6IS3gdgJP9TlKLQV', is_error=False)], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='Arxiv_Search_Agent', models_usage=None, metadata={}, content='[{\\'title\\': \\'Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks\\', \\'authors\\': [\\'Yunfan Gao\\', \\'Yun Xiong\\', \\'Meng Wang\\', \\'Haofen Wang\\'], \\'published\\': \\'2024-07-26\\', \\'abstract\\': \\'Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\\\\nof Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\\\\nincreasing demands of application scenarios have driven the evolution of RAG,\\\\nleading to the integration of advanced retrievers, LLMs and other complementary\\\\ntechnologies, which in turn has amplified the intricacy of RAG systems.\\\\nHowever, the rapid advancements are outpacing the foundational RAG paradigm,\\\\nwith many methods struggling to be unified under the process of\\\\n\"retrieve-then-generate\". In this context, this paper examines the limitations\\\\nof the existing RAG paradigm and introduces the modular RAG framework. By\\\\ndecomposing complex RAG systems into independent modules and specialized\\\\noperators, it facilitates a highly reconfigurable framework. Modular RAG\\\\ntranscends the traditional linear architecture, embracing a more advanced\\\\ndesign that integrates routing, scheduling, and fusion mechanisms. Drawing on\\\\nextensive research, this paper further identifies prevalent RAG\\\\npatterns-linear, conditional, branching, and looping-and offers a comprehensive\\\\nanalysis of their respective implementation nuances. Modular RAG presents\\\\ninnovative opportunities for the conceptualization and deployment of RAG\\\\nsystems. Finally, the paper explores the potential emergence of new operators\\\\nand paradigms, establishing a solid theoretical foundation and a practical\\\\nroadmap for the continued evolution and practical deployment of RAG\\\\ntechnologies.\\', \\'pdf_url\\': \\'http://arxiv.org/pdf/2407.21059v1\\'}, {\\'title\\': \\'Toward General Instruction-Following Alignment for Retrieval-Augmented Generation\\', \\'authors\\': [\\'Guanting Dong\\', \\'Xiaoshuai Song\\', \\'Yutao Zhu\\', \\'Runqi Qiao\\', \\'Zhicheng Dou\\', \\'Ji-Rong Wen\\'], \\'published\\': \\'2024-10-12\\', \\'abstract\\': \\'Following natural instructions is crucial for the effective application of\\\\nRetrieval-Augmented Generation (RAG) systems. Despite recent advancements in\\\\nLarge Language Models (LLMs), research on assessing and improving\\\\ninstruction-following (IF) alignment within the RAG domain remains limited. To\\\\naddress this issue, we propose VIF-RAG, the first automated, scalable, and\\\\nverifiable synthetic pipeline for instruction-following alignment in RAG\\\\nsystems. We start by manually crafting a minimal set of atomic instructions\\\\n(<100) and developing combination rules to synthesize and verify complex\\\\ninstructions for a seed set. We then use supervised models for instruction\\\\nrewriting while simultaneously generating code to automate the verification of\\\\ninstruction quality via a Python executor. Finally, we integrate these\\\\ninstructions with extensive RAG and general data samples, scaling up to a\\\\nhigh-quality VIF-RAG-QA dataset (>100k) through automated processes. To further\\\\nbridge the gap in instruction-following auto-evaluation for RAG systems, we\\\\nintroduce FollowRAG Benchmark, which includes approximately 3K test samples,\\\\ncovering 22 categories of general instruction constraints and four\\\\nknowledge-intensive QA datasets. Due to its robust pipeline design, FollowRAG\\\\ncan seamlessly integrate with different RAG benchmarks. Using FollowRAG and\\\\neight widely-used IF and foundational abilities benchmarks for LLMs, we\\\\ndemonstrate that VIF-RAG markedly enhances LLM performance across a broad range\\\\nof general instruction constraints while effectively leveraging its\\\\ncapabilities in RAG scenarios. Further analysis offers practical insights for\\\\nachieving IF alignment in RAG systems. Our code and datasets are released at\\\\nhttps://FollowRAG.github.io.\\', \\'pdf_url\\': \\'http://arxiv.org/pdf/2410.09584v1\\'}]', type='ToolCallSummaryMessage'), TextMessage(source='Report_Agent', models_usage=RequestUsage(prompt_tokens=2090, completion_tokens=1390), metadata={}, content='# Literature Review: Current Trends and Advances in Retrieval-Augmented Generation (RAG)\\n\\n## 1. Introduction to RAG\\nRetrieval-Augmented Generation (RAG) integrates the strengths of retrieval systems and generative models (typically Large Language Models, LLMs) to address knowledge-intensive tasks. This hybrid architecture allows RAG systems to fetch relevant external knowledge bases or documents and refine contextually accurate outputs through their generative components. RAG is particularly relevant for scenarios requiring real-time information retrieval or highly domain-specific responses—tasks often challenging for standalone LLMs due to their static knowledge and \"hallucination\" tendencies (Dong et al., 2024; Gao et al., 2024).\\n\\nThe concept has gained substantial traction across industries, finding applications in customer support automation, knowledge management systems, and even customized corporate natural language interfaces. The synergy of retrieval and generation opens up transformative possibilities for ensuring more accurate, relevant, and dynamic responses in interactions (Skelter Labs, 2024; NIA, 2024).\\n\\n---\\n\\n## 2. Technological Evolution of RAG\\n\\n### 2.1 Modularity in RAG Systems\\nRecent advancements in RAG architectures emphasize modularity, allowing task-specific customization and reconfigurability. For instance, Gao et al. (2024) propose \"Modular RAG,\" which moves beyond linear retrieve-then-generate paradigms by decomposing RAG systems into independent modules. This approach introduces novel routing, scheduling, and fusion mechanisms, facilitating more complex workflows, including conditional retrieval and looping processes.\\n\\nModular RAG aligns with emerging needs for scalability, efficiency, and adaptability in enterprise AI deployments. Tasks such as decision-making automation benefit from these modular frameworks, which offer dynamic operators and flexible patterns like branching and fusion (Gao et al., 2024).\\n\\n### 2.2 Instruction-Following Alignment in RAG\\nAnother critical limitation in many RAG systems is the often-suboptimal alignment of generative outputs with user intentions or given instructions. Addressing this, Dong et al. (2024) introduce VIF-RAG—a pipeline engineered to ensure robust instruction-following (IF) capabilities. They manually design atomic instruction sets and merge them with automated verification and combination mechanisms. This creates a scalable framework capable of synthesizing complex instructions for training RAG models.\\n\\nThe proposed FollowRAG benchmark (Dong et al., 2024) pushes these endeavors further by offering a dataset specifically crafted to evaluate compliance with diverse user instructions across multiple categories. This benchmark demonstrates how improving instruction-following alignment significantly enhances RAG\\'s performance across knowledge-intensive domains.\\n\\n---\\n\\n## 3. Practical Applications\\n\\n### 3.1 Reducing Hallucination for Domain-Specific Tasks\\nCorporate environments often rely on LLMs for creating tailored chatbot solutions. Here, RAG next-gen systems, which leverage retrievals from private or enterprise environments, effectively mitigate hallucinations while maintaining contextual accuracy. Skelter Labs (2024) highlights how integrating RAG into customer service workflows offers real-time querying capabilities embedded with domain-specific insights—thus aligning database fidelity with natural user inquiries.\\n\\n### 3.2 Realtime Knowledge Base Integration\\nRAG enriches applications requiring live information retrieval. In scenarios such as financial reporting or technical troubleshooting, RAG’s retrieval components can access updated databases or APIs, ensuring generative outputs remain highly relevant and recent (NIA, 2024). This transformation significantly improves LLM deficiencies in rapidly changing disciplines.\\n\\n---\\n\\n## 4. Challenges and Research Opportunities\\n\\n### 4.1 Scalability Issues in Large Datasets\\nAlthough RAG systems promise high accuracy, training them with large and ever-expanding datasets raises storage and computational complexity challenges. As detailed by Gao et al. (2024), modular systems might offer partial relief via more streamlined architectures.\\n\\n### 4.2 Instruction-Generalization Problems\\nEnsuring instruction-following robustness across varying user contexts is another open research area. While works such as Dong et al. (2024) provide scalable results for instruction-following refinement, further improvements in the blend of supervised learning and synthetic pipelines remain critical to generalizing performance.\\n\\n---\\n\\n## 5. Future Directions\\n\\n### 5.1 Towards Unified Architectures\\nThe fragmentation between retrieval engines and generative modules suggests the need for unified RAG architectures capable of embedding adaptability within a single pipeline (Gao et al., 2024).\\n\\n### 5.2 Expanding Instruction Benchmarks\\nEfforts like FollowRAG (Dong et al., 2024) should expand to non-textual domains, addressing diverse multimodal input-output constraints.\\n\\n### 5.3 Socio-Technical Integration\\nFinally, increasing RAG’s adoption in diverse fields will require bridging technical capabilities with ethical and operational considerations, especially for sensitive applications such as healthcare or defense (Skelter Labs, 2024).\\n\\n---\\n\\n## 6. Conclusion\\nRAG embodies a promising methodology for augmenting LLMs with external knowledge, ensuring heightened performance in dynamic and domain-intensive contexts. With advances in modular construction and instruction-following refinement, RAG continues to expand its relevance across enterprise AI, customer interaction systems, and knowledge retrieval domains. As researchers tackle scalability and context alignment challenges, RAG is poised to redefine intelligent system designs for the future.\\n\\n---\\n\\n### References\\n1. Gao, Y., Xiong, Y., Wang, M., & Wang, H. (2024). Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks. Retrieved from [http://arxiv.org/pdf/2407.21059v1](http://arxiv.org/pdf/2407.21059v1)\\n2. Dong, G., Song, X., Zhu, Y., Qiao, R., Dou, Z., & Wen, J.-R. (2024). Toward General Instruction-Following Alignment for Retrieval-Augmented Generation. Retrieved from [http://arxiv.org/pdf/2410.09584v1](http://arxiv.org/pdf/2410.09584v1)\\n3. Skelter Labs. (2024). 2024 Year Of The RAG: RAG Technology Trends and Use Cases. Retrieved from [https://www.skelterlabs.com/blog/2024-year-of-the-rag](https://www.skelterlabs.com/blog/2024-year-of-the-rag)\\n4. NIA. (2024). 검색증강생성(RAG) 기술의 등장과 발전 동향. Retrieved from [https://www.nia.or.kr/common/board/Download.do?bcIdx=27539&cbIdx=82618&fileNo=1](https://www.nia.or.kr/common/board/Download.do?bcIdx=27539&cbIdx=82618&fileNo=1)\\n\\nTERMINATE', type='TextMessage')], stop_reason=\"Text 'TERMINATE' mentioned\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await Console(\n",
    "    team.run_stream(\n",
    "        # task=\"멀티 에이전트 AI 시스템 구축을 위한한 논문 리뷰 리포트 작성\",\n",
    "        task=\"최신 RAG 기술에 대한 동향 및 논문 리뷰\",\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

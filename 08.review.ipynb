{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting arxiv\n",
      "  Downloading arxiv-2.1.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting feedparser~=6.0.10 (from arxiv)\n",
      "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: requests~=2.32.0 in ./.venv/lib/python3.11/site-packages (from arxiv) (2.32.3)\n",
      "Collecting sgmllib3k (from feedparser~=6.0.10->arxiv)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests~=2.32.0->arxiv) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests~=2.32.0->arxiv) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests~=2.32.0->arxiv) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests~=2.32.0->arxiv) (2025.1.31)\n",
      "Downloading arxiv-2.1.3-py3-none-any.whl (11 kB)\n",
      "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "Building wheels for collected packages: sgmllib3k\n",
      "  Building wheel for sgmllib3k (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6089 sha256=f30466ae84a13ea68b1a868a8f65c1f55f1e2f9299397dc954e7c8b267d55e68\n",
      "  Stored in directory: /Users/andy/Library/Caches/pip/wheels/3b/25/2a/105d6a15df6914f4d15047691c6c28f9052cc1173e40285d03\n",
      "Successfully built sgmllib3k\n",
      "Installing collected packages: sgmllib3k, feedparser, arxiv\n",
      "Successfully installed arxiv-2.1.3 feedparser-6.0.11 sgmllib3k-1.0.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_core.tools import FunctionTool\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_chat_completion_client = AzureOpenAIChatCompletionClient(\n",
    "            model=\"gpt-4o\",\n",
    "            azure_endpoint=azure_endpoint,\n",
    "            api_version=api_version,\n",
    "            api_key=api_key,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_search(query: str, num_results: int = 2, max_chars: int = 500) -> list:  # type: ignore[type-arg]\n",
    "    import os\n",
    "    import time\n",
    "\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "    serp_api_key = os.getenv(\"SERPAPI_KEY\")\n",
    "\n",
    "    if not serp_api_key:\n",
    "        raise ValueError(\"SerpAPI key not found in environment variables\")\n",
    "\n",
    "    url = \"https://serpapi.com/search\"\n",
    "    params = {\n",
    "        \"engine\": \"google\",\n",
    "        \"q\": query,\n",
    "        \"num\": num_results,\n",
    "        \"api_key\": serp_api_key,\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(response.json())\n",
    "        raise Exception(f\"Error in API request: {response.status_code}\")\n",
    "\n",
    "    results = response.json().get(\"organic_results\", [])\n",
    "\n",
    "    def get_page_content(url: str) -> str:\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            text = soup.get_text(separator=\" \", strip=True)\n",
    "            words = text.split()\n",
    "            content = \"\"\n",
    "            for word in words:\n",
    "                if len(content) + len(word) + 1 > max_chars:\n",
    "                    break\n",
    "                content += \" \" + word\n",
    "            return content.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {url}: {str(e)}\")\n",
    "            return \"\"\n",
    "\n",
    "    enriched_results = []\n",
    "    for item in results:\n",
    "        body = get_page_content(item[\"link\"])\n",
    "        enriched_results.append(\n",
    "            {\"title\": item[\"title\"], \"link\": item[\"link\"], \"snippet\": item.get(\"snippet\", \"\"), \"body\": body}\n",
    "        )\n",
    "        time.sleep(1)  # Be respectful to the servers\n",
    "\n",
    "    print(enriched_results)    \n",
    "\n",
    "    return enriched_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arxiv_search(query: str, max_results: int = 2) -> list:  # type: ignore[type-arg]\n",
    "    \"\"\"\n",
    "    Search Arxiv for papers and return the results including abstracts.\n",
    "    \"\"\"\n",
    "    import arxiv\n",
    "\n",
    "    client = arxiv.Client()\n",
    "    search = arxiv.Search(query=query, max_results=max_results, sort_by=arxiv.SortCriterion.Relevance)\n",
    "\n",
    "    results = []\n",
    "    for paper in client.results(search):\n",
    "        results.append(\n",
    "            {\n",
    "                \"title\": paper.title,\n",
    "                \"authors\": [author.name for author in paper.authors],\n",
    "                \"published\": paper.published.strftime(\"%Y-%m-%d\"),\n",
    "                \"abstract\": paper.summary,\n",
    "                \"pdf_url\": paper.pdf_url,\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "    print(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_search_tool = FunctionTool(\n",
    "    google_search, description=\"Search Google for information, returns results with a snippet and body content\"\n",
    ")\n",
    "arxiv_search_tool = FunctionTool(\n",
    "    arxiv_search, description=\"Search Arxiv for papers related to a given topic, including abstracts\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_search_agent = AssistantAgent(\n",
    "    name=\"Google_Search_Agent\",\n",
    "    tools=[google_search_tool],\n",
    "    model_client=azure_openai_chat_completion_client,\n",
    "    description=\"An agent that can search Google for information, returns results with a snippet and body content\",\n",
    "    system_message=\"You are a helpful AI assistant. Solve tasks using your tools.\",\n",
    ")\n",
    "\n",
    "arxiv_search_agent = AssistantAgent(\n",
    "    name=\"Arxiv_Search_Agent\",\n",
    "    tools=[arxiv_search_tool],\n",
    "    model_client=azure_openai_chat_completion_client,\n",
    "    description=\"An agent that can search Arxiv for papers related to a given topic, including abstracts\",\n",
    "    system_message=\"You are a helpful AI assistant. Solve tasks using your tools. Specifically, you can take into consideration the user's request and craft a search query that is most likely to return relevant academi papers.\",\n",
    ")\n",
    "\n",
    "\n",
    "report_agent = AssistantAgent(\n",
    "    name=\"Report_Agent\",\n",
    "    model_client=azure_openai_chat_completion_client,\n",
    "    description=\"Generate a report based on a given topic\",\n",
    "    system_message=\"You are a helpful assistant. Your task is to synthesize data extracted into a high quality literature review including CORRECT references. You MUST write a final report that is formatted as a literature review with CORRECT references.  Your response should end with the word 'TERMINATE'\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "termination = TextMentionTermination(\"TERMINATE\")\n",
    "team = RoundRobinGroupChat(\n",
    "    participants=[google_search_agent, arxiv_search_agent, report_agent], termination_condition=termination\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "최신 RAG 기술에 대한 동향 및 논문 리뷰\n",
      "---------- Google_Search_Agent ----------\n",
      "[FunctionCall(id='call_JAOwPSZHLvT5ves4U6jWSMF6', arguments='{\"query\": \"최신 RAG 기술 동향\", \"num_results\": 2, \"max_chars\": 500}', name='google_search'), FunctionCall(id='call_K0f4UfIxcsCD6SUxqclfdr68', arguments='{\"query\": \"최신 RAG 논문 리뷰\", \"num_results\": 2, \"max_chars\": 500}', name='google_search')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andy/works/ai/autogen04-sample/.venv/lib/python3.11/site-packages/autogen_agentchat/agents/_assistant_agent.py:870: UserWarning: Resolved model mismatch: gpt-4o-2024-08-06 != gpt-4o-2024-11-20. Model mapping in autogen_ext.models.openai may be incorrect. Set the model to gpt-4o-2024-11-20 to enhance token/cost estimation and suppress this warning.\n",
      "  model_result = await model_client.create(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': '2024 Year Of The RAG :: RAG가 주목 받는 이유와 미래 동향', 'link': 'https://www.skelterlabs.com/blog/2024-year-of-the-rag', 'snippet': 'RAG의 미래는 개인화와 확장성 그리고 정확성에 초점을 맞추며, 다양한 데이터를 처리하고 실시간으로 반응하는 더 똑똑한 시스템으로 발전할 것으로 전망됩니다. 그러나 ...', 'body': '2024 Year Of The RAG :: RAG가 주목 받는 이유와 미래 동향 Company Gen ai Offerings AI Agent 를 활용한 비즈니스 자동화 기업의 복잡한 업무를 독립적으로 수행하는 AI Agent 모델을 구축합니다. RAG 기반 맞춤형 챗봇 등 애플리케이션 개발 RAG 기술로 할루시네이션을 제어하고, 기업 데이터 기반으로 동작해 정확도와 효율을 극대화합니다. Private Data 기반, 기업에 꼭 맞는 LLM 모델 구축 모델 학습에 기업 데이터를 활용해 보안성과 성능을 모두 갖춘 기업향 LLM 모델을 구축합니다. 대고객용 노코드 AI 챗봇 빌더 구축 및 운영 지원 코딩 없이 구축 가능한 AI 챗봇으로, 신속한 고객 응대를 통해 비즈니스 민첩성을 강화합니다. AI 컨택센터 구축을 위한 실시간 STT 및 TTS 모델 제공 한국어 특화 음성 인식과 자연스러운 음성 합성 기술로 고객 커뮤니케이션을 지원합니다. USECASE Newsroom Blog'}, {'title': 'RAG의 짧은 역사 훑어보기(첫 논문부터 최근 동향까지)', 'link': 'https://medium.com/rate-labs/rag%EC%9D%98-%EC%A7%A7%EC%9D%80-%EC%97%AD%EC%82%AC-%ED%9B%91%EC%96%B4%EB%B3%B4%EA%B8%B0-%EC%B2%AB-%EB%85%BC%EB%AC%B8%EB%B6%80%ED%84%B0-%EC%B5%9C%EA%B7%BC-%EB%8F%99%ED%96%A5%EA%B9%8C%EC%A7%80-53c07b9b3bee', 'snippet': '최근 RAG는 모델의 학습이 아닌 모델의 Inference 성능을 레버리지하기 위해 주로 사용되고 있다. RAG는 문서를 어떻게 잘 검색해서 가져오고 LLM에 잘 ...', 'body': 'RAG의 짧은 역사 훑어보기(첫 논문부터 최근 동향까지). 해당 글은 필자의 블로그에 이미 발간된 글입니다. | by Pangyoalto | 취미로 논문 읽는 그룹 | Medium Open in app Sign up Sign in Write Sign up Sign in Home Library Stories Stats 취미로 논문 읽는 그룹 Home About · 가끔 컴퓨터 과학 분야 논문 읽고 발표하는 모임 RAG의 짧은 역사 훑어보기(첫 논문부터 최근 동향까지) Pangyoalto · Follow Published in 취미로 논문 읽는 그룹 · 17 min read · May 11, 2024 -- Share Photo by Rafael de Paiva on Unsplash 해당 글은 필자의 블로그에 이미 발간된 글 입니다. [요약] RAG는 Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks (2020)에서 처음'}]\n",
      "[{'title': 'RAG의 짧은 역사 훑어보기(첫 논문부터 최근 동향까지)', 'link': 'https://medium.com/rate-labs/rag%EC%9D%98-%EC%A7%A7%EC%9D%80-%EC%97%AD%EC%82%AC-%ED%9B%91%EC%96%B4%EB%B3%B4%EA%B8%B0-%EC%B2%AB-%EB%85%BC%EB%AC%B8%EB%B6%80%ED%84%B0-%EC%B5%9C%EA%B7%BC-%EB%8F%99%ED%96%A5%EA%B9%8C%EC%A7%80-53c07b9b3bee', 'snippet': '논문에서는 RAG의 모델을 두 가지 제시한다. 완성된 sequence를 생성하기 위해 같은 문서만을 사용하는 모델이다. 각 문서 z마다 beam search를 실행하여 ...', 'body': 'RAG의 짧은 역사 훑어보기(첫 논문부터 최근 동향까지). 해당 글은 필자의 블로그에 이미 발간된 글입니다. | by Pangyoalto | 취미로 논문 읽는 그룹 | Medium Open in app Sign up Sign in Write Sign up Sign in Home Library Stories Stats 취미로 논문 읽는 그룹 Home About · 가끔 컴퓨터 과학 분야 논문 읽고 발표하는 모임 RAG의 짧은 역사 훑어보기(첫 논문부터 최근 동향까지) Pangyoalto · Follow Published in 취미로 논문 읽는 그룹 · 17 min read · May 11, 2024 -- Share Photo by Rafael de Paiva on Unsplash 해당 글은 필자의 블로그에 이미 발간된 글 입니다. [요약] RAG는 Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks (2020)에서 처음'}, {'title': '[논문리뷰] Retrieval-Augmented Generation for Knowledge ...', 'link': 'https://jeonsworld.github.io/NLP/rag/', 'snippet': '언어생성을 위해 Pre-trained model과 non-parametric memory를 결합한 Retrieval-Augmented Generation(RAG)를 제안하고 범용적인 fine-tuning 방법에 대해 제안한다.', 'body': '[논문리뷰] Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks | Deep Learner You need to enable JavaScript to run this app. Deep Learner D L [논문리뷰] Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, Douwe Kiela'}]\n",
      "---------- Google_Search_Agent ----------\n",
      "[FunctionExecutionResult(content=\"[{'title': '2024 Year Of The RAG :: RAG가 주목 받는 이유와 미래 동향', 'link': 'https://www.skelterlabs.com/blog/2024-year-of-the-rag', 'snippet': 'RAG의 미래는 개인화와 확장성 그리고 정확성에 초점을 맞추며, 다양한 데이터를 처리하고 실시간으로 반응하는 더 똑똑한 시스템으로 발전할 것으로 전망됩니다. 그러나 ...', 'body': '2024 Year Of The RAG :: RAG가 주목 받는 이유와 미래 동향 Company Gen ai Offerings AI Agent 를 활용한 비즈니스 자동화 기업의 복잡한 업무를 독립적으로 수행하는 AI Agent 모델을 구축합니다. RAG 기반 맞춤형 챗봇 등 애플리케이션 개발 RAG 기술로 할루시네이션을 제어하고, 기업 데이터 기반으로 동작해 정확도와 효율을 극대화합니다. Private Data 기반, 기업에 꼭 맞는 LLM 모델 구축 모델 학습에 기업 데이터를 활용해 보안성과 성능을 모두 갖춘 기업향 LLM 모델을 구축합니다. 대고객용 노코드 AI 챗봇 빌더 구축 및 운영 지원 코딩 없이 구축 가능한 AI 챗봇으로, 신속한 고객 응대를 통해 비즈니스 민첩성을 강화합니다. AI 컨택센터 구축을 위한 실시간 STT 및 TTS 모델 제공 한국어 특화 음성 인식과 자연스러운 음성 합성 기술로 고객 커뮤니케이션을 지원합니다. USECASE Newsroom Blog'}, {'title': 'RAG의 짧은 역사 훑어보기(첫 논문부터 최근 동향까지)', 'link': 'https://medium.com/rate-labs/rag%EC%9D%98-%EC%A7%A7%EC%9D%80-%EC%97%AD%EC%82%AC-%ED%9B%91%EC%96%B4%EB%B3%B4%EA%B8%B0-%EC%B2%AB-%EB%85%BC%EB%AC%B8%EB%B6%80%ED%84%B0-%EC%B5%9C%EA%B7%BC-%EB%8F%99%ED%96%A5%EA%B9%8C%EC%A7%80-53c07b9b3bee', 'snippet': '최근 RAG는 모델의 학습이 아닌 모델의 Inference 성능을 레버리지하기 위해 주로 사용되고 있다. RAG는 문서를 어떻게 잘 검색해서 가져오고 LLM에 잘 ...', 'body': 'RAG의 짧은 역사 훑어보기(첫 논문부터 최근 동향까지). 해당 글은 필자의 블로그에 이미 발간된 글입니다. | by Pangyoalto | 취미로 논문 읽는 그룹 | Medium Open in app Sign up Sign in Write Sign up Sign in Home Library Stories Stats 취미로 논문 읽는 그룹 Home About · 가끔 컴퓨터 과학 분야 논문 읽고 발표하는 모임 RAG의 짧은 역사 훑어보기(첫 논문부터 최근 동향까지) Pangyoalto · Follow Published in 취미로 논문 읽는 그룹 · 17 min read · May 11, 2024 -- Share Photo by Rafael de Paiva on Unsplash 해당 글은 필자의 블로그에 이미 발간된 글 입니다. [요약] RAG는 Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks (2020)에서 처음'}]\", name='google_search', call_id='call_JAOwPSZHLvT5ves4U6jWSMF6', is_error=False), FunctionExecutionResult(content=\"[{'title': 'RAG의 짧은 역사 훑어보기(첫 논문부터 최근 동향까지)', 'link': 'https://medium.com/rate-labs/rag%EC%9D%98-%EC%A7%A7%EC%9D%80-%EC%97%AD%EC%82%AC-%ED%9B%91%EC%96%B4%EB%B3%B4%EA%B8%B0-%EC%B2%AB-%EB%85%BC%EB%AC%B8%EB%B6%80%ED%84%B0-%EC%B5%9C%EA%B7%BC-%EB%8F%99%ED%96%A5%EA%B9%8C%EC%A7%80-53c07b9b3bee', 'snippet': '논문에서는 RAG의 모델을 두 가지 제시한다. 완성된 sequence를 생성하기 위해 같은 문서만을 사용하는 모델이다. 각 문서 z마다 beam search를 실행하여 ...', 'body': 'RAG의 짧은 역사 훑어보기(첫 논문부터 최근 동향까지). 해당 글은 필자의 블로그에 이미 발간된 글입니다. | by Pangyoalto | 취미로 논문 읽는 그룹 | Medium Open in app Sign up Sign in Write Sign up Sign in Home Library Stories Stats 취미로 논문 읽는 그룹 Home About · 가끔 컴퓨터 과학 분야 논문 읽고 발표하는 모임 RAG의 짧은 역사 훑어보기(첫 논문부터 최근 동향까지) Pangyoalto · Follow Published in 취미로 논문 읽는 그룹 · 17 min read · May 11, 2024 -- Share Photo by Rafael de Paiva on Unsplash 해당 글은 필자의 블로그에 이미 발간된 글 입니다. [요약] RAG는 Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks (2020)에서 처음'}, {'title': '[논문리뷰] Retrieval-Augmented Generation for Knowledge ...', 'link': 'https://jeonsworld.github.io/NLP/rag/', 'snippet': '언어생성을 위해 Pre-trained model과 non-parametric memory를 결합한 Retrieval-Augmented Generation(RAG)를 제안하고 범용적인 fine-tuning 방법에 대해 제안한다.', 'body': '[논문리뷰] Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks | Deep Learner You need to enable JavaScript to run this app. Deep Learner D L [논문리뷰] Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, Douwe Kiela'}]\", name='google_search', call_id='call_K0f4UfIxcsCD6SUxqclfdr68', is_error=False)]\n",
      "---------- Google_Search_Agent ----------\n",
      "[{'title': '2024 Year Of The RAG :: RAG가 주목 받는 이유와 미래 동향', 'link': 'https://www.skelterlabs.com/blog/2024-year-of-the-rag', 'snippet': 'RAG의 미래는 개인화와 확장성 그리고 정확성에 초점을 맞추며, 다양한 데이터를 처리하고 실시간으로 반응하는 더 똑똑한 시스템으로 발전할 것으로 전망됩니다. 그러나 ...', 'body': '2024 Year Of The RAG :: RAG가 주목 받는 이유와 미래 동향 Company Gen ai Offerings AI Agent 를 활용한 비즈니스 자동화 기업의 복잡한 업무를 독립적으로 수행하는 AI Agent 모델을 구축합니다. RAG 기반 맞춤형 챗봇 등 애플리케이션 개발 RAG 기술로 할루시네이션을 제어하고, 기업 데이터 기반으로 동작해 정확도와 효율을 극대화합니다. Private Data 기반, 기업에 꼭 맞는 LLM 모델 구축 모델 학습에 기업 데이터를 활용해 보안성과 성능을 모두 갖춘 기업향 LLM 모델을 구축합니다. 대고객용 노코드 AI 챗봇 빌더 구축 및 운영 지원 코딩 없이 구축 가능한 AI 챗봇으로, 신속한 고객 응대를 통해 비즈니스 민첩성을 강화합니다. AI 컨택센터 구축을 위한 실시간 STT 및 TTS 모델 제공 한국어 특화 음성 인식과 자연스러운 음성 합성 기술로 고객 커뮤니케이션을 지원합니다. USECASE Newsroom Blog'}, {'title': 'RAG의 짧은 역사 훑어보기(첫 논문부터 최근 동향까지)', 'link': 'https://medium.com/rate-labs/rag%EC%9D%98-%EC%A7%A7%EC%9D%80-%EC%97%AD%EC%82%AC-%ED%9B%91%EC%96%B4%EB%B3%B4%EA%B8%B0-%EC%B2%AB-%EB%85%BC%EB%AC%B8%EB%B6%80%ED%84%B0-%EC%B5%9C%EA%B7%BC-%EB%8F%99%ED%96%A5%EA%B9%8C%EC%A7%80-53c07b9b3bee', 'snippet': '최근 RAG는 모델의 학습이 아닌 모델의 Inference 성능을 레버리지하기 위해 주로 사용되고 있다. RAG는 문서를 어떻게 잘 검색해서 가져오고 LLM에 잘 ...', 'body': 'RAG의 짧은 역사 훑어보기(첫 논문부터 최근 동향까지). 해당 글은 필자의 블로그에 이미 발간된 글입니다. | by Pangyoalto | 취미로 논문 읽는 그룹 | Medium Open in app Sign up Sign in Write Sign up Sign in Home Library Stories Stats 취미로 논문 읽는 그룹 Home About · 가끔 컴퓨터 과학 분야 논문 읽고 발표하는 모임 RAG의 짧은 역사 훑어보기(첫 논문부터 최근 동향까지) Pangyoalto · Follow Published in 취미로 논문 읽는 그룹 · 17 min read · May 11, 2024 -- Share Photo by Rafael de Paiva on Unsplash 해당 글은 필자의 블로그에 이미 발간된 글 입니다. [요약] RAG는 Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks (2020)에서 처음'}]\n",
      "[{'title': 'RAG의 짧은 역사 훑어보기(첫 논문부터 최근 동향까지)', 'link': 'https://medium.com/rate-labs/rag%EC%9D%98-%EC%A7%A7%EC%9D%80-%EC%97%AD%EC%82%AC-%ED%9B%91%EC%96%B4%EB%B3%B4%EA%B8%B0-%EC%B2%AB-%EB%85%BC%EB%AC%B8%EB%B6%80%ED%84%B0-%EC%B5%9C%EA%B7%BC-%EB%8F%99%ED%96%A5%EA%B9%8C%EC%A7%80-53c07b9b3bee', 'snippet': '논문에서는 RAG의 모델을 두 가지 제시한다. 완성된 sequence를 생성하기 위해 같은 문서만을 사용하는 모델이다. 각 문서 z마다 beam search를 실행하여 ...', 'body': 'RAG의 짧은 역사 훑어보기(첫 논문부터 최근 동향까지). 해당 글은 필자의 블로그에 이미 발간된 글입니다. | by Pangyoalto | 취미로 논문 읽는 그룹 | Medium Open in app Sign up Sign in Write Sign up Sign in Home Library Stories Stats 취미로 논문 읽는 그룹 Home About · 가끔 컴퓨터 과학 분야 논문 읽고 발표하는 모임 RAG의 짧은 역사 훑어보기(첫 논문부터 최근 동향까지) Pangyoalto · Follow Published in 취미로 논문 읽는 그룹 · 17 min read · May 11, 2024 -- Share Photo by Rafael de Paiva on Unsplash 해당 글은 필자의 블로그에 이미 발간된 글 입니다. [요약] RAG는 Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks (2020)에서 처음'}, {'title': '[논문리뷰] Retrieval-Augmented Generation for Knowledge ...', 'link': 'https://jeonsworld.github.io/NLP/rag/', 'snippet': '언어생성을 위해 Pre-trained model과 non-parametric memory를 결합한 Retrieval-Augmented Generation(RAG)를 제안하고 범용적인 fine-tuning 방법에 대해 제안한다.', 'body': '[논문리뷰] Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks | Deep Learner You need to enable JavaScript to run this app. Deep Learner D L [논문리뷰] Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, Douwe Kiela'}]\n",
      "---------- Arxiv_Search_Agent ----------\n",
      "[FunctionCall(id='call_2fCCjJI02r9kmpRqTXZal8pj', arguments='{\"query\": \"retrieval-augmented generation\"}', name='arxiv_search'), FunctionCall(id='call_wCu45NzU5QMSgaXizL2BpuB0', arguments='{\"query\": \"RAG trends\"}', name='arxiv_search')]\n",
      "[{'title': 'OCR Hinders RAG: Evaluating the Cascading Impact of OCR on Retrieval-Augmented Generation', 'authors': ['Junyuan Zhang', 'Qintong Zhang', 'Bin Wang', 'Linke Ouyang', 'Zichen Wen', 'Ying Li', 'Ka-Ho Chow', 'Conghui He', 'Wentao Zhang'], 'published': '2024-12-03', 'abstract': \"Retrieval-augmented Generation (RAG) enhances Large Language Models (LLMs) by\\nintegrating external knowledge to reduce hallucinations and incorporate\\nup-to-date information without retraining. As an essential part of RAG,\\nexternal knowledge bases are commonly built by extracting structured data from\\nunstructured PDF documents using Optical Character Recognition (OCR). However,\\ngiven the imperfect prediction of OCR and the inherent non-uniform\\nrepresentation of structured data, knowledge bases inevitably contain various\\nOCR noises. In this paper, we introduce OHRBench, the first benchmark for\\nunderstanding the cascading impact of OCR on RAG systems. OHRBench includes\\n8,561 carefully selected unstructured document images from seven real-world RAG\\napplication domains, along with 8,498 Q&A pairs derived from multimodal\\nelements in documents, challenging existing OCR solutions used for RAG. To\\nbetter understand OCR's impact on RAG systems, we identify two primary types of\\nOCR noise: Semantic Noise and Formatting Noise and apply perturbation to\\ngenerate a set of structured data with varying degrees of each OCR noise. Using\\nOHRBench, we first conduct a comprehensive evaluation of current OCR solutions\\nand reveal that none is competent for constructing high-quality knowledge bases\\nfor RAG systems. We then systematically evaluate the impact of these two noise\\ntypes and demonstrate the trend relationship between the degree of OCR noise\\nand RAG performance. Our OHRBench, including PDF documents, Q&As, and the\\nground truth structured data are released at:\\nhttps://github.com/opendatalab/OHR-Bench\", 'pdf_url': 'http://arxiv.org/pdf/2412.02592v2'}, {'title': 'The 2nd FutureDial Challenge: Dialog Systems with Retrieval Augmented Generation (FutureDial-RAG)', 'authors': ['Yucheng Cai', 'Si Chen', 'Yuxuan Wu', 'Yi Huang', 'Junlan Feng', 'Zhijian Ou'], 'published': '2024-05-21', 'abstract': 'Recently, increasing research interests have focused on retrieval augmented\\ngeneration (RAG) to mitigate hallucination for large language models (LLMs).\\nFollowing this trend, we launch the FutureDial-RAG challenge at SLT 2024, which\\naims at promoting the study of RAG for dialog systems. The challenge builds\\nupon the MobileCS2 dataset, a real-life customer service datasets with nearly\\n3000 high-quality dialogs containing annotations for knowledge base query and\\ncorresponding results. Over the dataset, we define two tasks, track 1 for\\nknowledge retrieval and track 2 for response generation, which are core\\nresearch questions in dialog systems with RAG. We build baseline systems for\\nthe two tracks and design metrics to measure whether the systems can perform\\naccurate retrieval and generate informative and coherent response. The baseline\\nresults show that it is very challenging to perform well on the two tasks,\\nwhich encourages the participating teams and the community to study how to make\\nbetter use of RAG for real-life dialog systems.', 'pdf_url': 'http://arxiv.org/pdf/2405.13084v2'}]\n",
      "[{'title': 'Generalized Baer and Generalized Quasi-Baer Rings of Skew Generalized Power Series', 'authors': ['M. M. Hamam', 'R. E. Abdel-Khalek', 'R. M. Salem'], 'published': '2024-05-06', 'abstract': 'Let $R$ be a ring with identity, $(S,\\\\leq)$ an ordered monoid, $\\\\omega:S \\\\to\\nEnd(R)$ a monoid homomorphism, and $A= R\\\\left[\\\\left[S,\\\\omega \\\\right]\\\\right]$\\nthe ring of skew generalized power series. The concepts of generalized Baer and\\ngeneralized quasi-Baer rings are generalization of Baer and quasi-Baer rings,\\nrespectively. A ring $R$ is called generalized right Baer (generalized right\\nquasi-Baer) if for any non-empty subset $S$ (right ideal $I$) of $R$, the right\\nannihilator of $S^n \\\\space{0.1cm}(I^n)$ is generated by an idempotent for some\\npositive integer $n$. Left cases may be defined analogously. A ring $R$ is\\ncalled generalized Baer (generalized quasi-Baer) if it is both generalized\\nright and left Baer (generalized right and left quasi-Baer) ring. In this\\npaper, we examine the behavior of a skew generalized power series ring over a\\ngeneralized right Baer (generalized right quasi-Baer) ring and prove that,\\nunder specific conditions, the ring $A$ is generalized right Baer (generalized\\nright quasi-Baer) if and only if $R$ is a generalized right Baer (generalized\\nright quasi-Baer) ring.', 'pdf_url': 'http://arxiv.org/pdf/2405.03423v2'}, {'title': 'On generalized topological groups', 'authors': ['Murad Hussain', 'Moiz Ud Din Khan', 'Cenap \\x7fÖzel'], 'published': '2012-05-17', 'abstract': 'In this work, we will introduce the notion of generalized topological groups\\nusing generalized topological structure and generalized continuity defined by\\n?A. Cs?asz?ar [2]. We will discuss some basic properties of this kind of\\nstructures and connectedness properties of this structures are given. Keywords:\\nGeneralized topology; generalized continuity; generalized topological groups;\\ngeneralized connectedness.', 'pdf_url': 'http://arxiv.org/pdf/1205.3915v1'}]\n",
      "---------- Arxiv_Search_Agent ----------\n",
      "[FunctionExecutionResult(content=\"[{'title': 'Generalized Baer and Generalized Quasi-Baer Rings of Skew Generalized Power Series', 'authors': ['M. M. Hamam', 'R. E. Abdel-Khalek', 'R. M. Salem'], 'published': '2024-05-06', 'abstract': 'Let $R$ be a ring with identity, $(S,\\\\\\\\leq)$ an ordered monoid, $\\\\\\\\omega:S \\\\\\\\to\\\\nEnd(R)$ a monoid homomorphism, and $A= R\\\\\\\\left[\\\\\\\\left[S,\\\\\\\\omega \\\\\\\\right]\\\\\\\\right]$\\\\nthe ring of skew generalized power series. The concepts of generalized Baer and\\\\ngeneralized quasi-Baer rings are generalization of Baer and quasi-Baer rings,\\\\nrespectively. A ring $R$ is called generalized right Baer (generalized right\\\\nquasi-Baer) if for any non-empty subset $S$ (right ideal $I$) of $R$, the right\\\\nannihilator of $S^n \\\\\\\\space{0.1cm}(I^n)$ is generated by an idempotent for some\\\\npositive integer $n$. Left cases may be defined analogously. A ring $R$ is\\\\ncalled generalized Baer (generalized quasi-Baer) if it is both generalized\\\\nright and left Baer (generalized right and left quasi-Baer) ring. In this\\\\npaper, we examine the behavior of a skew generalized power series ring over a\\\\ngeneralized right Baer (generalized right quasi-Baer) ring and prove that,\\\\nunder specific conditions, the ring $A$ is generalized right Baer (generalized\\\\nright quasi-Baer) if and only if $R$ is a generalized right Baer (generalized\\\\nright quasi-Baer) ring.', 'pdf_url': 'http://arxiv.org/pdf/2405.03423v2'}, {'title': 'On generalized topological groups', 'authors': ['Murad Hussain', 'Moiz Ud Din Khan', 'Cenap \\\\x7fÖzel'], 'published': '2012-05-17', 'abstract': 'In this work, we will introduce the notion of generalized topological groups\\\\nusing generalized topological structure and generalized continuity defined by\\\\n?A. Cs?asz?ar [2]. We will discuss some basic properties of this kind of\\\\nstructures and connectedness properties of this structures are given. Keywords:\\\\nGeneralized topology; generalized continuity; generalized topological groups;\\\\ngeneralized connectedness.', 'pdf_url': 'http://arxiv.org/pdf/1205.3915v1'}]\", name='arxiv_search', call_id='call_2fCCjJI02r9kmpRqTXZal8pj', is_error=False), FunctionExecutionResult(content='[{\\'title\\': \\'OCR Hinders RAG: Evaluating the Cascading Impact of OCR on Retrieval-Augmented Generation\\', \\'authors\\': [\\'Junyuan Zhang\\', \\'Qintong Zhang\\', \\'Bin Wang\\', \\'Linke Ouyang\\', \\'Zichen Wen\\', \\'Ying Li\\', \\'Ka-Ho Chow\\', \\'Conghui He\\', \\'Wentao Zhang\\'], \\'published\\': \\'2024-12-03\\', \\'abstract\\': \"Retrieval-augmented Generation (RAG) enhances Large Language Models (LLMs) by\\\\nintegrating external knowledge to reduce hallucinations and incorporate\\\\nup-to-date information without retraining. As an essential part of RAG,\\\\nexternal knowledge bases are commonly built by extracting structured data from\\\\nunstructured PDF documents using Optical Character Recognition (OCR). However,\\\\ngiven the imperfect prediction of OCR and the inherent non-uniform\\\\nrepresentation of structured data, knowledge bases inevitably contain various\\\\nOCR noises. In this paper, we introduce OHRBench, the first benchmark for\\\\nunderstanding the cascading impact of OCR on RAG systems. OHRBench includes\\\\n8,561 carefully selected unstructured document images from seven real-world RAG\\\\napplication domains, along with 8,498 Q&A pairs derived from multimodal\\\\nelements in documents, challenging existing OCR solutions used for RAG. To\\\\nbetter understand OCR\\'s impact on RAG systems, we identify two primary types of\\\\nOCR noise: Semantic Noise and Formatting Noise and apply perturbation to\\\\ngenerate a set of structured data with varying degrees of each OCR noise. Using\\\\nOHRBench, we first conduct a comprehensive evaluation of current OCR solutions\\\\nand reveal that none is competent for constructing high-quality knowledge bases\\\\nfor RAG systems. We then systematically evaluate the impact of these two noise\\\\ntypes and demonstrate the trend relationship between the degree of OCR noise\\\\nand RAG performance. Our OHRBench, including PDF documents, Q&As, and the\\\\nground truth structured data are released at:\\\\nhttps://github.com/opendatalab/OHR-Bench\", \\'pdf_url\\': \\'http://arxiv.org/pdf/2412.02592v2\\'}, {\\'title\\': \\'The 2nd FutureDial Challenge: Dialog Systems with Retrieval Augmented Generation (FutureDial-RAG)\\', \\'authors\\': [\\'Yucheng Cai\\', \\'Si Chen\\', \\'Yuxuan Wu\\', \\'Yi Huang\\', \\'Junlan Feng\\', \\'Zhijian Ou\\'], \\'published\\': \\'2024-05-21\\', \\'abstract\\': \\'Recently, increasing research interests have focused on retrieval augmented\\\\ngeneration (RAG) to mitigate hallucination for large language models (LLMs).\\\\nFollowing this trend, we launch the FutureDial-RAG challenge at SLT 2024, which\\\\naims at promoting the study of RAG for dialog systems. The challenge builds\\\\nupon the MobileCS2 dataset, a real-life customer service datasets with nearly\\\\n3000 high-quality dialogs containing annotations for knowledge base query and\\\\ncorresponding results. Over the dataset, we define two tasks, track 1 for\\\\nknowledge retrieval and track 2 for response generation, which are core\\\\nresearch questions in dialog systems with RAG. We build baseline systems for\\\\nthe two tracks and design metrics to measure whether the systems can perform\\\\naccurate retrieval and generate informative and coherent response. The baseline\\\\nresults show that it is very challenging to perform well on the two tasks,\\\\nwhich encourages the participating teams and the community to study how to make\\\\nbetter use of RAG for real-life dialog systems.\\', \\'pdf_url\\': \\'http://arxiv.org/pdf/2405.13084v2\\'}]', name='arxiv_search', call_id='call_wCu45NzU5QMSgaXizL2BpuB0', is_error=False)]\n",
      "---------- Arxiv_Search_Agent ----------\n",
      "[{'title': 'Generalized Baer and Generalized Quasi-Baer Rings of Skew Generalized Power Series', 'authors': ['M. M. Hamam', 'R. E. Abdel-Khalek', 'R. M. Salem'], 'published': '2024-05-06', 'abstract': 'Let $R$ be a ring with identity, $(S,\\\\leq)$ an ordered monoid, $\\\\omega:S \\\\to\\nEnd(R)$ a monoid homomorphism, and $A= R\\\\left[\\\\left[S,\\\\omega \\\\right]\\\\right]$\\nthe ring of skew generalized power series. The concepts of generalized Baer and\\ngeneralized quasi-Baer rings are generalization of Baer and quasi-Baer rings,\\nrespectively. A ring $R$ is called generalized right Baer (generalized right\\nquasi-Baer) if for any non-empty subset $S$ (right ideal $I$) of $R$, the right\\nannihilator of $S^n \\\\space{0.1cm}(I^n)$ is generated by an idempotent for some\\npositive integer $n$. Left cases may be defined analogously. A ring $R$ is\\ncalled generalized Baer (generalized quasi-Baer) if it is both generalized\\nright and left Baer (generalized right and left quasi-Baer) ring. In this\\npaper, we examine the behavior of a skew generalized power series ring over a\\ngeneralized right Baer (generalized right quasi-Baer) ring and prove that,\\nunder specific conditions, the ring $A$ is generalized right Baer (generalized\\nright quasi-Baer) if and only if $R$ is a generalized right Baer (generalized\\nright quasi-Baer) ring.', 'pdf_url': 'http://arxiv.org/pdf/2405.03423v2'}, {'title': 'On generalized topological groups', 'authors': ['Murad Hussain', 'Moiz Ud Din Khan', 'Cenap \\x7fÖzel'], 'published': '2012-05-17', 'abstract': 'In this work, we will introduce the notion of generalized topological groups\\nusing generalized topological structure and generalized continuity defined by\\n?A. Cs?asz?ar [2]. We will discuss some basic properties of this kind of\\nstructures and connectedness properties of this structures are given. Keywords:\\nGeneralized topology; generalized continuity; generalized topological groups;\\ngeneralized connectedness.', 'pdf_url': 'http://arxiv.org/pdf/1205.3915v1'}]\n",
      "[{'title': 'OCR Hinders RAG: Evaluating the Cascading Impact of OCR on Retrieval-Augmented Generation', 'authors': ['Junyuan Zhang', 'Qintong Zhang', 'Bin Wang', 'Linke Ouyang', 'Zichen Wen', 'Ying Li', 'Ka-Ho Chow', 'Conghui He', 'Wentao Zhang'], 'published': '2024-12-03', 'abstract': \"Retrieval-augmented Generation (RAG) enhances Large Language Models (LLMs) by\\nintegrating external knowledge to reduce hallucinations and incorporate\\nup-to-date information without retraining. As an essential part of RAG,\\nexternal knowledge bases are commonly built by extracting structured data from\\nunstructured PDF documents using Optical Character Recognition (OCR). However,\\ngiven the imperfect prediction of OCR and the inherent non-uniform\\nrepresentation of structured data, knowledge bases inevitably contain various\\nOCR noises. In this paper, we introduce OHRBench, the first benchmark for\\nunderstanding the cascading impact of OCR on RAG systems. OHRBench includes\\n8,561 carefully selected unstructured document images from seven real-world RAG\\napplication domains, along with 8,498 Q&A pairs derived from multimodal\\nelements in documents, challenging existing OCR solutions used for RAG. To\\nbetter understand OCR's impact on RAG systems, we identify two primary types of\\nOCR noise: Semantic Noise and Formatting Noise and apply perturbation to\\ngenerate a set of structured data with varying degrees of each OCR noise. Using\\nOHRBench, we first conduct a comprehensive evaluation of current OCR solutions\\nand reveal that none is competent for constructing high-quality knowledge bases\\nfor RAG systems. We then systematically evaluate the impact of these two noise\\ntypes and demonstrate the trend relationship between the degree of OCR noise\\nand RAG performance. Our OHRBench, including PDF documents, Q&As, and the\\nground truth structured data are released at:\\nhttps://github.com/opendatalab/OHR-Bench\", 'pdf_url': 'http://arxiv.org/pdf/2412.02592v2'}, {'title': 'The 2nd FutureDial Challenge: Dialog Systems with Retrieval Augmented Generation (FutureDial-RAG)', 'authors': ['Yucheng Cai', 'Si Chen', 'Yuxuan Wu', 'Yi Huang', 'Junlan Feng', 'Zhijian Ou'], 'published': '2024-05-21', 'abstract': 'Recently, increasing research interests have focused on retrieval augmented\\ngeneration (RAG) to mitigate hallucination for large language models (LLMs).\\nFollowing this trend, we launch the FutureDial-RAG challenge at SLT 2024, which\\naims at promoting the study of RAG for dialog systems. The challenge builds\\nupon the MobileCS2 dataset, a real-life customer service datasets with nearly\\n3000 high-quality dialogs containing annotations for knowledge base query and\\ncorresponding results. Over the dataset, we define two tasks, track 1 for\\nknowledge retrieval and track 2 for response generation, which are core\\nresearch questions in dialog systems with RAG. We build baseline systems for\\nthe two tracks and design metrics to measure whether the systems can perform\\naccurate retrieval and generate informative and coherent response. The baseline\\nresults show that it is very challenging to perform well on the two tasks,\\nwhich encourages the participating teams and the community to study how to make\\nbetter use of RAG for real-life dialog systems.', 'pdf_url': 'http://arxiv.org/pdf/2405.13084v2'}]\n",
      "---------- Report_Agent ----------\n",
      "# 최신 RAG(Retrieval-Augmented Generation) 기술 동향 및 관련 논문에 대한 리뷰\n",
      "\n",
      "## 서론\n",
      "Retrieval-Augmented Generation(RAG)은 외부 지식을 활용하여 대규모 언어 모델(LLM)의 성능을 강화하고 할루시네이션을 줄이며 최신 정보와의 통합을 가능하게 하는 혁신적인 방법입니다. 이는 생성적 언어 모델의 성능을 향상시키기 위해 검색 및 생성의 두 가지 작업을 결합한 접근 방식이라 할 수 있습니다. 이러한 기술은 특히 지식 집약적인 NLP 작업에서 주목받고 있으며, 학계와 산업계 모두에서 활발히 연구되고 있습니다.\n",
      "\n",
      "본 리뷰에서는 최신 RAG 기술의 정의와 활용 사례, 주요 연구 흐름, 현재의 한계점 및 앞으로의 개선 방향을 다룰 것입니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 최신 RAG 기술 동향\n",
      "\n",
      "### RAG의 정의와 발전\n",
      "RAG는 최초로 **Lewis et al. (2020)**에 의해 도입되었으며, \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\"라는 논문에서 그 주요 개념이 설명되었습니다. 이 기술은 사전 학습된 언어 모델과 외부 메모리(주로 문서 베이스)를 결합하여 더 정확하고 지식 기반의 텍스트 생성을 구현합니다(Lewis et al., 2020).\n",
      "\n",
      "RAG의 기술적 핵심은 두 가지입니다:\n",
      "1. **정보 검색(Search)**: 입력된 질문이나 요청에 대해 가장 관련성이 높은 문서를 검색합니다.\n",
      "2. **텍스트 생성(Generation)**: 검색된 문서를 기반으로 생성된 텍스트를 반환합니다.\n",
      "\n",
      "최근에는 기존의 정형화된 단일 데이터 소스뿐만 아니라 비정형 데이터(PDF, 이미지 등)로부터 정보를 처리하는 방향으로 발전하고 있습니다(Jeon, 2020).\n",
      "\n",
      "---\n",
      "\n",
      "### 사례 연구: 다양한 응용 분야\n",
      "1. **고객 서비스 챗봇 및 대화형 시스템**  \n",
      "   최신 연구에서 RAG는 고객 등의 특화된 질문에 즉각적으로 응답할 수 있는 대화형 시스템에 활용되고 있습니다. FutureDial-RAG 챌린지(SLT 2024)에서는 RAG의 활용을 중심으로 지식 검색 및 응답 생성 트랙을 설정하여 실제 고객 서비스에서의 성능을 평가하였습니다(Cai et al., 2024).\n",
      "\n",
      "2. **OCR 기반 RAG**  \n",
      "   Optical Character Recognition(OCR) 기술이 통합된 RAG 시스템은 특히 PDF 문서와 같은 비정형 데이터를 처리하는 데 사용됩니다. Zhang et al. (2024)은 \"OHRBench\"라는 벤치마크를 통해 OCR 오류가 RAG 성능에 미치는 영향을 체계적으로 분석하였습니다. 이는 체계적인 지식 베이스 구축 과정에서 OCR의 중요성과 한계를 명확히 보여주었습니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 최신 연구 결과 및 관련 논문\n",
      "\n",
      "### 선행 논문\n",
      "1. **Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks**  \n",
      "   이 논문은 RAG의 원리를 제시한 최초의 연구로, LLM과 외부 문서 검색 시스템의 통합에 대한 아이디어를 소개하였습니다(Lewis et al., 2020).\n",
      "\n",
      "### 최신 연구 발표\n",
      "2. **The 2nd FutureDial Challenge: Dialog Systems with Retrieval-Augmented Generation**  \n",
      "   본 연구는 FutureDial-RAG 챌린지를 소개하며, 두 가지 주요 작업(지식 검색 및 응답 생성)에 대한 성과와 어려움을 다루었습니다. 이를 통해 실무 환경에서 RAG 시스템의 도전 과제를 제시합니다(Cai et al., 2024).\n",
      "\n",
      "3. **OCR Hinders RAG: Evaluating the Cascading Impact of OCR on Retrieval-Augmented Generation**  \n",
      "   Zhang et al.의 연구는 OCR 기술이 RAG 시스템의 지식 정확도와 텍스트 생성 품질에 끼치는 부정적인 영향을 실험적으로 입증하였습니다(Zhang et al., 2024). 이를 통해 RAG 시스템의 성능 최적화를 위한 방향성을 제안하였습니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 한계점 및 개선 방향\n",
      "\n",
      "### 한계점\n",
      "1. **할루시네이션 문제**  \n",
      "   LLM은 여전히 잘못된 정보를 생성할 가능성이 높습니다. 이는 지식 검색 과정이 부정확하거나 생성 모델이 충분히 문맥을 반영하지 못하는 경우 발생합니다.\n",
      "\n",
      "2. **시스템 복잡성**  \n",
      "   검색 및 생성 모듈의 조합은 시스템의 구현과 유지보수를 어렵게 만듭니다.\n",
      "\n",
      "3. **비정형 데이터의 통합 문제**  \n",
      "   OCR과 같은 전처리 과정이 완벽하지 않을 경우 잘못된 정보를 기반으로 한 잘못된 텍스트가 생성될 수 있습니다(Zhang et al., 2024).\n",
      "\n",
      "### 개선 방향\n",
      "- **지식 기반 강화학습 도입**  \n",
      "  검색 및 생성 모델을 통합적으로 학습시키기 위해 강화학습 기반 접근 방식을 활용할 수 있습니다.\n",
      "  \n",
      "- **데이터 품질 개선**  \n",
      "  OCR 기술의 정밀도를 향상시키고, 사전 처리 과정에서 발생하는 오류를 최소화하는 연구가 필요합니다(Zhang et al., 2024).\n",
      "\n",
      "- **경량화된 모델 개발**  \n",
      "  복잡한 검색-생성 과정을 최적화하는 단순화된 아키텍처 설계가 중요합니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 결론\n",
      "RAG는 지식 기반 NLP 작업에서 강력한 도구로 자리매김하고 있습니다. 최신 연구들은 RAG의 정확성과 응용 가능성을 높이기 위해 다양한 발전 방향을 제안하고 있습니다. 그러나 여전히 OCR, 비정형 데이터 통합 등 실용적 측면에서의 도전 과제가 존재하며, 차세대 RAG 기술은 보다 현실적인 문제를 해결하는 방향으로 발전할 것으로 전망됩니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 참고 문헌\n",
      "1. Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., & Riedel, S. (2020). \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\". *arXiv preprint arXiv:2005.11401.*\n",
      "2. Cai, Y., Chen, S., Wu, Y., Huang, Y., Feng, J., & Ou, Z. (2024). \"The 2nd FutureDial Challenge: Dialog Systems with Retrieval Augmented Generation\". *arXiv preprint arXiv:2405.13084.*\n",
      "3. Zhang, J., Zhang, Q., Wang, B., Ouyang, L., Wen, Z., Li, Y., & Zhang, W. (2024). \"OCR Hinders RAG: Evaluating the Cascading Impact of OCR on Retrieval-Augmented Generation\". *arXiv preprint arXiv:2412.02592.*\n",
      "\n",
      "TERMINATE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, metadata={}, content='최신 RAG 기술에 대한 동향 및 논문 리뷰', type='TextMessage'), ToolCallRequestEvent(source='Google_Search_Agent', models_usage=RequestUsage(prompt_tokens=122, completion_tokens=76), metadata={}, content=[FunctionCall(id='call_JAOwPSZHLvT5ves4U6jWSMF6', arguments='{\"query\": \"최신 RAG 기술 동향\", \"num_results\": 2, \"max_chars\": 500}', name='google_search'), FunctionCall(id='call_K0f4UfIxcsCD6SUxqclfdr68', arguments='{\"query\": \"최신 RAG 논문 리뷰\", \"num_results\": 2, \"max_chars\": 500}', name='google_search')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='Google_Search_Agent', models_usage=None, metadata={}, content=[FunctionExecutionResult(content=\"[{'title': '2024 Year Of The RAG :: RAG가 주목 받는 이유와 미래 동향', 'link': 'https://www.skelterlabs.com/blog/2024-year-of-the-rag', 'snippet': 'RAG의 미래는 개인화와 확장성 그리고 정확성에 초점을 맞추며, 다양한 데이터를 처리하고 실시간으로 반응하는 더 똑똑한 시스템으로 발전할 것으로 전망됩니다. 그러나 ...', 'body': '2024 Year Of The RAG :: RAG가 주목 받는 이유와 미래 동향 Company Gen ai Offerings AI Agent 를 활용한 비즈니스 자동화 기업의 복잡한 업무를 독립적으로 수행하는 AI Agent 모델을 구축합니다. RAG 기반 맞춤형 챗봇 등 애플리케이션 개발 RAG 기술로 할루시네이션을 제어하고, 기업 데이터 기반으로 동작해 정확도와 효율을 극대화합니다. Private Data 기반, 기업에 꼭 맞는 LLM 모델 구축 모델 학습에 기업 데이터를 활용해 보안성과 성능을 모두 갖춘 기업향 LLM 모델을 구축합니다. 대고객용 노코드 AI 챗봇 빌더 구축 및 운영 지원 코딩 없이 구축 가능한 AI 챗봇으로, 신속한 고객 응대를 통해 비즈니스 민첩성을 강화합니다. AI 컨택센터 구축을 위한 실시간 STT 및 TTS 모델 제공 한국어 특화 음성 인식과 자연스러운 음성 합성 기술로 고객 커뮤니케이션을 지원합니다. USECASE Newsroom Blog'}, {'title': 'RAG의 짧은 역사 훑어보기(첫 논문부터 최근 동향까지)', 'link': 'https://medium.com/rate-labs/rag%EC%9D%98-%EC%A7%A7%EC%9D%80-%EC%97%AD%EC%82%AC-%ED%9B%91%EC%96%B4%EB%B3%B4%EA%B8%B0-%EC%B2%AB-%EB%85%BC%EB%AC%B8%EB%B6%80%ED%84%B0-%EC%B5%9C%EA%B7%BC-%EB%8F%99%ED%96%A5%EA%B9%8C%EC%A7%80-53c07b9b3bee', 'snippet': '최근 RAG는 모델의 학습이 아닌 모델의 Inference 성능을 레버리지하기 위해 주로 사용되고 있다. RAG는 문서를 어떻게 잘 검색해서 가져오고 LLM에 잘 ...', 'body': 'RAG의 짧은 역사 훑어보기(첫 논문부터 최근 동향까지). 해당 글은 필자의 블로그에 이미 발간된 글입니다. | by Pangyoalto | 취미로 논문 읽는 그룹 | Medium Open in app Sign up Sign in Write Sign up Sign in Home Library Stories Stats 취미로 논문 읽는 그룹 Home About · 가끔 컴퓨터 과학 분야 논문 읽고 발표하는 모임 RAG의 짧은 역사 훑어보기(첫 논문부터 최근 동향까지) Pangyoalto · Follow Published in 취미로 논문 읽는 그룹 · 17 min read · May 11, 2024 -- Share Photo by Rafael de Paiva on Unsplash 해당 글은 필자의 블로그에 이미 발간된 글 입니다. [요약] RAG는 Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks (2020)에서 처음'}]\", name='google_search', call_id='call_JAOwPSZHLvT5ves4U6jWSMF6', is_error=False), FunctionExecutionResult(content=\"[{'title': 'RAG의 짧은 역사 훑어보기(첫 논문부터 최근 동향까지)', 'link': 'https://medium.com/rate-labs/rag%EC%9D%98-%EC%A7%A7%EC%9D%80-%EC%97%AD%EC%82%AC-%ED%9B%91%EC%96%B4%EB%B3%B4%EA%B8%B0-%EC%B2%AB-%EB%85%BC%EB%AC%B8%EB%B6%80%ED%84%B0-%EC%B5%9C%EA%B7%BC-%EB%8F%99%ED%96%A5%EA%B9%8C%EC%A7%80-53c07b9b3bee', 'snippet': '논문에서는 RAG의 모델을 두 가지 제시한다. 완성된 sequence를 생성하기 위해 같은 문서만을 사용하는 모델이다. 각 문서 z마다 beam search를 실행하여 ...', 'body': 'RAG의 짧은 역사 훑어보기(첫 논문부터 최근 동향까지). 해당 글은 필자의 블로그에 이미 발간된 글입니다. | by Pangyoalto | 취미로 논문 읽는 그룹 | Medium Open in app Sign up Sign in Write Sign up Sign in Home Library Stories Stats 취미로 논문 읽는 그룹 Home About · 가끔 컴퓨터 과학 분야 논문 읽고 발표하는 모임 RAG의 짧은 역사 훑어보기(첫 논문부터 최근 동향까지) Pangyoalto · Follow Published in 취미로 논문 읽는 그룹 · 17 min read · May 11, 2024 -- Share Photo by Rafael de Paiva on Unsplash 해당 글은 필자의 블로그에 이미 발간된 글 입니다. [요약] RAG는 Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks (2020)에서 처음'}, {'title': '[논문리뷰] Retrieval-Augmented Generation for Knowledge ...', 'link': 'https://jeonsworld.github.io/NLP/rag/', 'snippet': '언어생성을 위해 Pre-trained model과 non-parametric memory를 결합한 Retrieval-Augmented Generation(RAG)를 제안하고 범용적인 fine-tuning 방법에 대해 제안한다.', 'body': '[논문리뷰] Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks | Deep Learner You need to enable JavaScript to run this app. Deep Learner D L [논문리뷰] Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, Douwe Kiela'}]\", name='google_search', call_id='call_K0f4UfIxcsCD6SUxqclfdr68', is_error=False)], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='Google_Search_Agent', models_usage=None, metadata={}, content=\"[{'title': '2024 Year Of The RAG :: RAG가 주목 받는 이유와 미래 동향', 'link': 'https://www.skelterlabs.com/blog/2024-year-of-the-rag', 'snippet': 'RAG의 미래는 개인화와 확장성 그리고 정확성에 초점을 맞추며, 다양한 데이터를 처리하고 실시간으로 반응하는 더 똑똑한 시스템으로 발전할 것으로 전망됩니다. 그러나 ...', 'body': '2024 Year Of The RAG :: RAG가 주목 받는 이유와 미래 동향 Company Gen ai Offerings AI Agent 를 활용한 비즈니스 자동화 기업의 복잡한 업무를 독립적으로 수행하는 AI Agent 모델을 구축합니다. RAG 기반 맞춤형 챗봇 등 애플리케이션 개발 RAG 기술로 할루시네이션을 제어하고, 기업 데이터 기반으로 동작해 정확도와 효율을 극대화합니다. Private Data 기반, 기업에 꼭 맞는 LLM 모델 구축 모델 학습에 기업 데이터를 활용해 보안성과 성능을 모두 갖춘 기업향 LLM 모델을 구축합니다. 대고객용 노코드 AI 챗봇 빌더 구축 및 운영 지원 코딩 없이 구축 가능한 AI 챗봇으로, 신속한 고객 응대를 통해 비즈니스 민첩성을 강화합니다. AI 컨택센터 구축을 위한 실시간 STT 및 TTS 모델 제공 한국어 특화 음성 인식과 자연스러운 음성 합성 기술로 고객 커뮤니케이션을 지원합니다. USECASE Newsroom Blog'}, {'title': 'RAG의 짧은 역사 훑어보기(첫 논문부터 최근 동향까지)', 'link': 'https://medium.com/rate-labs/rag%EC%9D%98-%EC%A7%A7%EC%9D%80-%EC%97%AD%EC%82%AC-%ED%9B%91%EC%96%B4%EB%B3%B4%EA%B8%B0-%EC%B2%AB-%EB%85%BC%EB%AC%B8%EB%B6%80%ED%84%B0-%EC%B5%9C%EA%B7%BC-%EB%8F%99%ED%96%A5%EA%B9%8C%EC%A7%80-53c07b9b3bee', 'snippet': '최근 RAG는 모델의 학습이 아닌 모델의 Inference 성능을 레버리지하기 위해 주로 사용되고 있다. RAG는 문서를 어떻게 잘 검색해서 가져오고 LLM에 잘 ...', 'body': 'RAG의 짧은 역사 훑어보기(첫 논문부터 최근 동향까지). 해당 글은 필자의 블로그에 이미 발간된 글입니다. | by Pangyoalto | 취미로 논문 읽는 그룹 | Medium Open in app Sign up Sign in Write Sign up Sign in Home Library Stories Stats 취미로 논문 읽는 그룹 Home About · 가끔 컴퓨터 과학 분야 논문 읽고 발표하는 모임 RAG의 짧은 역사 훑어보기(첫 논문부터 최근 동향까지) Pangyoalto · Follow Published in 취미로 논문 읽는 그룹 · 17 min read · May 11, 2024 -- Share Photo by Rafael de Paiva on Unsplash 해당 글은 필자의 블로그에 이미 발간된 글 입니다. [요약] RAG는 Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks (2020)에서 처음'}]\\n[{'title': 'RAG의 짧은 역사 훑어보기(첫 논문부터 최근 동향까지)', 'link': 'https://medium.com/rate-labs/rag%EC%9D%98-%EC%A7%A7%EC%9D%80-%EC%97%AD%EC%82%AC-%ED%9B%91%EC%96%B4%EB%B3%B4%EA%B8%B0-%EC%B2%AB-%EB%85%BC%EB%AC%B8%EB%B6%80%ED%84%B0-%EC%B5%9C%EA%B7%BC-%EB%8F%99%ED%96%A5%EA%B9%8C%EC%A7%80-53c07b9b3bee', 'snippet': '논문에서는 RAG의 모델을 두 가지 제시한다. 완성된 sequence를 생성하기 위해 같은 문서만을 사용하는 모델이다. 각 문서 z마다 beam search를 실행하여 ...', 'body': 'RAG의 짧은 역사 훑어보기(첫 논문부터 최근 동향까지). 해당 글은 필자의 블로그에 이미 발간된 글입니다. | by Pangyoalto | 취미로 논문 읽는 그룹 | Medium Open in app Sign up Sign in Write Sign up Sign in Home Library Stories Stats 취미로 논문 읽는 그룹 Home About · 가끔 컴퓨터 과학 분야 논문 읽고 발표하는 모임 RAG의 짧은 역사 훑어보기(첫 논문부터 최근 동향까지) Pangyoalto · Follow Published in 취미로 논문 읽는 그룹 · 17 min read · May 11, 2024 -- Share Photo by Rafael de Paiva on Unsplash 해당 글은 필자의 블로그에 이미 발간된 글 입니다. [요약] RAG는 Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks (2020)에서 처음'}, {'title': '[논문리뷰] Retrieval-Augmented Generation for Knowledge ...', 'link': 'https://jeonsworld.github.io/NLP/rag/', 'snippet': '언어생성을 위해 Pre-trained model과 non-parametric memory를 결합한 Retrieval-Augmented Generation(RAG)를 제안하고 범용적인 fine-tuning 방법에 대해 제안한다.', 'body': '[논문리뷰] Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks | Deep Learner You need to enable JavaScript to run this app. Deep Learner D L [논문리뷰] Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, Douwe Kiela'}]\", type='ToolCallSummaryMessage'), ToolCallRequestEvent(source='Arxiv_Search_Agent', models_usage=RequestUsage(prompt_tokens=1531, completion_tokens=53), metadata={}, content=[FunctionCall(id='call_2fCCjJI02r9kmpRqTXZal8pj', arguments='{\"query\": \"retrieval-augmented generation\"}', name='arxiv_search'), FunctionCall(id='call_wCu45NzU5QMSgaXizL2BpuB0', arguments='{\"query\": \"RAG trends\"}', name='arxiv_search')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='Arxiv_Search_Agent', models_usage=None, metadata={}, content=[FunctionExecutionResult(content=\"[{'title': 'Generalized Baer and Generalized Quasi-Baer Rings of Skew Generalized Power Series', 'authors': ['M. M. Hamam', 'R. E. Abdel-Khalek', 'R. M. Salem'], 'published': '2024-05-06', 'abstract': 'Let $R$ be a ring with identity, $(S,\\\\\\\\leq)$ an ordered monoid, $\\\\\\\\omega:S \\\\\\\\to\\\\nEnd(R)$ a monoid homomorphism, and $A= R\\\\\\\\left[\\\\\\\\left[S,\\\\\\\\omega \\\\\\\\right]\\\\\\\\right]$\\\\nthe ring of skew generalized power series. The concepts of generalized Baer and\\\\ngeneralized quasi-Baer rings are generalization of Baer and quasi-Baer rings,\\\\nrespectively. A ring $R$ is called generalized right Baer (generalized right\\\\nquasi-Baer) if for any non-empty subset $S$ (right ideal $I$) of $R$, the right\\\\nannihilator of $S^n \\\\\\\\space{0.1cm}(I^n)$ is generated by an idempotent for some\\\\npositive integer $n$. Left cases may be defined analogously. A ring $R$ is\\\\ncalled generalized Baer (generalized quasi-Baer) if it is both generalized\\\\nright and left Baer (generalized right and left quasi-Baer) ring. In this\\\\npaper, we examine the behavior of a skew generalized power series ring over a\\\\ngeneralized right Baer (generalized right quasi-Baer) ring and prove that,\\\\nunder specific conditions, the ring $A$ is generalized right Baer (generalized\\\\nright quasi-Baer) if and only if $R$ is a generalized right Baer (generalized\\\\nright quasi-Baer) ring.', 'pdf_url': 'http://arxiv.org/pdf/2405.03423v2'}, {'title': 'On generalized topological groups', 'authors': ['Murad Hussain', 'Moiz Ud Din Khan', 'Cenap \\\\x7fÖzel'], 'published': '2012-05-17', 'abstract': 'In this work, we will introduce the notion of generalized topological groups\\\\nusing generalized topological structure and generalized continuity defined by\\\\n?A. Cs?asz?ar [2]. We will discuss some basic properties of this kind of\\\\nstructures and connectedness properties of this structures are given. Keywords:\\\\nGeneralized topology; generalized continuity; generalized topological groups;\\\\ngeneralized connectedness.', 'pdf_url': 'http://arxiv.org/pdf/1205.3915v1'}]\", name='arxiv_search', call_id='call_2fCCjJI02r9kmpRqTXZal8pj', is_error=False), FunctionExecutionResult(content='[{\\'title\\': \\'OCR Hinders RAG: Evaluating the Cascading Impact of OCR on Retrieval-Augmented Generation\\', \\'authors\\': [\\'Junyuan Zhang\\', \\'Qintong Zhang\\', \\'Bin Wang\\', \\'Linke Ouyang\\', \\'Zichen Wen\\', \\'Ying Li\\', \\'Ka-Ho Chow\\', \\'Conghui He\\', \\'Wentao Zhang\\'], \\'published\\': \\'2024-12-03\\', \\'abstract\\': \"Retrieval-augmented Generation (RAG) enhances Large Language Models (LLMs) by\\\\nintegrating external knowledge to reduce hallucinations and incorporate\\\\nup-to-date information without retraining. As an essential part of RAG,\\\\nexternal knowledge bases are commonly built by extracting structured data from\\\\nunstructured PDF documents using Optical Character Recognition (OCR). However,\\\\ngiven the imperfect prediction of OCR and the inherent non-uniform\\\\nrepresentation of structured data, knowledge bases inevitably contain various\\\\nOCR noises. In this paper, we introduce OHRBench, the first benchmark for\\\\nunderstanding the cascading impact of OCR on RAG systems. OHRBench includes\\\\n8,561 carefully selected unstructured document images from seven real-world RAG\\\\napplication domains, along with 8,498 Q&A pairs derived from multimodal\\\\nelements in documents, challenging existing OCR solutions used for RAG. To\\\\nbetter understand OCR\\'s impact on RAG systems, we identify two primary types of\\\\nOCR noise: Semantic Noise and Formatting Noise and apply perturbation to\\\\ngenerate a set of structured data with varying degrees of each OCR noise. Using\\\\nOHRBench, we first conduct a comprehensive evaluation of current OCR solutions\\\\nand reveal that none is competent for constructing high-quality knowledge bases\\\\nfor RAG systems. We then systematically evaluate the impact of these two noise\\\\ntypes and demonstrate the trend relationship between the degree of OCR noise\\\\nand RAG performance. Our OHRBench, including PDF documents, Q&As, and the\\\\nground truth structured data are released at:\\\\nhttps://github.com/opendatalab/OHR-Bench\", \\'pdf_url\\': \\'http://arxiv.org/pdf/2412.02592v2\\'}, {\\'title\\': \\'The 2nd FutureDial Challenge: Dialog Systems with Retrieval Augmented Generation (FutureDial-RAG)\\', \\'authors\\': [\\'Yucheng Cai\\', \\'Si Chen\\', \\'Yuxuan Wu\\', \\'Yi Huang\\', \\'Junlan Feng\\', \\'Zhijian Ou\\'], \\'published\\': \\'2024-05-21\\', \\'abstract\\': \\'Recently, increasing research interests have focused on retrieval augmented\\\\ngeneration (RAG) to mitigate hallucination for large language models (LLMs).\\\\nFollowing this trend, we launch the FutureDial-RAG challenge at SLT 2024, which\\\\naims at promoting the study of RAG for dialog systems. The challenge builds\\\\nupon the MobileCS2 dataset, a real-life customer service datasets with nearly\\\\n3000 high-quality dialogs containing annotations for knowledge base query and\\\\ncorresponding results. Over the dataset, we define two tasks, track 1 for\\\\nknowledge retrieval and track 2 for response generation, which are core\\\\nresearch questions in dialog systems with RAG. We build baseline systems for\\\\nthe two tracks and design metrics to measure whether the systems can perform\\\\naccurate retrieval and generate informative and coherent response. The baseline\\\\nresults show that it is very challenging to perform well on the two tasks,\\\\nwhich encourages the participating teams and the community to study how to make\\\\nbetter use of RAG for real-life dialog systems.\\', \\'pdf_url\\': \\'http://arxiv.org/pdf/2405.13084v2\\'}]', name='arxiv_search', call_id='call_wCu45NzU5QMSgaXizL2BpuB0', is_error=False)], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='Arxiv_Search_Agent', models_usage=None, metadata={}, content='[{\\'title\\': \\'Generalized Baer and Generalized Quasi-Baer Rings of Skew Generalized Power Series\\', \\'authors\\': [\\'M. M. Hamam\\', \\'R. E. Abdel-Khalek\\', \\'R. M. Salem\\'], \\'published\\': \\'2024-05-06\\', \\'abstract\\': \\'Let $R$ be a ring with identity, $(S,\\\\\\\\leq)$ an ordered monoid, $\\\\\\\\omega:S \\\\\\\\to\\\\nEnd(R)$ a monoid homomorphism, and $A= R\\\\\\\\left[\\\\\\\\left[S,\\\\\\\\omega \\\\\\\\right]\\\\\\\\right]$\\\\nthe ring of skew generalized power series. The concepts of generalized Baer and\\\\ngeneralized quasi-Baer rings are generalization of Baer and quasi-Baer rings,\\\\nrespectively. A ring $R$ is called generalized right Baer (generalized right\\\\nquasi-Baer) if for any non-empty subset $S$ (right ideal $I$) of $R$, the right\\\\nannihilator of $S^n \\\\\\\\space{0.1cm}(I^n)$ is generated by an idempotent for some\\\\npositive integer $n$. Left cases may be defined analogously. A ring $R$ is\\\\ncalled generalized Baer (generalized quasi-Baer) if it is both generalized\\\\nright and left Baer (generalized right and left quasi-Baer) ring. In this\\\\npaper, we examine the behavior of a skew generalized power series ring over a\\\\ngeneralized right Baer (generalized right quasi-Baer) ring and prove that,\\\\nunder specific conditions, the ring $A$ is generalized right Baer (generalized\\\\nright quasi-Baer) if and only if $R$ is a generalized right Baer (generalized\\\\nright quasi-Baer) ring.\\', \\'pdf_url\\': \\'http://arxiv.org/pdf/2405.03423v2\\'}, {\\'title\\': \\'On generalized topological groups\\', \\'authors\\': [\\'Murad Hussain\\', \\'Moiz Ud Din Khan\\', \\'Cenap \\\\x7fÖzel\\'], \\'published\\': \\'2012-05-17\\', \\'abstract\\': \\'In this work, we will introduce the notion of generalized topological groups\\\\nusing generalized topological structure and generalized continuity defined by\\\\n?A. Cs?asz?ar [2]. We will discuss some basic properties of this kind of\\\\nstructures and connectedness properties of this structures are given. Keywords:\\\\nGeneralized topology; generalized continuity; generalized topological groups;\\\\ngeneralized connectedness.\\', \\'pdf_url\\': \\'http://arxiv.org/pdf/1205.3915v1\\'}]\\n[{\\'title\\': \\'OCR Hinders RAG: Evaluating the Cascading Impact of OCR on Retrieval-Augmented Generation\\', \\'authors\\': [\\'Junyuan Zhang\\', \\'Qintong Zhang\\', \\'Bin Wang\\', \\'Linke Ouyang\\', \\'Zichen Wen\\', \\'Ying Li\\', \\'Ka-Ho Chow\\', \\'Conghui He\\', \\'Wentao Zhang\\'], \\'published\\': \\'2024-12-03\\', \\'abstract\\': \"Retrieval-augmented Generation (RAG) enhances Large Language Models (LLMs) by\\\\nintegrating external knowledge to reduce hallucinations and incorporate\\\\nup-to-date information without retraining. As an essential part of RAG,\\\\nexternal knowledge bases are commonly built by extracting structured data from\\\\nunstructured PDF documents using Optical Character Recognition (OCR). However,\\\\ngiven the imperfect prediction of OCR and the inherent non-uniform\\\\nrepresentation of structured data, knowledge bases inevitably contain various\\\\nOCR noises. In this paper, we introduce OHRBench, the first benchmark for\\\\nunderstanding the cascading impact of OCR on RAG systems. OHRBench includes\\\\n8,561 carefully selected unstructured document images from seven real-world RAG\\\\napplication domains, along with 8,498 Q&A pairs derived from multimodal\\\\nelements in documents, challenging existing OCR solutions used for RAG. To\\\\nbetter understand OCR\\'s impact on RAG systems, we identify two primary types of\\\\nOCR noise: Semantic Noise and Formatting Noise and apply perturbation to\\\\ngenerate a set of structured data with varying degrees of each OCR noise. Using\\\\nOHRBench, we first conduct a comprehensive evaluation of current OCR solutions\\\\nand reveal that none is competent for constructing high-quality knowledge bases\\\\nfor RAG systems. We then systematically evaluate the impact of these two noise\\\\ntypes and demonstrate the trend relationship between the degree of OCR noise\\\\nand RAG performance. Our OHRBench, including PDF documents, Q&As, and the\\\\nground truth structured data are released at:\\\\nhttps://github.com/opendatalab/OHR-Bench\", \\'pdf_url\\': \\'http://arxiv.org/pdf/2412.02592v2\\'}, {\\'title\\': \\'The 2nd FutureDial Challenge: Dialog Systems with Retrieval Augmented Generation (FutureDial-RAG)\\', \\'authors\\': [\\'Yucheng Cai\\', \\'Si Chen\\', \\'Yuxuan Wu\\', \\'Yi Huang\\', \\'Junlan Feng\\', \\'Zhijian Ou\\'], \\'published\\': \\'2024-05-21\\', \\'abstract\\': \\'Recently, increasing research interests have focused on retrieval augmented\\\\ngeneration (RAG) to mitigate hallucination for large language models (LLMs).\\\\nFollowing this trend, we launch the FutureDial-RAG challenge at SLT 2024, which\\\\naims at promoting the study of RAG for dialog systems. The challenge builds\\\\nupon the MobileCS2 dataset, a real-life customer service datasets with nearly\\\\n3000 high-quality dialogs containing annotations for knowledge base query and\\\\ncorresponding results. Over the dataset, we define two tasks, track 1 for\\\\nknowledge retrieval and track 2 for response generation, which are core\\\\nresearch questions in dialog systems with RAG. We build baseline systems for\\\\nthe two tracks and design metrics to measure whether the systems can perform\\\\naccurate retrieval and generate informative and coherent response. The baseline\\\\nresults show that it is very challenging to perform well on the two tasks,\\\\nwhich encourages the participating teams and the community to study how to make\\\\nbetter use of RAG for real-life dialog systems.\\', \\'pdf_url\\': \\'http://arxiv.org/pdf/2405.13084v2\\'}]', type='ToolCallSummaryMessage'), TextMessage(source='Report_Agent', models_usage=RequestUsage(prompt_tokens=2808, completion_tokens=1484), metadata={}, content='# 최신 RAG(Retrieval-Augmented Generation) 기술 동향 및 관련 논문에 대한 리뷰\\n\\n## 서론\\nRetrieval-Augmented Generation(RAG)은 외부 지식을 활용하여 대규모 언어 모델(LLM)의 성능을 강화하고 할루시네이션을 줄이며 최신 정보와의 통합을 가능하게 하는 혁신적인 방법입니다. 이는 생성적 언어 모델의 성능을 향상시키기 위해 검색 및 생성의 두 가지 작업을 결합한 접근 방식이라 할 수 있습니다. 이러한 기술은 특히 지식 집약적인 NLP 작업에서 주목받고 있으며, 학계와 산업계 모두에서 활발히 연구되고 있습니다.\\n\\n본 리뷰에서는 최신 RAG 기술의 정의와 활용 사례, 주요 연구 흐름, 현재의 한계점 및 앞으로의 개선 방향을 다룰 것입니다.\\n\\n---\\n\\n## 최신 RAG 기술 동향\\n\\n### RAG의 정의와 발전\\nRAG는 최초로 **Lewis et al. (2020)**에 의해 도입되었으며, \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\"라는 논문에서 그 주요 개념이 설명되었습니다. 이 기술은 사전 학습된 언어 모델과 외부 메모리(주로 문서 베이스)를 결합하여 더 정확하고 지식 기반의 텍스트 생성을 구현합니다(Lewis et al., 2020).\\n\\nRAG의 기술적 핵심은 두 가지입니다:\\n1. **정보 검색(Search)**: 입력된 질문이나 요청에 대해 가장 관련성이 높은 문서를 검색합니다.\\n2. **텍스트 생성(Generation)**: 검색된 문서를 기반으로 생성된 텍스트를 반환합니다.\\n\\n최근에는 기존의 정형화된 단일 데이터 소스뿐만 아니라 비정형 데이터(PDF, 이미지 등)로부터 정보를 처리하는 방향으로 발전하고 있습니다(Jeon, 2020).\\n\\n---\\n\\n### 사례 연구: 다양한 응용 분야\\n1. **고객 서비스 챗봇 및 대화형 시스템**  \\n   최신 연구에서 RAG는 고객 등의 특화된 질문에 즉각적으로 응답할 수 있는 대화형 시스템에 활용되고 있습니다. FutureDial-RAG 챌린지(SLT 2024)에서는 RAG의 활용을 중심으로 지식 검색 및 응답 생성 트랙을 설정하여 실제 고객 서비스에서의 성능을 평가하였습니다(Cai et al., 2024).\\n\\n2. **OCR 기반 RAG**  \\n   Optical Character Recognition(OCR) 기술이 통합된 RAG 시스템은 특히 PDF 문서와 같은 비정형 데이터를 처리하는 데 사용됩니다. Zhang et al. (2024)은 \"OHRBench\"라는 벤치마크를 통해 OCR 오류가 RAG 성능에 미치는 영향을 체계적으로 분석하였습니다. 이는 체계적인 지식 베이스 구축 과정에서 OCR의 중요성과 한계를 명확히 보여주었습니다.\\n\\n---\\n\\n## 최신 연구 결과 및 관련 논문\\n\\n### 선행 논문\\n1. **Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks**  \\n   이 논문은 RAG의 원리를 제시한 최초의 연구로, LLM과 외부 문서 검색 시스템의 통합에 대한 아이디어를 소개하였습니다(Lewis et al., 2020).\\n\\n### 최신 연구 발표\\n2. **The 2nd FutureDial Challenge: Dialog Systems with Retrieval-Augmented Generation**  \\n   본 연구는 FutureDial-RAG 챌린지를 소개하며, 두 가지 주요 작업(지식 검색 및 응답 생성)에 대한 성과와 어려움을 다루었습니다. 이를 통해 실무 환경에서 RAG 시스템의 도전 과제를 제시합니다(Cai et al., 2024).\\n\\n3. **OCR Hinders RAG: Evaluating the Cascading Impact of OCR on Retrieval-Augmented Generation**  \\n   Zhang et al.의 연구는 OCR 기술이 RAG 시스템의 지식 정확도와 텍스트 생성 품질에 끼치는 부정적인 영향을 실험적으로 입증하였습니다(Zhang et al., 2024). 이를 통해 RAG 시스템의 성능 최적화를 위한 방향성을 제안하였습니다.\\n\\n---\\n\\n## 한계점 및 개선 방향\\n\\n### 한계점\\n1. **할루시네이션 문제**  \\n   LLM은 여전히 잘못된 정보를 생성할 가능성이 높습니다. 이는 지식 검색 과정이 부정확하거나 생성 모델이 충분히 문맥을 반영하지 못하는 경우 발생합니다.\\n\\n2. **시스템 복잡성**  \\n   검색 및 생성 모듈의 조합은 시스템의 구현과 유지보수를 어렵게 만듭니다.\\n\\n3. **비정형 데이터의 통합 문제**  \\n   OCR과 같은 전처리 과정이 완벽하지 않을 경우 잘못된 정보를 기반으로 한 잘못된 텍스트가 생성될 수 있습니다(Zhang et al., 2024).\\n\\n### 개선 방향\\n- **지식 기반 강화학습 도입**  \\n  검색 및 생성 모델을 통합적으로 학습시키기 위해 강화학습 기반 접근 방식을 활용할 수 있습니다.\\n  \\n- **데이터 품질 개선**  \\n  OCR 기술의 정밀도를 향상시키고, 사전 처리 과정에서 발생하는 오류를 최소화하는 연구가 필요합니다(Zhang et al., 2024).\\n\\n- **경량화된 모델 개발**  \\n  복잡한 검색-생성 과정을 최적화하는 단순화된 아키텍처 설계가 중요합니다.\\n\\n---\\n\\n## 결론\\nRAG는 지식 기반 NLP 작업에서 강력한 도구로 자리매김하고 있습니다. 최신 연구들은 RAG의 정확성과 응용 가능성을 높이기 위해 다양한 발전 방향을 제안하고 있습니다. 그러나 여전히 OCR, 비정형 데이터 통합 등 실용적 측면에서의 도전 과제가 존재하며, 차세대 RAG 기술은 보다 현실적인 문제를 해결하는 방향으로 발전할 것으로 전망됩니다.\\n\\n---\\n\\n## 참고 문헌\\n1. Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., & Riedel, S. (2020). \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\". *arXiv preprint arXiv:2005.11401.*\\n2. Cai, Y., Chen, S., Wu, Y., Huang, Y., Feng, J., & Ou, Z. (2024). \"The 2nd FutureDial Challenge: Dialog Systems with Retrieval Augmented Generation\". *arXiv preprint arXiv:2405.13084.*\\n3. Zhang, J., Zhang, Q., Wang, B., Ouyang, L., Wen, Z., Li, Y., & Zhang, W. (2024). \"OCR Hinders RAG: Evaluating the Cascading Impact of OCR on Retrieval-Augmented Generation\". *arXiv preprint arXiv:2412.02592.*\\n\\nTERMINATE', type='TextMessage')], stop_reason=\"Text 'TERMINATE' mentioned\")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await Console(\n",
    "    team.run_stream(\n",
    "        # task=\"멀티 에이전트 AI 시스템 구축을 위한한 논문 리뷰 리포트 작성\",\n",
    "        task=\"최신 RAG 기술에 대한 동향 및 논문 리뷰\",\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

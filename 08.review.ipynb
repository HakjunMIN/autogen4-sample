{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: arxiv in ./.venv/lib/python3.11/site-packages (2.1.3)\n",
      "Requirement already satisfied: feedparser~=6.0.10 in ./.venv/lib/python3.11/site-packages (from arxiv) (6.0.11)\n",
      "Requirement already satisfied: requests~=2.32.0 in ./.venv/lib/python3.11/site-packages (from arxiv) (2.32.3)\n",
      "Requirement already satisfied: sgmllib3k in ./.venv/lib/python3.11/site-packages (from feedparser~=6.0.10->arxiv) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests~=2.32.0->arxiv) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests~=2.32.0->arxiv) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests~=2.32.0->arxiv) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests~=2.32.0->arxiv) (2024.12.14)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andy/works/openai/autogen04-sample/.venv/lib/python3.11/site-packages/autogen_ext/models/openai/_openai_client.py:1029: UserWarning: Previous behavior of using the model name as the deployment name is deprecated and will be removed in 0.4. Please specify azure_deployment\n",
      "  client = _azure_openai_client_from_config(copied_args)\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_core.tools import FunctionTool\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_chat_completion_client = AzureOpenAIChatCompletionClient(\n",
    "            model=\"gpt-4o\",\n",
    "            azure_endpoint=azure_endpoint,\n",
    "            api_version=api_version,\n",
    "            api_key=api_key,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_search(query: str, num_results: int = 2, max_chars: int = 500) -> list:  # type: ignore[type-arg]\n",
    "    import os\n",
    "    import time\n",
    "\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "    serp_api_key = os.getenv(\"SERPAPI_KEY\")\n",
    "\n",
    "    if not serp_api_key:\n",
    "        raise ValueError(\"SerpAPI key not found in environment variables\")\n",
    "\n",
    "    url = \"https://serpapi.com/search\"\n",
    "    params = {\n",
    "        \"engine\": \"google\",\n",
    "        \"q\": query,\n",
    "        \"num\": num_results,\n",
    "        \"api_key\": serp_api_key,\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(response.json())\n",
    "        raise Exception(f\"Error in API request: {response.status_code}\")\n",
    "\n",
    "    results = response.json().get(\"organic_results\", [])\n",
    "\n",
    "    def get_page_content(url: str) -> str:\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            text = soup.get_text(separator=\" \", strip=True)\n",
    "            words = text.split()\n",
    "            content = \"\"\n",
    "            for word in words:\n",
    "                if len(content) + len(word) + 1 > max_chars:\n",
    "                    break\n",
    "                content += \" \" + word\n",
    "            return content.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {url}: {str(e)}\")\n",
    "            return \"\"\n",
    "\n",
    "    enriched_results = []\n",
    "    for item in results:\n",
    "        body = get_page_content(item[\"link\"])\n",
    "        enriched_results.append(\n",
    "            {\"title\": item[\"title\"], \"link\": item[\"link\"], \"snippet\": item.get(\"snippet\", \"\"), \"body\": body}\n",
    "        )\n",
    "        time.sleep(1)  # Be respectful to the servers\n",
    "\n",
    "    print(enriched_results)    \n",
    "\n",
    "    return enriched_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arxiv_search(query: str, max_results: int = 2) -> list:  # type: ignore[type-arg]\n",
    "    \"\"\"\n",
    "    Search Arxiv for papers and return the results including abstracts.\n",
    "    \"\"\"\n",
    "    import arxiv\n",
    "\n",
    "    client = arxiv.Client()\n",
    "    search = arxiv.Search(query=query, max_results=max_results, sort_by=arxiv.SortCriterion.Relevance)\n",
    "\n",
    "    results = []\n",
    "    for paper in client.results(search):\n",
    "        results.append(\n",
    "            {\n",
    "                \"title\": paper.title,\n",
    "                \"authors\": [author.name for author in paper.authors],\n",
    "                \"published\": paper.published.strftime(\"%Y-%m-%d\"),\n",
    "                \"abstract\": paper.summary,\n",
    "                \"pdf_url\": paper.pdf_url,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # # Write results to a file\n",
    "    # with open('arxiv_search_results.json', 'w') as f:\n",
    "    #     json.dump(results, f, indent=2)\n",
    "    print(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_search_tool = FunctionTool(\n",
    "    google_search, description=\"Search Google for information, returns results with a snippet and body content\"\n",
    ")\n",
    "arxiv_search_tool = FunctionTool(\n",
    "    arxiv_search, description=\"Search Arxiv for papers related to a given topic, including abstracts\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_search_agent = AssistantAgent(\n",
    "    name=\"Google_Search_Agent\",\n",
    "    tools=[google_search_tool],\n",
    "    model_client=azure_openai_chat_completion_client,\n",
    "    description=\"An agent that can search Google for information, returns results with a snippet and body content\",\n",
    "    system_message=\"You are a helpful AI assistant. Solve tasks using your tools.\",\n",
    ")\n",
    "\n",
    "arxiv_search_agent = AssistantAgent(\n",
    "    name=\"Arxiv_Search_Agent\",\n",
    "    tools=[arxiv_search_tool],\n",
    "    model_client=azure_openai_chat_completion_client,\n",
    "    description=\"An agent that can search Arxiv for papers related to a given topic, including abstracts\",\n",
    "    system_message=\"You are a helpful AI assistant. Solve tasks using your tools. Specifically, you can take into consideration the user's request and craft a search query that is most likely to return relevant academi papers.\",\n",
    ")\n",
    "\n",
    "\n",
    "report_agent = AssistantAgent(\n",
    "    name=\"Report_Agent\",\n",
    "    model_client=azure_openai_chat_completion_client,\n",
    "    description=\"Generate a report based on a given topic\",\n",
    "    system_message=\"You are a helpful assistant. Your task is to synthesize data extracted into a high quality literature review including CORRECT references. You MUST write a final report that is formatted as a literature review with CORRECT references.  Your response should end with the word 'TERMINATE'\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "termination = TextMentionTermination(\"TERMINATE\")\n",
    "team = RoundRobinGroupChat(\n",
    "    participants=[google_search_agent, arxiv_search_agent, report_agent], termination_condition=termination\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "최신 RAG 기술에 대한 동향 및 논문 리뷰\n",
      "---------- Google_Search_Agent ----------\n",
      "[FunctionCall(id='call_Kts8sCafod2fGJzziWGpXpdO', arguments='{\"query\": \"current trends in RAG technology\", \"num_results\": 2}', name='google_search'), FunctionCall(id='call_EUHkCPGhBjELZbwqquPGwLA9', arguments='{\"query\": \"recent papers on Retrieval-Augmented Generation (RAG)\", \"num_results\": 2}', name='google_search')]\n",
      "[Prompt tokens: 6590, Completion tokens: 69]\n",
      "---------- Google_Search_Agent ----------\n",
      "[FunctionExecutionResult(content=\"[{'title': 'Latest Developments in Retrieval-Augmented Generation', 'link': 'https://celerdata.com/glossary/latest-developments-in-retrieval-augmented-generation', 'snippet': 'The future of RAG looks promising with continued advancements in technology, model architectures, and training methodologies driving innovation ...', 'body': 'Latest Developments in Retrieval-Augmented Generation PRODUCTS PRODUCTS CelerData Overview CelerData Cloud BYOC SOLUTIONS USE CASES Lakehouse Analytics Real-Time Analytics Customer-Facing Analytics TECHNOLOGY ALTERNATIVES Trino/Presto ClickHouse Apache Druid ENHANCEMENTS Apache Iceberg STARROCKS RESOURCES RESOURCES CelerData Blog Documentation Whitepapers & Case Studies Webinars & Videos Glossary Events COMPANY COMPANY About Us Partners Newsroom Careers Contact Us Free Trial Latest Developments'}, {'title': '2024 AI Trends to Watch Out for: The Rise of RAG and MoE', 'link': 'https://flock-io.medium.com/2024-ai-trends-to-watch-out-for-the-rise-of-rag-and-moe-883cf1985fd1', 'snippet': 'The integration of RAG and MoE represents a significant step forward in AI, providing more efficient and tailored experiences. These ...', 'body': '2024 AI Trends to Watch Out for: The Rise of RAG and MoE | by FLock.io | Medium Open in app Sign up Sign in Write Sign up Sign in 2024 AI Trends to Watch Out for: The Rise of RAG and MoE FLock.io · Follow 3 min read · Jan 14, 2024 -- Listen Share As we delve into 2024, Retrieval-Augmented Generation (RAG) and Mixture of Experts (MoE) stand out as the two key technologies in the realm of artificial intelligence (AI) to watch. These technologies are reshaping the way AI systems process'}]\", call_id='call_Kts8sCafod2fGJzziWGpXpdO'), FunctionExecutionResult(content='[{\\'title\\': \\'[2410.12837] A Comprehensive Survey of Retrieval ...\\', \\'link\\': \\'https://arxiv.org/abs/2410.12837\\', \\'snippet\\': \\'This paper presents a comprehensive study of Retrieval-Augmented Generation (RAG), tracing its evolution from foundational concepts to the ...\\', \\'body\\': \"[2410.12837] A Comprehensive Survey of Retrieval-Augmented Generation (RAG): Evolution, Current Landscape and Future Directions Change to arXiv\\'s privacy policy The arXiv Privacy Policy has changed. By continuing to use arxiv.org, you are agreeing to the privacy policy. I Understand Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate > cs > arXiv:2410.12837 Help | Advanced Search All fields Title Author Abstract\"}, {\\'title\\': \\'RAG\\', \\'link\\': \\'https://paperswithcode.com/task/rag\\', \\'snippet\\': \\'We introduce RAGAs (Retrieval Augmented Generation Assessment), a framework for reference-free evaluation of Retrieval Augmented Generation (RAG) pipelines. 2.\\', \\'body\\': \"RAG | Papers With Code Browse State-of-the-Art Datasets Methods More Newsletter RC2022 About Trends Portals Libraries Sign In Subscribe to the PwC Newsletter × Stay informed on the latest trending ML papers with code, research developments, libraries, methods, and datasets. Read previous issues Subscribe Join the community × You need to log in to edit. You can create a new account if you don\\'t have one. Edit task × Task name: * Top-level area: * --------- Adversarial Audio Computer Code\"}]', call_id='call_EUHkCPGhBjELZbwqquPGwLA9')]\n",
      "---------- Google_Search_Agent ----------\n",
      "[{'title': 'Latest Developments in Retrieval-Augmented Generation', 'link': 'https://celerdata.com/glossary/latest-developments-in-retrieval-augmented-generation', 'snippet': 'The future of RAG looks promising with continued advancements in technology, model architectures, and training methodologies driving innovation ...', 'body': 'Latest Developments in Retrieval-Augmented Generation PRODUCTS PRODUCTS CelerData Overview CelerData Cloud BYOC SOLUTIONS USE CASES Lakehouse Analytics Real-Time Analytics Customer-Facing Analytics TECHNOLOGY ALTERNATIVES Trino/Presto ClickHouse Apache Druid ENHANCEMENTS Apache Iceberg STARROCKS RESOURCES RESOURCES CelerData Blog Documentation Whitepapers & Case Studies Webinars & Videos Glossary Events COMPANY COMPANY About Us Partners Newsroom Careers Contact Us Free Trial Latest Developments'}, {'title': '2024 AI Trends to Watch Out for: The Rise of RAG and MoE', 'link': 'https://flock-io.medium.com/2024-ai-trends-to-watch-out-for-the-rise-of-rag-and-moe-883cf1985fd1', 'snippet': 'The integration of RAG and MoE represents a significant step forward in AI, providing more efficient and tailored experiences. These ...', 'body': '2024 AI Trends to Watch Out for: The Rise of RAG and MoE | by FLock.io | Medium Open in app Sign up Sign in Write Sign up Sign in 2024 AI Trends to Watch Out for: The Rise of RAG and MoE FLock.io · Follow 3 min read · Jan 14, 2024 -- Listen Share As we delve into 2024, Retrieval-Augmented Generation (RAG) and Mixture of Experts (MoE) stand out as the two key technologies in the realm of artificial intelligence (AI) to watch. These technologies are reshaping the way AI systems process'}]\n",
      "[{'title': '[2410.12837] A Comprehensive Survey of Retrieval ...', 'link': 'https://arxiv.org/abs/2410.12837', 'snippet': 'This paper presents a comprehensive study of Retrieval-Augmented Generation (RAG), tracing its evolution from foundational concepts to the ...', 'body': \"[2410.12837] A Comprehensive Survey of Retrieval-Augmented Generation (RAG): Evolution, Current Landscape and Future Directions Change to arXiv's privacy policy The arXiv Privacy Policy has changed. By continuing to use arxiv.org, you are agreeing to the privacy policy. I Understand Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate > cs > arXiv:2410.12837 Help | Advanced Search All fields Title Author Abstract\"}, {'title': 'RAG', 'link': 'https://paperswithcode.com/task/rag', 'snippet': 'We introduce RAGAs (Retrieval Augmented Generation Assessment), a framework for reference-free evaluation of Retrieval Augmented Generation (RAG) pipelines. 2.', 'body': \"RAG | Papers With Code Browse State-of-the-Art Datasets Methods More Newsletter RC2022 About Trends Portals Libraries Sign In Subscribe to the PwC Newsletter × Stay informed on the latest trending ML papers with code, research developments, libraries, methods, and datasets. Read previous issues Subscribe Join the community × You need to log in to edit. You can create a new account if you don't have one. Edit task × Task name: * Top-level area: * --------- Adversarial Audio Computer Code\"}]\n",
      "---------- Arxiv_Search_Agent ----------\n",
      "[FunctionCall(id='call_R4ODhDFZWKlFo2lHOgdXVS7l', arguments='{\"query\":\"latest trends in Retrieval-Augmented Generation (RAG)\",\"max_results\":5}', name='arxiv_search')]\n",
      "[Prompt tokens: 7455, Completion tokens: 30]\n",
      "---------- Arxiv_Search_Agent ----------\n",
      "[FunctionExecutionResult(content='[{\\'title\\': \\'Towards Fair RAG: On the Impact of Fair Ranking in Retrieval-Augmented Generation\\', \\'authors\\': [\\'To Eun Kim\\', \\'Fernando Diaz\\'], \\'published\\': \\'2024-09-17\\', \\'abstract\\': \\'Many language models now enhance their responses with retrieval capabilities,\\\\nleading to the widespread adoption of retrieval-augmented generation (RAG)\\\\nsystems. However, despite retrieval being a core component of RAG, much of the\\\\nresearch in this area overlooks the extensive body of work on fair ranking,\\\\nneglecting the importance of considering all stakeholders involved. This paper\\\\npresents the first systematic evaluation of RAG systems integrated with fair\\\\nrankings. We focus specifically on measuring the fair exposure of each relevant\\\\nitem across the rankings utilized by RAG systems (i.e., item-side fairness),\\\\naiming to promote equitable growth for relevant item providers. To gain a deep\\\\nunderstanding of the relationship between item-fairness, ranking quality, and\\\\ngeneration quality in the context of RAG, we analyze nine different RAG systems\\\\nthat incorporate fair rankings across seven distinct datasets. Our findings\\\\nindicate that RAG systems with fair rankings can maintain a high level of\\\\ngeneration quality and, in many cases, even outperform traditional RAG systems,\\\\ndespite the general trend of a tradeoff between ensuring fairness and\\\\nmaintaining system-effectiveness. We believe our insights lay the groundwork\\\\nfor responsible and equitable RAG systems and open new avenues for future\\\\nresearch. We publicly release our codebase and dataset at\\\\nhttps://github.com/kimdanny/Fair-RAG.\\', \\'pdf_url\\': \\'http://arxiv.org/pdf/2409.11598v2\\'}, {\\'title\\': \\'A RAG-Based Question-Answering Solution for Cyber-Attack Investigation and Attribution\\', \\'authors\\': [\\'Sampath Rajapaksha\\', \\'Ruby Rani\\', \\'Erisa Karafili\\'], \\'published\\': \\'2024-08-12\\', \\'abstract\\': \"In the constantly evolving field of cybersecurity, it is imperative for\\\\nanalysts to stay abreast of the latest attack trends and pertinent information\\\\nthat aids in the investigation and attribution of cyber-attacks. In this work,\\\\nwe introduce the first question-answering (QA) model and its application that\\\\nprovides information to the cybersecurity experts about cyber-attacks\\\\ninvestigations and attribution. Our QA model is based on Retrieval Augmented\\\\nGeneration (RAG) techniques together with a Large Language Model (LLM) and\\\\nprovides answers to the users\\' queries based on either our knowledge base (KB)\\\\nthat contains curated information about cyber-attacks investigations and\\\\nattribution or on outside resources provided by the users. We have tested and\\\\nevaluated our QA model with various types of questions, including KB-based,\\\\nmetadata-based, specific documents from the KB, and external sources-based\\\\nquestions. We compared the answers for KB-based questions with those from\\\\nOpenAI\\'s GPT-3.5 and the latest GPT-4o LLMs. Our proposed QA model outperforms\\\\nOpenAI\\'s GPT models by providing the source of the answers and overcoming the\\\\nhallucination limitations of the GPT models, which is critical for cyber-attack\\\\ninvestigation and attribution. Additionally, our analysis showed that when the\\\\nRAG QA model is given few-shot examples rather than zero-shot instructions, it\\\\ngenerates better answers compared to cases where no examples are supplied in\\\\naddition to the query.\", \\'pdf_url\\': \\'http://arxiv.org/pdf/2408.06272v1\\'}, {\\'title\\': \\'Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive Study and Hybrid Approach\\', \\'authors\\': [\\'Zhuowan Li\\', \\'Cheng Li\\', \\'Mingyang Zhang\\', \\'Qiaozhu Mei\\', \\'Michael Bendersky\\'], \\'published\\': \\'2024-07-23\\', \\'abstract\\': \"Retrieval Augmented Generation (RAG) has been a powerful tool for Large\\\\nLanguage Models (LLMs) to efficiently process overly lengthy contexts. However,\\\\nrecent LLMs like Gemini-1.5 and GPT-4 show exceptional capabilities to\\\\nunderstand long contexts directly. We conduct a comprehensive comparison\\\\nbetween RAG and long-context (LC) LLMs, aiming to leverage the strengths of\\\\nboth. We benchmark RAG and LC across various public datasets using three latest\\\\nLLMs. Results reveal that when resourced sufficiently, LC consistently\\\\noutperforms RAG in terms of average performance. However, RAG\\'s significantly\\\\nlower cost remains a distinct advantage. Based on this observation, we propose\\\\nSelf-Route, a simple yet effective method that routes queries to RAG or LC\\\\nbased on model self-reflection. Self-Route significantly reduces the\\\\ncomputation cost while maintaining a comparable performance to LC. Our findings\\\\nprovide a guideline for long-context applications of LLMs using RAG and LC.\", \\'pdf_url\\': \\'http://arxiv.org/pdf/2407.16833v2\\'}, {\\'title\\': \\'Mask-based Membership Inference Attacks for Retrieval-Augmented Generation\\', \\'authors\\': [\\'Mingrui Liu\\', \\'Sixiao Zhang\\', \\'Cheng Long\\'], \\'published\\': \\'2024-10-26\\', \\'abstract\\': \"Retrieval-Augmented Generation (RAG) has been an effective approach to\\\\nmitigate hallucinations in large language models (LLMs) by incorporating\\\\nup-to-date and domain-specific knowledge. Recently, there has been a trend of\\\\nstoring up-to-date or copyrighted data in RAG knowledge databases instead of\\\\nusing it for LLM training. This practice has raised concerns about Membership\\\\nInference Attacks (MIAs), which aim to detect if a specific target document is\\\\nstored in the RAG system\\'s knowledge database so as to protect the rights of\\\\ndata producers. While research has focused on enhancing the trustworthiness of\\\\nRAG systems, existing MIAs for RAG systems remain largely insufficient.\\\\nPrevious work either relies solely on the RAG system\\'s judgment or is easily\\\\ninfluenced by other documents or the LLM\\'s internal knowledge, which is\\\\nunreliable and lacks explainability. To address these limitations, we propose a\\\\nMask-Based Membership Inference Attacks (MBA) framework. Our framework first\\\\nemploys a masking algorithm that effectively masks a certain number of words in\\\\nthe target document. The masked text is then used to prompt the RAG system, and\\\\nthe RAG system is required to predict the mask values. If the target document\\\\nappears in the knowledge database, the masked text will retrieve the complete\\\\ntarget document as context, allowing for accurate mask prediction. Finally, we\\\\nadopt a simple yet effective threshold-based method to infer the membership of\\\\ntarget document by analyzing the accuracy of mask prediction. Our mask-based\\\\napproach is more document-specific, making the RAG system\\'s generation less\\\\nsusceptible to distractions from other documents or the LLM\\'s internal\\\\nknowledge. Extensive experiments demonstrate the effectiveness of our approach\\\\ncompared to existing baseline models.\", \\'pdf_url\\': \\'http://arxiv.org/pdf/2410.20142v1\\'}, {\\'title\\': \\'The 2nd FutureDial Challenge: Dialog Systems with Retrieval Augmented Generation (FutureDial-RAG)\\', \\'authors\\': [\\'Yucheng Cai\\', \\'Si Chen\\', \\'Yuxuan Wu\\', \\'Yi Huang\\', \\'Junlan Feng\\', \\'Zhijian Ou\\'], \\'published\\': \\'2024-05-21\\', \\'abstract\\': \\'Recently, increasing research interests have focused on retrieval augmented\\\\ngeneration (RAG) to mitigate hallucination for large language models (LLMs).\\\\nFollowing this trend, we launch the FutureDial-RAG challenge at SLT 2024, which\\\\naims at promoting the study of RAG for dialog systems. The challenge builds\\\\nupon the MobileCS2 dataset, a real-life customer service datasets with nearly\\\\n3000 high-quality dialogs containing annotations for knowledge base query and\\\\ncorresponding results. Over the dataset, we define two tasks, track 1 for\\\\nknowledge retrieval and track 2 for response generation, which are core\\\\nresearch questions in dialog systems with RAG. We build baseline systems for\\\\nthe two tracks and design metrics to measure whether the systems can perform\\\\naccurate retrieval and generate informative and coherent response. The baseline\\\\nresults show that it is very challenging to perform well on the two tasks,\\\\nwhich encourages the participating teams and the community to study how to make\\\\nbetter use of RAG for real-life dialog systems.\\', \\'pdf_url\\': \\'http://arxiv.org/pdf/2405.13084v2\\'}]', call_id='call_R4ODhDFZWKlFo2lHOgdXVS7l')]\n",
      "---------- Arxiv_Search_Agent ----------\n",
      "[{'title': 'Towards Fair RAG: On the Impact of Fair Ranking in Retrieval-Augmented Generation', 'authors': ['To Eun Kim', 'Fernando Diaz'], 'published': '2024-09-17', 'abstract': 'Many language models now enhance their responses with retrieval capabilities,\\nleading to the widespread adoption of retrieval-augmented generation (RAG)\\nsystems. However, despite retrieval being a core component of RAG, much of the\\nresearch in this area overlooks the extensive body of work on fair ranking,\\nneglecting the importance of considering all stakeholders involved. This paper\\npresents the first systematic evaluation of RAG systems integrated with fair\\nrankings. We focus specifically on measuring the fair exposure of each relevant\\nitem across the rankings utilized by RAG systems (i.e., item-side fairness),\\naiming to promote equitable growth for relevant item providers. To gain a deep\\nunderstanding of the relationship between item-fairness, ranking quality, and\\ngeneration quality in the context of RAG, we analyze nine different RAG systems\\nthat incorporate fair rankings across seven distinct datasets. Our findings\\nindicate that RAG systems with fair rankings can maintain a high level of\\ngeneration quality and, in many cases, even outperform traditional RAG systems,\\ndespite the general trend of a tradeoff between ensuring fairness and\\nmaintaining system-effectiveness. We believe our insights lay the groundwork\\nfor responsible and equitable RAG systems and open new avenues for future\\nresearch. We publicly release our codebase and dataset at\\nhttps://github.com/kimdanny/Fair-RAG.', 'pdf_url': 'http://arxiv.org/pdf/2409.11598v2'}, {'title': 'A RAG-Based Question-Answering Solution for Cyber-Attack Investigation and Attribution', 'authors': ['Sampath Rajapaksha', 'Ruby Rani', 'Erisa Karafili'], 'published': '2024-08-12', 'abstract': \"In the constantly evolving field of cybersecurity, it is imperative for\\nanalysts to stay abreast of the latest attack trends and pertinent information\\nthat aids in the investigation and attribution of cyber-attacks. In this work,\\nwe introduce the first question-answering (QA) model and its application that\\nprovides information to the cybersecurity experts about cyber-attacks\\ninvestigations and attribution. Our QA model is based on Retrieval Augmented\\nGeneration (RAG) techniques together with a Large Language Model (LLM) and\\nprovides answers to the users' queries based on either our knowledge base (KB)\\nthat contains curated information about cyber-attacks investigations and\\nattribution or on outside resources provided by the users. We have tested and\\nevaluated our QA model with various types of questions, including KB-based,\\nmetadata-based, specific documents from the KB, and external sources-based\\nquestions. We compared the answers for KB-based questions with those from\\nOpenAI's GPT-3.5 and the latest GPT-4o LLMs. Our proposed QA model outperforms\\nOpenAI's GPT models by providing the source of the answers and overcoming the\\nhallucination limitations of the GPT models, which is critical for cyber-attack\\ninvestigation and attribution. Additionally, our analysis showed that when the\\nRAG QA model is given few-shot examples rather than zero-shot instructions, it\\ngenerates better answers compared to cases where no examples are supplied in\\naddition to the query.\", 'pdf_url': 'http://arxiv.org/pdf/2408.06272v1'}, {'title': 'Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive Study and Hybrid Approach', 'authors': ['Zhuowan Li', 'Cheng Li', 'Mingyang Zhang', 'Qiaozhu Mei', 'Michael Bendersky'], 'published': '2024-07-23', 'abstract': \"Retrieval Augmented Generation (RAG) has been a powerful tool for Large\\nLanguage Models (LLMs) to efficiently process overly lengthy contexts. However,\\nrecent LLMs like Gemini-1.5 and GPT-4 show exceptional capabilities to\\nunderstand long contexts directly. We conduct a comprehensive comparison\\nbetween RAG and long-context (LC) LLMs, aiming to leverage the strengths of\\nboth. We benchmark RAG and LC across various public datasets using three latest\\nLLMs. Results reveal that when resourced sufficiently, LC consistently\\noutperforms RAG in terms of average performance. However, RAG's significantly\\nlower cost remains a distinct advantage. Based on this observation, we propose\\nSelf-Route, a simple yet effective method that routes queries to RAG or LC\\nbased on model self-reflection. Self-Route significantly reduces the\\ncomputation cost while maintaining a comparable performance to LC. Our findings\\nprovide a guideline for long-context applications of LLMs using RAG and LC.\", 'pdf_url': 'http://arxiv.org/pdf/2407.16833v2'}, {'title': 'Mask-based Membership Inference Attacks for Retrieval-Augmented Generation', 'authors': ['Mingrui Liu', 'Sixiao Zhang', 'Cheng Long'], 'published': '2024-10-26', 'abstract': \"Retrieval-Augmented Generation (RAG) has been an effective approach to\\nmitigate hallucinations in large language models (LLMs) by incorporating\\nup-to-date and domain-specific knowledge. Recently, there has been a trend of\\nstoring up-to-date or copyrighted data in RAG knowledge databases instead of\\nusing it for LLM training. This practice has raised concerns about Membership\\nInference Attacks (MIAs), which aim to detect if a specific target document is\\nstored in the RAG system's knowledge database so as to protect the rights of\\ndata producers. While research has focused on enhancing the trustworthiness of\\nRAG systems, existing MIAs for RAG systems remain largely insufficient.\\nPrevious work either relies solely on the RAG system's judgment or is easily\\ninfluenced by other documents or the LLM's internal knowledge, which is\\nunreliable and lacks explainability. To address these limitations, we propose a\\nMask-Based Membership Inference Attacks (MBA) framework. Our framework first\\nemploys a masking algorithm that effectively masks a certain number of words in\\nthe target document. The masked text is then used to prompt the RAG system, and\\nthe RAG system is required to predict the mask values. If the target document\\nappears in the knowledge database, the masked text will retrieve the complete\\ntarget document as context, allowing for accurate mask prediction. Finally, we\\nadopt a simple yet effective threshold-based method to infer the membership of\\ntarget document by analyzing the accuracy of mask prediction. Our mask-based\\napproach is more document-specific, making the RAG system's generation less\\nsusceptible to distractions from other documents or the LLM's internal\\nknowledge. Extensive experiments demonstrate the effectiveness of our approach\\ncompared to existing baseline models.\", 'pdf_url': 'http://arxiv.org/pdf/2410.20142v1'}, {'title': 'The 2nd FutureDial Challenge: Dialog Systems with Retrieval Augmented Generation (FutureDial-RAG)', 'authors': ['Yucheng Cai', 'Si Chen', 'Yuxuan Wu', 'Yi Huang', 'Junlan Feng', 'Zhijian Ou'], 'published': '2024-05-21', 'abstract': 'Recently, increasing research interests have focused on retrieval augmented\\ngeneration (RAG) to mitigate hallucination for large language models (LLMs).\\nFollowing this trend, we launch the FutureDial-RAG challenge at SLT 2024, which\\naims at promoting the study of RAG for dialog systems. The challenge builds\\nupon the MobileCS2 dataset, a real-life customer service datasets with nearly\\n3000 high-quality dialogs containing annotations for knowledge base query and\\ncorresponding results. Over the dataset, we define two tasks, track 1 for\\nknowledge retrieval and track 2 for response generation, which are core\\nresearch questions in dialog systems with RAG. We build baseline systems for\\nthe two tracks and design metrics to measure whether the systems can perform\\naccurate retrieval and generate informative and coherent response. The baseline\\nresults show that it is very challenging to perform well on the two tasks,\\nwhich encourages the participating teams and the community to study how to make\\nbetter use of RAG for real-life dialog systems.', 'pdf_url': 'http://arxiv.org/pdf/2405.13084v2'}]\n",
      "---------- Report_Agent ----------\n",
      "### 최신 RAG 기술에 대한 동향 및 논문 리뷰\n",
      "\n",
      "#### 서론\n",
      "Retrieval-Augmented Generation (RAG)는 최신 인공지능(AI) 기술의 발전으로 주목받고 있는 분야입니다. RAG는 정보 검색과 텍스트 생성 기능을 결합하여 새로운 유형의 문제를 해결합니다. 이 기술은 특히 긴 맥락을 처리하거나 특정 도메인 지식을 필요로 하는 작업에서 유리합니다. 이 리뷰에서는 최신 RAG 기술 동향과 관련된 주요 논문들을 검토하여 현재 연구의 발전 방향과 도전 과제를 살펴보겠습니다.\n",
      "\n",
      "#### 주요 연구 검토\n",
      "\n",
      "1. **Towards Fair RAG: On the Impact of Fair Ranking in Retrieval-Augmented Generation**\n",
      "   Kim, T. E., & Diaz, F. (2024)의 연구는 공평한 순위 매기기(fair ranking)를 통합한 RAG 시스템을 체계적으로 평가한 최초의 논문입니다. 이 연구는 9개의 다른 RAG 시스템과 7개의 데이터셋을 사용하여 항목의 공평한 노출이 순위 품질과 생성 품질에 미치는 영향을 분석합니다. 연구 결과, 공평한 순위 매기기를 사용한 RAG 시스템이 전통적인 RAG 시스템보다 높은 생성 품질을 유지할 수 있음을 확인했습니다.\n",
      "   \n",
      "   **주요 기여:**\n",
      "   - RAG 시스템에 공평한 순위 매기기를 통합하여 공평성 개선\n",
      "   - 코드를 공용으로 공개하여 다른 연구자의 접근성을 높임\n",
      "   \n",
      "   [PDF 파일 링크](http://arxiv.org/pdf/2409.11598v2)\n",
      "\n",
      "2. **A RAG-Based Question-Answering Solution for Cyber-Attack Investigation and Attribution**\n",
      "   Rajapaksha, S., Rani, R., & Karafili, E. (2024)는 사이버 공격 조사와 귀속을 위한 질문-응답(QA) 모델을 제안합니다. 이 모델은 Large Language Model(LLM)과 RAG 기술을 결합하여, 사이버 보안 전문가에게 신뢰할 수 있는 정보를 제공합니다. 연구는 다양한 타입의 질문에 대한 모델의 성능을 평가하고, OpenAI의 GPT-3.5 및 GPT-4와 비교하여 RAG QA 모델이 우수한 성능을 보였음을 확인했습니다.\n",
      "   \n",
      "   **주요 기여:**\n",
      "   - 사이버 보안 도메인을 위한 RAG 기반 QA 모델 개발\n",
      "   - GPT 모델의 한계를 극복하는 더 정확한 답변 제공\n",
      "   \n",
      "   [PDF 파일 링크](http://arxiv.org/pdf/2408.06272v1)\n",
      "\n",
      "3. **Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive Study and Hybrid Approach**\n",
      "   Li, Z., Li, C., Zhang, M., Mei, Q., & Bendersky, M. (2024)는 RAG와 긴 맥락(long-context, LC) LLM 기술을 비교하여, 두 기술의 장점을 결합한 하이브리드 접근법인 Self-Route를 제안합니다. 연구는 다양한 공개 데이터셋을 사용하여 RAG와 LC 기술의 성능을 비교한 결과, LC가 더 높은 성능을 보였으나, RAG의 비용 효율성이 여전히 큰 장점으로 나타났습니다.\n",
      "   \n",
      "   **주요 기여:**\n",
      "   - RAG와 LC LLM의 성능 비교\n",
      "   - Self-Route라는 비용 효율적인 하이브리드 접근법 제안\n",
      "   \n",
      "   [PDF 파일 링크](http://arxiv.org/pdf/2407.16833v2)\n",
      "\n",
      "4. **Mask-based Membership Inference Attacks for Retrieval-Augmented Generation**\n",
      "   Liu, M., Zhang, S., & Long, C. (2024)의 연구는 RAG 시스템의 신뢰성을 높이기 위해 Mask-based Membership Inference Attacks(MBA) 프레임워크를 제안합니다. 이 방법은 타겟 문서의 멤버십을 추론하기 위해 마스크 알고리즘을 사용하여 RAG 시스템의 예측 정확도를 분석합니다. 실험 결과, MBA 프레임워크가 기존 모델보다 효과적임을 확인했습니다.\n",
      "   \n",
      "   **주요 기여:**\n",
      "   - RAG 시스템의 먼버십 추론을 위한 마스크 기반 공격 방법 제안\n",
      "   - 더 정밀한 문서 특정 예측 제공\n",
      "   \n",
      "   [PDF 파일 링크](http://arxiv.org/pdf/2410.20142v1)\n",
      "\n",
      "5. **The 2nd FutureDial Challenge: Dialog Systems with Retrieval Augmented Generation (FutureDial-RAG)**\n",
      "   Cai, Y. et al. (2024)는 SLT 2024에서 열린 FutureDial-RAG 챌린지의 목표를 설명합니다. 이 챌린지는 MobileCS2 데이터셋을 사용하여 지식 검색 및 응답 생성 작업에 대한 RAG 시스템의 성능을 평가합니다. 이를 통해 실제 대화 시스템에서 RAG의 효과를 연구하고, 연구 커뮤니티가 더 나은 RAG 시스템을 개발하도록 장려합니다.\n",
      "   \n",
      "   **주요 기여:**\n",
      "   - 실제 응용 분야에서 RAG 기술의 성능을 평가하는 챌린지 소개\n",
      "   - 대화 시스템에서 지식 검색과 응답 생성 작업의 성능 지표 개발\n",
      "   \n",
      "   [PDF 파일 링크](http://arxiv.org/pdf/2405.13084v2)\n",
      "\n",
      "#### 결론\n",
      "\n",
      "이 논문 리뷰는 최신 RAG 기술 동향과 주요 연구 성과를 검토하여, 현재 연구의 발전 방향과 도전 과제를 체계적으로 분석하였습니다. 공평한 순위 매기기, 사이버 보안 도메인 응용, 긴 맥락 LLM과의 비교, 마스크 기반 공격 방법, 그리고 대화 시스템에 관한 연구들이 주요 트렌드로 나타났습니다. 이러한 연구들은 RAG 기술의 신뢰성을 높이고, 더 다양한 응용 분야에서의 성능을 증진하는 데 기여하고 있습니다.\n",
      "\n",
      "**참고문헌**\n",
      "- Kim, T. E., & Diaz, F. (2024). Towards Fair RAG: On the Impact of Fair Ranking in Retrieval-Augmented Generation. arXiv preprint. Retrieved from http://arxiv.org/pdf/2409.11598v2\n",
      "- Rajapaksha, S., Rani, R., & Karafili, E. (2024). A RAG-Based Question-Answering Solution for Cyber-Attack Investigation and Attribution. arXiv preprint. Retrieved from http://arxiv.org/pdf/2408.06272v1\n",
      "- Li, Z., Li, C., Zhang, M., Mei, Q., & Bendersky, M. (2024). Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive Study and Hybrid Approach. arXiv preprint. Retrieved from http://arxiv.org/pdf/2407.16833v2\n",
      "- Liu, M., Zhang, S., & Long, C. (2024). Mask-based Membership Inference Attacks for Retrieval-Augmented Generation. arXiv preprint. Retrieved from http://arxiv.org/pdf/2410.20142v1\n",
      "- Cai, Y., Chen, S., Wu, Y., Huang, Y., Feng, J., & Ou, Z. (2024). The 2nd FutureDial Challenge: Dialog Systems with Retrieval Augmented Generation (FutureDial-RAG). arXiv preprint. Retrieved from http://arxiv.org/pdf/2405.13084v2\n",
      "\n",
      "TERMINATE\n",
      "[Prompt tokens: 9038, Completion tokens: 1611]\n",
      "---------- Summary ----------\n",
      "Number of messages: 8\n",
      "Finish reason: Text 'TERMINATE' mentioned\n",
      "Total prompt tokens: 23083\n",
      "Total completion tokens: 1710\n",
      "Duration: 31.09 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='최신 RAG 기술에 대한 동향 및 논문 리뷰', type='TextMessage'), ToolCallMessage(source='Google_Search_Agent', models_usage=RequestUsage(prompt_tokens=6590, completion_tokens=69), content=[FunctionCall(id='call_Kts8sCafod2fGJzziWGpXpdO', arguments='{\"query\": \"current trends in RAG technology\", \"num_results\": 2}', name='google_search'), FunctionCall(id='call_EUHkCPGhBjELZbwqquPGwLA9', arguments='{\"query\": \"recent papers on Retrieval-Augmented Generation (RAG)\", \"num_results\": 2}', name='google_search')], type='ToolCallMessage'), ToolCallResultMessage(source='Google_Search_Agent', models_usage=None, content=[FunctionExecutionResult(content=\"[{'title': 'Latest Developments in Retrieval-Augmented Generation', 'link': 'https://celerdata.com/glossary/latest-developments-in-retrieval-augmented-generation', 'snippet': 'The future of RAG looks promising with continued advancements in technology, model architectures, and training methodologies driving innovation ...', 'body': 'Latest Developments in Retrieval-Augmented Generation PRODUCTS PRODUCTS CelerData Overview CelerData Cloud BYOC SOLUTIONS USE CASES Lakehouse Analytics Real-Time Analytics Customer-Facing Analytics TECHNOLOGY ALTERNATIVES Trino/Presto ClickHouse Apache Druid ENHANCEMENTS Apache Iceberg STARROCKS RESOURCES RESOURCES CelerData Blog Documentation Whitepapers & Case Studies Webinars & Videos Glossary Events COMPANY COMPANY About Us Partners Newsroom Careers Contact Us Free Trial Latest Developments'}, {'title': '2024 AI Trends to Watch Out for: The Rise of RAG and MoE', 'link': 'https://flock-io.medium.com/2024-ai-trends-to-watch-out-for-the-rise-of-rag-and-moe-883cf1985fd1', 'snippet': 'The integration of RAG and MoE represents a significant step forward in AI, providing more efficient and tailored experiences. These ...', 'body': '2024 AI Trends to Watch Out for: The Rise of RAG and MoE | by FLock.io | Medium Open in app Sign up Sign in Write Sign up Sign in 2024 AI Trends to Watch Out for: The Rise of RAG and MoE FLock.io · Follow 3 min read · Jan 14, 2024 -- Listen Share As we delve into 2024, Retrieval-Augmented Generation (RAG) and Mixture of Experts (MoE) stand out as the two key technologies in the realm of artificial intelligence (AI) to watch. These technologies are reshaping the way AI systems process'}]\", call_id='call_Kts8sCafod2fGJzziWGpXpdO'), FunctionExecutionResult(content='[{\\'title\\': \\'[2410.12837] A Comprehensive Survey of Retrieval ...\\', \\'link\\': \\'https://arxiv.org/abs/2410.12837\\', \\'snippet\\': \\'This paper presents a comprehensive study of Retrieval-Augmented Generation (RAG), tracing its evolution from foundational concepts to the ...\\', \\'body\\': \"[2410.12837] A Comprehensive Survey of Retrieval-Augmented Generation (RAG): Evolution, Current Landscape and Future Directions Change to arXiv\\'s privacy policy The arXiv Privacy Policy has changed. By continuing to use arxiv.org, you are agreeing to the privacy policy. I Understand Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate > cs > arXiv:2410.12837 Help | Advanced Search All fields Title Author Abstract\"}, {\\'title\\': \\'RAG\\', \\'link\\': \\'https://paperswithcode.com/task/rag\\', \\'snippet\\': \\'We introduce RAGAs (Retrieval Augmented Generation Assessment), a framework for reference-free evaluation of Retrieval Augmented Generation (RAG) pipelines. 2.\\', \\'body\\': \"RAG | Papers With Code Browse State-of-the-Art Datasets Methods More Newsletter RC2022 About Trends Portals Libraries Sign In Subscribe to the PwC Newsletter × Stay informed on the latest trending ML papers with code, research developments, libraries, methods, and datasets. Read previous issues Subscribe Join the community × You need to log in to edit. You can create a new account if you don\\'t have one. Edit task × Task name: * Top-level area: * --------- Adversarial Audio Computer Code\"}]', call_id='call_EUHkCPGhBjELZbwqquPGwLA9')], type='ToolCallResultMessage'), TextMessage(source='Google_Search_Agent', models_usage=None, content='[{\\'title\\': \\'Latest Developments in Retrieval-Augmented Generation\\', \\'link\\': \\'https://celerdata.com/glossary/latest-developments-in-retrieval-augmented-generation\\', \\'snippet\\': \\'The future of RAG looks promising with continued advancements in technology, model architectures, and training methodologies driving innovation ...\\', \\'body\\': \\'Latest Developments in Retrieval-Augmented Generation PRODUCTS PRODUCTS CelerData Overview CelerData Cloud BYOC SOLUTIONS USE CASES Lakehouse Analytics Real-Time Analytics Customer-Facing Analytics TECHNOLOGY ALTERNATIVES Trino/Presto ClickHouse Apache Druid ENHANCEMENTS Apache Iceberg STARROCKS RESOURCES RESOURCES CelerData Blog Documentation Whitepapers & Case Studies Webinars & Videos Glossary Events COMPANY COMPANY About Us Partners Newsroom Careers Contact Us Free Trial Latest Developments\\'}, {\\'title\\': \\'2024 AI Trends to Watch Out for: The Rise of RAG and MoE\\', \\'link\\': \\'https://flock-io.medium.com/2024-ai-trends-to-watch-out-for-the-rise-of-rag-and-moe-883cf1985fd1\\', \\'snippet\\': \\'The integration of RAG and MoE represents a significant step forward in AI, providing more efficient and tailored experiences. These ...\\', \\'body\\': \\'2024 AI Trends to Watch Out for: The Rise of RAG and MoE | by FLock.io | Medium Open in app Sign up Sign in Write Sign up Sign in 2024 AI Trends to Watch Out for: The Rise of RAG and MoE FLock.io · Follow 3 min read · Jan 14, 2024 -- Listen Share As we delve into 2024, Retrieval-Augmented Generation (RAG) and Mixture of Experts (MoE) stand out as the two key technologies in the realm of artificial intelligence (AI) to watch. These technologies are reshaping the way AI systems process\\'}]\\n[{\\'title\\': \\'[2410.12837] A Comprehensive Survey of Retrieval ...\\', \\'link\\': \\'https://arxiv.org/abs/2410.12837\\', \\'snippet\\': \\'This paper presents a comprehensive study of Retrieval-Augmented Generation (RAG), tracing its evolution from foundational concepts to the ...\\', \\'body\\': \"[2410.12837] A Comprehensive Survey of Retrieval-Augmented Generation (RAG): Evolution, Current Landscape and Future Directions Change to arXiv\\'s privacy policy The arXiv Privacy Policy has changed. By continuing to use arxiv.org, you are agreeing to the privacy policy. I Understand Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate > cs > arXiv:2410.12837 Help | Advanced Search All fields Title Author Abstract\"}, {\\'title\\': \\'RAG\\', \\'link\\': \\'https://paperswithcode.com/task/rag\\', \\'snippet\\': \\'We introduce RAGAs (Retrieval Augmented Generation Assessment), a framework for reference-free evaluation of Retrieval Augmented Generation (RAG) pipelines. 2.\\', \\'body\\': \"RAG | Papers With Code Browse State-of-the-Art Datasets Methods More Newsletter RC2022 About Trends Portals Libraries Sign In Subscribe to the PwC Newsletter × Stay informed on the latest trending ML papers with code, research developments, libraries, methods, and datasets. Read previous issues Subscribe Join the community × You need to log in to edit. You can create a new account if you don\\'t have one. Edit task × Task name: * Top-level area: * --------- Adversarial Audio Computer Code\"}]', type='TextMessage'), ToolCallMessage(source='Arxiv_Search_Agent', models_usage=RequestUsage(prompt_tokens=7455, completion_tokens=30), content=[FunctionCall(id='call_R4ODhDFZWKlFo2lHOgdXVS7l', arguments='{\"query\":\"latest trends in Retrieval-Augmented Generation (RAG)\",\"max_results\":5}', name='arxiv_search')], type='ToolCallMessage'), ToolCallResultMessage(source='Arxiv_Search_Agent', models_usage=None, content=[FunctionExecutionResult(content='[{\\'title\\': \\'Towards Fair RAG: On the Impact of Fair Ranking in Retrieval-Augmented Generation\\', \\'authors\\': [\\'To Eun Kim\\', \\'Fernando Diaz\\'], \\'published\\': \\'2024-09-17\\', \\'abstract\\': \\'Many language models now enhance their responses with retrieval capabilities,\\\\nleading to the widespread adoption of retrieval-augmented generation (RAG)\\\\nsystems. However, despite retrieval being a core component of RAG, much of the\\\\nresearch in this area overlooks the extensive body of work on fair ranking,\\\\nneglecting the importance of considering all stakeholders involved. This paper\\\\npresents the first systematic evaluation of RAG systems integrated with fair\\\\nrankings. We focus specifically on measuring the fair exposure of each relevant\\\\nitem across the rankings utilized by RAG systems (i.e., item-side fairness),\\\\naiming to promote equitable growth for relevant item providers. To gain a deep\\\\nunderstanding of the relationship between item-fairness, ranking quality, and\\\\ngeneration quality in the context of RAG, we analyze nine different RAG systems\\\\nthat incorporate fair rankings across seven distinct datasets. Our findings\\\\nindicate that RAG systems with fair rankings can maintain a high level of\\\\ngeneration quality and, in many cases, even outperform traditional RAG systems,\\\\ndespite the general trend of a tradeoff between ensuring fairness and\\\\nmaintaining system-effectiveness. We believe our insights lay the groundwork\\\\nfor responsible and equitable RAG systems and open new avenues for future\\\\nresearch. We publicly release our codebase and dataset at\\\\nhttps://github.com/kimdanny/Fair-RAG.\\', \\'pdf_url\\': \\'http://arxiv.org/pdf/2409.11598v2\\'}, {\\'title\\': \\'A RAG-Based Question-Answering Solution for Cyber-Attack Investigation and Attribution\\', \\'authors\\': [\\'Sampath Rajapaksha\\', \\'Ruby Rani\\', \\'Erisa Karafili\\'], \\'published\\': \\'2024-08-12\\', \\'abstract\\': \"In the constantly evolving field of cybersecurity, it is imperative for\\\\nanalysts to stay abreast of the latest attack trends and pertinent information\\\\nthat aids in the investigation and attribution of cyber-attacks. In this work,\\\\nwe introduce the first question-answering (QA) model and its application that\\\\nprovides information to the cybersecurity experts about cyber-attacks\\\\ninvestigations and attribution. Our QA model is based on Retrieval Augmented\\\\nGeneration (RAG) techniques together with a Large Language Model (LLM) and\\\\nprovides answers to the users\\' queries based on either our knowledge base (KB)\\\\nthat contains curated information about cyber-attacks investigations and\\\\nattribution or on outside resources provided by the users. We have tested and\\\\nevaluated our QA model with various types of questions, including KB-based,\\\\nmetadata-based, specific documents from the KB, and external sources-based\\\\nquestions. We compared the answers for KB-based questions with those from\\\\nOpenAI\\'s GPT-3.5 and the latest GPT-4o LLMs. Our proposed QA model outperforms\\\\nOpenAI\\'s GPT models by providing the source of the answers and overcoming the\\\\nhallucination limitations of the GPT models, which is critical for cyber-attack\\\\ninvestigation and attribution. Additionally, our analysis showed that when the\\\\nRAG QA model is given few-shot examples rather than zero-shot instructions, it\\\\ngenerates better answers compared to cases where no examples are supplied in\\\\naddition to the query.\", \\'pdf_url\\': \\'http://arxiv.org/pdf/2408.06272v1\\'}, {\\'title\\': \\'Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive Study and Hybrid Approach\\', \\'authors\\': [\\'Zhuowan Li\\', \\'Cheng Li\\', \\'Mingyang Zhang\\', \\'Qiaozhu Mei\\', \\'Michael Bendersky\\'], \\'published\\': \\'2024-07-23\\', \\'abstract\\': \"Retrieval Augmented Generation (RAG) has been a powerful tool for Large\\\\nLanguage Models (LLMs) to efficiently process overly lengthy contexts. However,\\\\nrecent LLMs like Gemini-1.5 and GPT-4 show exceptional capabilities to\\\\nunderstand long contexts directly. We conduct a comprehensive comparison\\\\nbetween RAG and long-context (LC) LLMs, aiming to leverage the strengths of\\\\nboth. We benchmark RAG and LC across various public datasets using three latest\\\\nLLMs. Results reveal that when resourced sufficiently, LC consistently\\\\noutperforms RAG in terms of average performance. However, RAG\\'s significantly\\\\nlower cost remains a distinct advantage. Based on this observation, we propose\\\\nSelf-Route, a simple yet effective method that routes queries to RAG or LC\\\\nbased on model self-reflection. Self-Route significantly reduces the\\\\ncomputation cost while maintaining a comparable performance to LC. Our findings\\\\nprovide a guideline for long-context applications of LLMs using RAG and LC.\", \\'pdf_url\\': \\'http://arxiv.org/pdf/2407.16833v2\\'}, {\\'title\\': \\'Mask-based Membership Inference Attacks for Retrieval-Augmented Generation\\', \\'authors\\': [\\'Mingrui Liu\\', \\'Sixiao Zhang\\', \\'Cheng Long\\'], \\'published\\': \\'2024-10-26\\', \\'abstract\\': \"Retrieval-Augmented Generation (RAG) has been an effective approach to\\\\nmitigate hallucinations in large language models (LLMs) by incorporating\\\\nup-to-date and domain-specific knowledge. Recently, there has been a trend of\\\\nstoring up-to-date or copyrighted data in RAG knowledge databases instead of\\\\nusing it for LLM training. This practice has raised concerns about Membership\\\\nInference Attacks (MIAs), which aim to detect if a specific target document is\\\\nstored in the RAG system\\'s knowledge database so as to protect the rights of\\\\ndata producers. While research has focused on enhancing the trustworthiness of\\\\nRAG systems, existing MIAs for RAG systems remain largely insufficient.\\\\nPrevious work either relies solely on the RAG system\\'s judgment or is easily\\\\ninfluenced by other documents or the LLM\\'s internal knowledge, which is\\\\nunreliable and lacks explainability. To address these limitations, we propose a\\\\nMask-Based Membership Inference Attacks (MBA) framework. Our framework first\\\\nemploys a masking algorithm that effectively masks a certain number of words in\\\\nthe target document. The masked text is then used to prompt the RAG system, and\\\\nthe RAG system is required to predict the mask values. If the target document\\\\nappears in the knowledge database, the masked text will retrieve the complete\\\\ntarget document as context, allowing for accurate mask prediction. Finally, we\\\\nadopt a simple yet effective threshold-based method to infer the membership of\\\\ntarget document by analyzing the accuracy of mask prediction. Our mask-based\\\\napproach is more document-specific, making the RAG system\\'s generation less\\\\nsusceptible to distractions from other documents or the LLM\\'s internal\\\\nknowledge. Extensive experiments demonstrate the effectiveness of our approach\\\\ncompared to existing baseline models.\", \\'pdf_url\\': \\'http://arxiv.org/pdf/2410.20142v1\\'}, {\\'title\\': \\'The 2nd FutureDial Challenge: Dialog Systems with Retrieval Augmented Generation (FutureDial-RAG)\\', \\'authors\\': [\\'Yucheng Cai\\', \\'Si Chen\\', \\'Yuxuan Wu\\', \\'Yi Huang\\', \\'Junlan Feng\\', \\'Zhijian Ou\\'], \\'published\\': \\'2024-05-21\\', \\'abstract\\': \\'Recently, increasing research interests have focused on retrieval augmented\\\\ngeneration (RAG) to mitigate hallucination for large language models (LLMs).\\\\nFollowing this trend, we launch the FutureDial-RAG challenge at SLT 2024, which\\\\naims at promoting the study of RAG for dialog systems. The challenge builds\\\\nupon the MobileCS2 dataset, a real-life customer service datasets with nearly\\\\n3000 high-quality dialogs containing annotations for knowledge base query and\\\\ncorresponding results. Over the dataset, we define two tasks, track 1 for\\\\nknowledge retrieval and track 2 for response generation, which are core\\\\nresearch questions in dialog systems with RAG. We build baseline systems for\\\\nthe two tracks and design metrics to measure whether the systems can perform\\\\naccurate retrieval and generate informative and coherent response. The baseline\\\\nresults show that it is very challenging to perform well on the two tasks,\\\\nwhich encourages the participating teams and the community to study how to make\\\\nbetter use of RAG for real-life dialog systems.\\', \\'pdf_url\\': \\'http://arxiv.org/pdf/2405.13084v2\\'}]', call_id='call_R4ODhDFZWKlFo2lHOgdXVS7l')], type='ToolCallResultMessage'), TextMessage(source='Arxiv_Search_Agent', models_usage=None, content='[{\\'title\\': \\'Towards Fair RAG: On the Impact of Fair Ranking in Retrieval-Augmented Generation\\', \\'authors\\': [\\'To Eun Kim\\', \\'Fernando Diaz\\'], \\'published\\': \\'2024-09-17\\', \\'abstract\\': \\'Many language models now enhance their responses with retrieval capabilities,\\\\nleading to the widespread adoption of retrieval-augmented generation (RAG)\\\\nsystems. However, despite retrieval being a core component of RAG, much of the\\\\nresearch in this area overlooks the extensive body of work on fair ranking,\\\\nneglecting the importance of considering all stakeholders involved. This paper\\\\npresents the first systematic evaluation of RAG systems integrated with fair\\\\nrankings. We focus specifically on measuring the fair exposure of each relevant\\\\nitem across the rankings utilized by RAG systems (i.e., item-side fairness),\\\\naiming to promote equitable growth for relevant item providers. To gain a deep\\\\nunderstanding of the relationship between item-fairness, ranking quality, and\\\\ngeneration quality in the context of RAG, we analyze nine different RAG systems\\\\nthat incorporate fair rankings across seven distinct datasets. Our findings\\\\nindicate that RAG systems with fair rankings can maintain a high level of\\\\ngeneration quality and, in many cases, even outperform traditional RAG systems,\\\\ndespite the general trend of a tradeoff between ensuring fairness and\\\\nmaintaining system-effectiveness. We believe our insights lay the groundwork\\\\nfor responsible and equitable RAG systems and open new avenues for future\\\\nresearch. We publicly release our codebase and dataset at\\\\nhttps://github.com/kimdanny/Fair-RAG.\\', \\'pdf_url\\': \\'http://arxiv.org/pdf/2409.11598v2\\'}, {\\'title\\': \\'A RAG-Based Question-Answering Solution for Cyber-Attack Investigation and Attribution\\', \\'authors\\': [\\'Sampath Rajapaksha\\', \\'Ruby Rani\\', \\'Erisa Karafili\\'], \\'published\\': \\'2024-08-12\\', \\'abstract\\': \"In the constantly evolving field of cybersecurity, it is imperative for\\\\nanalysts to stay abreast of the latest attack trends and pertinent information\\\\nthat aids in the investigation and attribution of cyber-attacks. In this work,\\\\nwe introduce the first question-answering (QA) model and its application that\\\\nprovides information to the cybersecurity experts about cyber-attacks\\\\ninvestigations and attribution. Our QA model is based on Retrieval Augmented\\\\nGeneration (RAG) techniques together with a Large Language Model (LLM) and\\\\nprovides answers to the users\\' queries based on either our knowledge base (KB)\\\\nthat contains curated information about cyber-attacks investigations and\\\\nattribution or on outside resources provided by the users. We have tested and\\\\nevaluated our QA model with various types of questions, including KB-based,\\\\nmetadata-based, specific documents from the KB, and external sources-based\\\\nquestions. We compared the answers for KB-based questions with those from\\\\nOpenAI\\'s GPT-3.5 and the latest GPT-4o LLMs. Our proposed QA model outperforms\\\\nOpenAI\\'s GPT models by providing the source of the answers and overcoming the\\\\nhallucination limitations of the GPT models, which is critical for cyber-attack\\\\ninvestigation and attribution. Additionally, our analysis showed that when the\\\\nRAG QA model is given few-shot examples rather than zero-shot instructions, it\\\\ngenerates better answers compared to cases where no examples are supplied in\\\\naddition to the query.\", \\'pdf_url\\': \\'http://arxiv.org/pdf/2408.06272v1\\'}, {\\'title\\': \\'Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive Study and Hybrid Approach\\', \\'authors\\': [\\'Zhuowan Li\\', \\'Cheng Li\\', \\'Mingyang Zhang\\', \\'Qiaozhu Mei\\', \\'Michael Bendersky\\'], \\'published\\': \\'2024-07-23\\', \\'abstract\\': \"Retrieval Augmented Generation (RAG) has been a powerful tool for Large\\\\nLanguage Models (LLMs) to efficiently process overly lengthy contexts. However,\\\\nrecent LLMs like Gemini-1.5 and GPT-4 show exceptional capabilities to\\\\nunderstand long contexts directly. We conduct a comprehensive comparison\\\\nbetween RAG and long-context (LC) LLMs, aiming to leverage the strengths of\\\\nboth. We benchmark RAG and LC across various public datasets using three latest\\\\nLLMs. Results reveal that when resourced sufficiently, LC consistently\\\\noutperforms RAG in terms of average performance. However, RAG\\'s significantly\\\\nlower cost remains a distinct advantage. Based on this observation, we propose\\\\nSelf-Route, a simple yet effective method that routes queries to RAG or LC\\\\nbased on model self-reflection. Self-Route significantly reduces the\\\\ncomputation cost while maintaining a comparable performance to LC. Our findings\\\\nprovide a guideline for long-context applications of LLMs using RAG and LC.\", \\'pdf_url\\': \\'http://arxiv.org/pdf/2407.16833v2\\'}, {\\'title\\': \\'Mask-based Membership Inference Attacks for Retrieval-Augmented Generation\\', \\'authors\\': [\\'Mingrui Liu\\', \\'Sixiao Zhang\\', \\'Cheng Long\\'], \\'published\\': \\'2024-10-26\\', \\'abstract\\': \"Retrieval-Augmented Generation (RAG) has been an effective approach to\\\\nmitigate hallucinations in large language models (LLMs) by incorporating\\\\nup-to-date and domain-specific knowledge. Recently, there has been a trend of\\\\nstoring up-to-date or copyrighted data in RAG knowledge databases instead of\\\\nusing it for LLM training. This practice has raised concerns about Membership\\\\nInference Attacks (MIAs), which aim to detect if a specific target document is\\\\nstored in the RAG system\\'s knowledge database so as to protect the rights of\\\\ndata producers. While research has focused on enhancing the trustworthiness of\\\\nRAG systems, existing MIAs for RAG systems remain largely insufficient.\\\\nPrevious work either relies solely on the RAG system\\'s judgment or is easily\\\\ninfluenced by other documents or the LLM\\'s internal knowledge, which is\\\\nunreliable and lacks explainability. To address these limitations, we propose a\\\\nMask-Based Membership Inference Attacks (MBA) framework. Our framework first\\\\nemploys a masking algorithm that effectively masks a certain number of words in\\\\nthe target document. The masked text is then used to prompt the RAG system, and\\\\nthe RAG system is required to predict the mask values. If the target document\\\\nappears in the knowledge database, the masked text will retrieve the complete\\\\ntarget document as context, allowing for accurate mask prediction. Finally, we\\\\nadopt a simple yet effective threshold-based method to infer the membership of\\\\ntarget document by analyzing the accuracy of mask prediction. Our mask-based\\\\napproach is more document-specific, making the RAG system\\'s generation less\\\\nsusceptible to distractions from other documents or the LLM\\'s internal\\\\nknowledge. Extensive experiments demonstrate the effectiveness of our approach\\\\ncompared to existing baseline models.\", \\'pdf_url\\': \\'http://arxiv.org/pdf/2410.20142v1\\'}, {\\'title\\': \\'The 2nd FutureDial Challenge: Dialog Systems with Retrieval Augmented Generation (FutureDial-RAG)\\', \\'authors\\': [\\'Yucheng Cai\\', \\'Si Chen\\', \\'Yuxuan Wu\\', \\'Yi Huang\\', \\'Junlan Feng\\', \\'Zhijian Ou\\'], \\'published\\': \\'2024-05-21\\', \\'abstract\\': \\'Recently, increasing research interests have focused on retrieval augmented\\\\ngeneration (RAG) to mitigate hallucination for large language models (LLMs).\\\\nFollowing this trend, we launch the FutureDial-RAG challenge at SLT 2024, which\\\\naims at promoting the study of RAG for dialog systems. The challenge builds\\\\nupon the MobileCS2 dataset, a real-life customer service datasets with nearly\\\\n3000 high-quality dialogs containing annotations for knowledge base query and\\\\ncorresponding results. Over the dataset, we define two tasks, track 1 for\\\\nknowledge retrieval and track 2 for response generation, which are core\\\\nresearch questions in dialog systems with RAG. We build baseline systems for\\\\nthe two tracks and design metrics to measure whether the systems can perform\\\\naccurate retrieval and generate informative and coherent response. The baseline\\\\nresults show that it is very challenging to perform well on the two tasks,\\\\nwhich encourages the participating teams and the community to study how to make\\\\nbetter use of RAG for real-life dialog systems.\\', \\'pdf_url\\': \\'http://arxiv.org/pdf/2405.13084v2\\'}]', type='TextMessage'), TextMessage(source='Report_Agent', models_usage=RequestUsage(prompt_tokens=9038, completion_tokens=1611), content='### 최신 RAG 기술에 대한 동향 및 논문 리뷰\\n\\n#### 서론\\nRetrieval-Augmented Generation (RAG)는 최신 인공지능(AI) 기술의 발전으로 주목받고 있는 분야입니다. RAG는 정보 검색과 텍스트 생성 기능을 결합하여 새로운 유형의 문제를 해결합니다. 이 기술은 특히 긴 맥락을 처리하거나 특정 도메인 지식을 필요로 하는 작업에서 유리합니다. 이 리뷰에서는 최신 RAG 기술 동향과 관련된 주요 논문들을 검토하여 현재 연구의 발전 방향과 도전 과제를 살펴보겠습니다.\\n\\n#### 주요 연구 검토\\n\\n1. **Towards Fair RAG: On the Impact of Fair Ranking in Retrieval-Augmented Generation**\\n   Kim, T. E., & Diaz, F. (2024)의 연구는 공평한 순위 매기기(fair ranking)를 통합한 RAG 시스템을 체계적으로 평가한 최초의 논문입니다. 이 연구는 9개의 다른 RAG 시스템과 7개의 데이터셋을 사용하여 항목의 공평한 노출이 순위 품질과 생성 품질에 미치는 영향을 분석합니다. 연구 결과, 공평한 순위 매기기를 사용한 RAG 시스템이 전통적인 RAG 시스템보다 높은 생성 품질을 유지할 수 있음을 확인했습니다.\\n   \\n   **주요 기여:**\\n   - RAG 시스템에 공평한 순위 매기기를 통합하여 공평성 개선\\n   - 코드를 공용으로 공개하여 다른 연구자의 접근성을 높임\\n   \\n   [PDF 파일 링크](http://arxiv.org/pdf/2409.11598v2)\\n\\n2. **A RAG-Based Question-Answering Solution for Cyber-Attack Investigation and Attribution**\\n   Rajapaksha, S., Rani, R., & Karafili, E. (2024)는 사이버 공격 조사와 귀속을 위한 질문-응답(QA) 모델을 제안합니다. 이 모델은 Large Language Model(LLM)과 RAG 기술을 결합하여, 사이버 보안 전문가에게 신뢰할 수 있는 정보를 제공합니다. 연구는 다양한 타입의 질문에 대한 모델의 성능을 평가하고, OpenAI의 GPT-3.5 및 GPT-4와 비교하여 RAG QA 모델이 우수한 성능을 보였음을 확인했습니다.\\n   \\n   **주요 기여:**\\n   - 사이버 보안 도메인을 위한 RAG 기반 QA 모델 개발\\n   - GPT 모델의 한계를 극복하는 더 정확한 답변 제공\\n   \\n   [PDF 파일 링크](http://arxiv.org/pdf/2408.06272v1)\\n\\n3. **Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive Study and Hybrid Approach**\\n   Li, Z., Li, C., Zhang, M., Mei, Q., & Bendersky, M. (2024)는 RAG와 긴 맥락(long-context, LC) LLM 기술을 비교하여, 두 기술의 장점을 결합한 하이브리드 접근법인 Self-Route를 제안합니다. 연구는 다양한 공개 데이터셋을 사용하여 RAG와 LC 기술의 성능을 비교한 결과, LC가 더 높은 성능을 보였으나, RAG의 비용 효율성이 여전히 큰 장점으로 나타났습니다.\\n   \\n   **주요 기여:**\\n   - RAG와 LC LLM의 성능 비교\\n   - Self-Route라는 비용 효율적인 하이브리드 접근법 제안\\n   \\n   [PDF 파일 링크](http://arxiv.org/pdf/2407.16833v2)\\n\\n4. **Mask-based Membership Inference Attacks for Retrieval-Augmented Generation**\\n   Liu, M., Zhang, S., & Long, C. (2024)의 연구는 RAG 시스템의 신뢰성을 높이기 위해 Mask-based Membership Inference Attacks(MBA) 프레임워크를 제안합니다. 이 방법은 타겟 문서의 멤버십을 추론하기 위해 마스크 알고리즘을 사용하여 RAG 시스템의 예측 정확도를 분석합니다. 실험 결과, MBA 프레임워크가 기존 모델보다 효과적임을 확인했습니다.\\n   \\n   **주요 기여:**\\n   - RAG 시스템의 먼버십 추론을 위한 마스크 기반 공격 방법 제안\\n   - 더 정밀한 문서 특정 예측 제공\\n   \\n   [PDF 파일 링크](http://arxiv.org/pdf/2410.20142v1)\\n\\n5. **The 2nd FutureDial Challenge: Dialog Systems with Retrieval Augmented Generation (FutureDial-RAG)**\\n   Cai, Y. et al. (2024)는 SLT 2024에서 열린 FutureDial-RAG 챌린지의 목표를 설명합니다. 이 챌린지는 MobileCS2 데이터셋을 사용하여 지식 검색 및 응답 생성 작업에 대한 RAG 시스템의 성능을 평가합니다. 이를 통해 실제 대화 시스템에서 RAG의 효과를 연구하고, 연구 커뮤니티가 더 나은 RAG 시스템을 개발하도록 장려합니다.\\n   \\n   **주요 기여:**\\n   - 실제 응용 분야에서 RAG 기술의 성능을 평가하는 챌린지 소개\\n   - 대화 시스템에서 지식 검색과 응답 생성 작업의 성능 지표 개발\\n   \\n   [PDF 파일 링크](http://arxiv.org/pdf/2405.13084v2)\\n\\n#### 결론\\n\\n이 논문 리뷰는 최신 RAG 기술 동향과 주요 연구 성과를 검토하여, 현재 연구의 발전 방향과 도전 과제를 체계적으로 분석하였습니다. 공평한 순위 매기기, 사이버 보안 도메인 응용, 긴 맥락 LLM과의 비교, 마스크 기반 공격 방법, 그리고 대화 시스템에 관한 연구들이 주요 트렌드로 나타났습니다. 이러한 연구들은 RAG 기술의 신뢰성을 높이고, 더 다양한 응용 분야에서의 성능을 증진하는 데 기여하고 있습니다.\\n\\n**참고문헌**\\n- Kim, T. E., & Diaz, F. (2024). Towards Fair RAG: On the Impact of Fair Ranking in Retrieval-Augmented Generation. arXiv preprint. Retrieved from http://arxiv.org/pdf/2409.11598v2\\n- Rajapaksha, S., Rani, R., & Karafili, E. (2024). A RAG-Based Question-Answering Solution for Cyber-Attack Investigation and Attribution. arXiv preprint. Retrieved from http://arxiv.org/pdf/2408.06272v1\\n- Li, Z., Li, C., Zhang, M., Mei, Q., & Bendersky, M. (2024). Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive Study and Hybrid Approach. arXiv preprint. Retrieved from http://arxiv.org/pdf/2407.16833v2\\n- Liu, M., Zhang, S., & Long, C. (2024). Mask-based Membership Inference Attacks for Retrieval-Augmented Generation. arXiv preprint. Retrieved from http://arxiv.org/pdf/2410.20142v1\\n- Cai, Y., Chen, S., Wu, Y., Huang, Y., Feng, J., & Ou, Z. (2024). The 2nd FutureDial Challenge: Dialog Systems with Retrieval Augmented Generation (FutureDial-RAG). arXiv preprint. Retrieved from http://arxiv.org/pdf/2405.13084v2\\n\\nTERMINATE', type='TextMessage')], stop_reason=\"Text 'TERMINATE' mentioned\")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await Console(\n",
    "    team.run_stream(\n",
    "        # task=\"멀티 에이전트 AI 시스템 구축을 위한한 논문 리뷰 리포트 작성\",\n",
    "        task=\"최신 RAG 기술에 대한 동향 및 논문 리뷰\",\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
